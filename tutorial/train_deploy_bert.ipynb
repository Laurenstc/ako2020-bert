{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Train and Deploy Your BERT Model with GluonNLP on SageMaker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Fine-tuning BERT for Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "In this section, we fine-tune the BERT Base model for sentiment analysis on the IMDB dataset.\n",
    "\n",
    "## Preparation\n",
    "\n",
    "First, let's install the necessary dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mmxnet-cu100mkl 1.5.1.post0 has requirement numpy<2.0.0,>1.16.0, but you'll have numpy 1.14.5 which is incompatible.\u001b[0m\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 19.2.3 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# gluonnlp is not available on SageMaker\n",
    "!pip install mxnet-cu100mkl https://github.com/dmlc/gluon-nlp/tarball/master -U -q\n",
    "import argparse, time\n",
    "import mxnet as mx\n",
    "import gluonnlp as nlp\n",
    "# a few utitility functions\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-06T01:36:58.464578Z",
     "start_time": "2019-08-06T01:36:57.258390Z"
    },
    "attributes": {
     "classes": [],
     "id": "",
     "n": "1"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(batch_size=32, lr=5e-05, num_epochs=1)\n"
     ]
    }
   ],
   "source": [
    "# these hyper-parameters can be used for SageMaker training jobs, or hyper-parameter tuning jobs.\n",
    "parser = argparse.ArgumentParser(description='BERT sentiment analysis fine-tune hyper-parameters.')\n",
    "parser.add_argument('--batch_size', type=int, default=32,\n",
    "                    help='batch size per GPU.')\n",
    "parser.add_argument('--num_epochs', type=int, default=1, \n",
    "                    help='The number of epochs to train')\n",
    "parser.add_argument('--lr', type=float, default=5e-5,\n",
    "                    help='Learning rate')\n",
    "\n",
    "args = parser.parse_args([])\n",
    "print(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Get Pre-trained BERT Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "We can load the pre-trained BERT fairly easily using the model API in GluonNLP, which returns the vocabulary along with the model. We include the pooler layer of the pre-trained model by setting `use_pooler` to `True`.\n",
    "The list of pre-trained BERT models available in GluonNLP can be found [here](http://gluon-nlp.mxnet.io/model_zoo/bert/index.html).\n",
    "\n",
    "Now that we have loaded the BERT model, we only need to attach an additional layer for classification.\n",
    "The `BERTClassifier` class uses a BERT base model to encode sentence representation, followed by a `nn.Dense` layer for classification. We only need to initialize the classification layer. The encoding layers are already initialized with pre-trained weights. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-26T22:44:54.906532Z",
     "start_time": "2019-07-26T22:44:34.102308Z"
    },
    "attributes": {
     "classes": [],
     "id": "",
     "n": "8"
    },
    "scrolled": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERTClassifier(\n",
      "  (bert): BERTModel(\n",
      "    (encoder): BERTEncoder(\n",
      "      (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "      (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "      (transformer_cells): HybridSequential(\n",
      "        (0): BERTEncoderCell(\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          (attention_cell): MultiHeadAttentionCell(\n",
      "            (_base_cell): DotProductAttentionCell(\n",
      "              (_dropout_layer): Dropout(p = 0.1, axes=())\n",
      "            )\n",
      "            (proj_query): Dense(768 -> 768, linear)\n",
      "            (proj_key): Dense(768 -> 768, linear)\n",
      "            (proj_value): Dense(768 -> 768, linear)\n",
      "          )\n",
      "          (proj): Dense(768 -> 768, linear)\n",
      "          (ffn): BERTPositionwiseFFN(\n",
      "            (ffn_1): Dense(768 -> 3072, linear)\n",
      "            (activation): GELU()\n",
      "            (ffn_2): Dense(3072 -> 768, linear)\n",
      "            (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "            (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "          )\n",
      "          (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "        )\n",
      "        (1): BERTEncoderCell(\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          (attention_cell): MultiHeadAttentionCell(\n",
      "            (_base_cell): DotProductAttentionCell(\n",
      "              (_dropout_layer): Dropout(p = 0.1, axes=())\n",
      "            )\n",
      "            (proj_query): Dense(768 -> 768, linear)\n",
      "            (proj_key): Dense(768 -> 768, linear)\n",
      "            (proj_value): Dense(768 -> 768, linear)\n",
      "          )\n",
      "          (proj): Dense(768 -> 768, linear)\n",
      "          (ffn): BERTPositionwiseFFN(\n",
      "            (ffn_1): Dense(768 -> 3072, linear)\n",
      "            (activation): GELU()\n",
      "            (ffn_2): Dense(3072 -> 768, linear)\n",
      "            (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "            (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "          )\n",
      "          (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "        )\n",
      "        (2): BERTEncoderCell(\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          (attention_cell): MultiHeadAttentionCell(\n",
      "            (_base_cell): DotProductAttentionCell(\n",
      "              (_dropout_layer): Dropout(p = 0.1, axes=())\n",
      "            )\n",
      "            (proj_query): Dense(768 -> 768, linear)\n",
      "            (proj_key): Dense(768 -> 768, linear)\n",
      "            (proj_value): Dense(768 -> 768, linear)\n",
      "          )\n",
      "          (proj): Dense(768 -> 768, linear)\n",
      "          (ffn): BERTPositionwiseFFN(\n",
      "            (ffn_1): Dense(768 -> 3072, linear)\n",
      "            (activation): GELU()\n",
      "            (ffn_2): Dense(3072 -> 768, linear)\n",
      "            (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "            (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "          )\n",
      "          (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "        )\n",
      "        (3): BERTEncoderCell(\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          (attention_cell): MultiHeadAttentionCell(\n",
      "            (_base_cell): DotProductAttentionCell(\n",
      "              (_dropout_layer): Dropout(p = 0.1, axes=())\n",
      "            )\n",
      "            (proj_query): Dense(768 -> 768, linear)\n",
      "            (proj_key): Dense(768 -> 768, linear)\n",
      "            (proj_value): Dense(768 -> 768, linear)\n",
      "          )\n",
      "          (proj): Dense(768 -> 768, linear)\n",
      "          (ffn): BERTPositionwiseFFN(\n",
      "            (ffn_1): Dense(768 -> 3072, linear)\n",
      "            (activation): GELU()\n",
      "            (ffn_2): Dense(3072 -> 768, linear)\n",
      "            (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "            (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "          )\n",
      "          (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "        )\n",
      "        (4): BERTEncoderCell(\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          (attention_cell): MultiHeadAttentionCell(\n",
      "            (_base_cell): DotProductAttentionCell(\n",
      "              (_dropout_layer): Dropout(p = 0.1, axes=())\n",
      "            )\n",
      "            (proj_query): Dense(768 -> 768, linear)\n",
      "            (proj_key): Dense(768 -> 768, linear)\n",
      "            (proj_value): Dense(768 -> 768, linear)\n",
      "          )\n",
      "          (proj): Dense(768 -> 768, linear)\n",
      "          (ffn): BERTPositionwiseFFN(\n",
      "            (ffn_1): Dense(768 -> 3072, linear)\n",
      "            (activation): GELU()\n",
      "            (ffn_2): Dense(3072 -> 768, linear)\n",
      "            (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "            (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "          )\n",
      "          (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "        )\n",
      "        (5): BERTEncoderCell(\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          (attention_cell): MultiHeadAttentionCell(\n",
      "            (_base_cell): DotProductAttentionCell(\n",
      "              (_dropout_layer): Dropout(p = 0.1, axes=())\n",
      "            )\n",
      "            (proj_query): Dense(768 -> 768, linear)\n",
      "            (proj_key): Dense(768 -> 768, linear)\n",
      "            (proj_value): Dense(768 -> 768, linear)\n",
      "          )\n",
      "          (proj): Dense(768 -> 768, linear)\n",
      "          (ffn): BERTPositionwiseFFN(\n",
      "            (ffn_1): Dense(768 -> 3072, linear)\n",
      "            (activation): GELU()\n",
      "            (ffn_2): Dense(3072 -> 768, linear)\n",
      "            (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "            (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "          )\n",
      "          (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "        )\n",
      "        (6): BERTEncoderCell(\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          (attention_cell): MultiHeadAttentionCell(\n",
      "            (_base_cell): DotProductAttentionCell(\n",
      "              (_dropout_layer): Dropout(p = 0.1, axes=())\n",
      "            )\n",
      "            (proj_query): Dense(768 -> 768, linear)\n",
      "            (proj_key): Dense(768 -> 768, linear)\n",
      "            (proj_value): Dense(768 -> 768, linear)\n",
      "          )\n",
      "          (proj): Dense(768 -> 768, linear)\n",
      "          (ffn): BERTPositionwiseFFN(\n",
      "            (ffn_1): Dense(768 -> 3072, linear)\n",
      "            (activation): GELU()\n",
      "            (ffn_2): Dense(3072 -> 768, linear)\n",
      "            (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "            (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "          )\n",
      "          (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "        )\n",
      "        (7): BERTEncoderCell(\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          (attention_cell): MultiHeadAttentionCell(\n",
      "            (_base_cell): DotProductAttentionCell(\n",
      "              (_dropout_layer): Dropout(p = 0.1, axes=())\n",
      "            )\n",
      "            (proj_query): Dense(768 -> 768, linear)\n",
      "            (proj_key): Dense(768 -> 768, linear)\n",
      "            (proj_value): Dense(768 -> 768, linear)\n",
      "          )\n",
      "          (proj): Dense(768 -> 768, linear)\n",
      "          (ffn): BERTPositionwiseFFN(\n",
      "            (ffn_1): Dense(768 -> 3072, linear)\n",
      "            (activation): GELU()\n",
      "            (ffn_2): Dense(3072 -> 768, linear)\n",
      "            (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "            (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "          )\n",
      "          (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "        )\n",
      "        (8): BERTEncoderCell(\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          (attention_cell): MultiHeadAttentionCell(\n",
      "            (_base_cell): DotProductAttentionCell(\n",
      "              (_dropout_layer): Dropout(p = 0.1, axes=())\n",
      "            )\n",
      "            (proj_query): Dense(768 -> 768, linear)\n",
      "            (proj_key): Dense(768 -> 768, linear)\n",
      "            (proj_value): Dense(768 -> 768, linear)\n",
      "          )\n",
      "          (proj): Dense(768 -> 768, linear)\n",
      "          (ffn): BERTPositionwiseFFN(\n",
      "            (ffn_1): Dense(768 -> 3072, linear)\n",
      "            (activation): GELU()\n",
      "            (ffn_2): Dense(3072 -> 768, linear)\n",
      "            (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "            (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "          )\n",
      "          (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "        )\n",
      "        (9): BERTEncoderCell(\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          (attention_cell): MultiHeadAttentionCell(\n",
      "            (_base_cell): DotProductAttentionCell(\n",
      "              (_dropout_layer): Dropout(p = 0.1, axes=())\n",
      "            )\n",
      "            (proj_query): Dense(768 -> 768, linear)\n",
      "            (proj_key): Dense(768 -> 768, linear)\n",
      "            (proj_value): Dense(768 -> 768, linear)\n",
      "          )\n",
      "          (proj): Dense(768 -> 768, linear)\n",
      "          (ffn): BERTPositionwiseFFN(\n",
      "            (ffn_1): Dense(768 -> 3072, linear)\n",
      "            (activation): GELU()\n",
      "            (ffn_2): Dense(3072 -> 768, linear)\n",
      "            (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "            (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "          )\n",
      "          (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "        )\n",
      "        (10): BERTEncoderCell(\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          (attention_cell): MultiHeadAttentionCell(\n",
      "            (_base_cell): DotProductAttentionCell(\n",
      "              (_dropout_layer): Dropout(p = 0.1, axes=())\n",
      "            )\n",
      "            (proj_query): Dense(768 -> 768, linear)\n",
      "            (proj_key): Dense(768 -> 768, linear)\n",
      "            (proj_value): Dense(768 -> 768, linear)\n",
      "          )\n",
      "          (proj): Dense(768 -> 768, linear)\n",
      "          (ffn): BERTPositionwiseFFN(\n",
      "            (ffn_1): Dense(768 -> 3072, linear)\n",
      "            (activation): GELU()\n",
      "            (ffn_2): Dense(3072 -> 768, linear)\n",
      "            (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "            (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "          )\n",
      "          (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "        )\n",
      "        (11): BERTEncoderCell(\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          (attention_cell): MultiHeadAttentionCell(\n",
      "            (_base_cell): DotProductAttentionCell(\n",
      "              (_dropout_layer): Dropout(p = 0.1, axes=())\n",
      "            )\n",
      "            (proj_query): Dense(768 -> 768, linear)\n",
      "            (proj_key): Dense(768 -> 768, linear)\n",
      "            (proj_value): Dense(768 -> 768, linear)\n",
      "          )\n",
      "          (proj): Dense(768 -> 768, linear)\n",
      "          (ffn): BERTPositionwiseFFN(\n",
      "            (ffn_1): Dense(768 -> 3072, linear)\n",
      "            (activation): GELU()\n",
      "            (ffn_2): Dense(3072 -> 768, linear)\n",
      "            (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "            (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "          )\n",
      "          (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (word_embed): HybridSequential(\n",
      "      (0): Embedding(30522 -> 768, float32)\n",
      "      (1): Dropout(p = 0.1, axes=())\n",
      "    )\n",
      "    (token_type_embed): HybridSequential(\n",
      "      (0): Embedding(2 -> 768, float32)\n",
      "      (1): Dropout(p = 0.1, axes=())\n",
      "    )\n",
      "    (pooler): Dense(768 -> 768, Activation(tanh))\n",
      "  )\n",
      "  (classifier): HybridSequential(\n",
      "    (0): Dense(None -> 2, linear)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "ctx = utils.try_all_gpus()\n",
    "bert, vocabulary = nlp.model.get_model('bert_12_768_12', # the 12-layer BERT Base model\n",
    "                                            dataset_name='book_corpus_wiki_en_uncased',\n",
    "                                            # use pre-trained weights\n",
    "                                            pretrained=True, ctx=ctx,\n",
    "                                            # decoder and classifier are for pre-training only\n",
    "                                            use_decoder=False, use_classifier=False)\n",
    "\n",
    "net = nlp.model.BERTClassifier(bert, 2)\n",
    "# only need initialize the classification layer from scratch\n",
    "net.classifier.initialize(ctx=ctx)\n",
    "# compile the model, required for deployment\n",
    "net.hybridize()\n",
    "print(net)\n",
    "loss_fn = mx.gluon.loss.SoftmaxCELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "To use the pre-trained BERT model, we need to:\n",
    "- tokenize the inputs into words,\n",
    "- insert [CLS] at the beginning of a sentence, \n",
    "- insert [SEP] at the end of a sentence, and\n",
    "- generate segment ids\n",
    "\n",
    "### Data Transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "We again use the IMDB dataset, but for this time, downloading using the GluonNLP data API. We then use the transform API to transform the raw scores to positive labels and negative labels. \n",
    "To process sentences with BERT-style '[CLS]', '[SEP]' tokens, you can use `data.BERTSentenceTransform` API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-26T22:44:57.188028Z",
     "start_time": "2019-07-26T22:44:57.181395Z"
    },
    "attributes": {
     "classes": [],
     "id": "",
     "n": "15"
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "train_dataset_raw = nlp.data.IMDB('train')\n",
    "test_dataset_raw = nlp.data.IMDB('test')\n",
    "# tokenize texts into words\n",
    "tokenizer = nlp.data.BERTTokenizer(vocabulary)\n",
    "# add begin-of-sentence, end-of-sentence tokens and perform vocabulary lookup\n",
    "transform = nlp.data.BERTSentenceTransform(tokenizer, max_seq_length=128, pair=False)\n",
    "\n",
    "def transform_fn(data):\n",
    "    # transform texts to tensors\n",
    "    text, label = data\n",
    "    # transform label into position / negative\n",
    "    label = 1 if label >= 5 else 0\n",
    "    data, length, segment_type = transform([text])\n",
    "    return data.astype('float32'), length.astype('float32'), segment_type.astype('float32'), label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-26T22:44:57.197310Z",
     "start_time": "2019-07-26T22:44:57.189448Z"
    },
    "attributes": {
     "classes": [],
     "id": "",
     "n": "16"
    },
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original sentence = \n",
      "Bromwell High is a cartoon comedy. It ran at the same time as some other programs about school life, such as \"Teachers\". My 35 years in the teaching profession lead me to believe that Bromwell High's satire is much closer to reality than is \"Teachers\". The scramble to survive financially, the insightful students who can see right through their pathetic teachers' pomp, the pettiness of the whole situation, all remind me of the schools I knew and their students. When I saw the episode in which a student repeatedly tried to burn down the school, I immediately recalled ......... at .......... High. A classic line: INSPECTOR: I'm here to sack one of your teachers. STUDENT: Welcome to Bromwell High. I expect that many adults of my age think that Bromwell High is far fetched. What a pity that it isn't!\n",
      "\n",
      "word indices = \n",
      "[    2 22953  2213  4381  2152  2003  1037  9476  4038  1012  2009  2743\n",
      "  2012  1996  2168  2051  2004  2070  2060  3454  2055  2082  2166  1010\n",
      "  2107  2004  1000  5089  1000  1012  2026  3486  2086  1999  1996  4252\n",
      "  9518  2599  2033  2000  2903  2008 22953  2213  4381  2152  1005  1055\n",
      " 18312  2003  2172  3553  2000  4507  2084  2003  1000  5089  1000  1012\n",
      "  1996 25740  2000  5788 13732  1010  1996 12369  3993  2493  2040  2064\n",
      "  2156  2157  2083  2037 17203  5089  1005 13433  8737  1010  1996  9004\n",
      " 10196  4757  1997  1996  2878  3663  1010  2035 10825  2033  1997  1996\n",
      "  2816  1045  2354  1998  2037  2493  1012  2043  1045  2387  1996  2792\n",
      "  1999  2029  1037  3076  8385  2699  2000  6402  2091  1996  2082  1010\n",
      "  1045  3202  7383  1012  1012  1012  1012     3]\n"
     ]
    }
   ],
   "source": [
    "train_dataset = train_dataset_raw.transform(transform_fn)\n",
    "test_dataset = test_dataset_raw.transform(transform_fn)\n",
    "\n",
    "data, length, _, label = train_dataset[0]\n",
    "print('original sentence = \\n{}'.format(train_dataset_raw[0][0]))\n",
    "print('\\nword indices = \\n{}'.format(data.astype('int32')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Let's Train the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Now we have all the pieces to put together, and we can finally start fine-tuning the\n",
    "model with a few epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-26T22:53:53.156467Z",
     "start_time": "2019-07-26T22:44:57.484026Z"
    },
    "attributes": {
     "classes": [],
     "id": "",
     "n": "19"
    },
    "scrolled": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0, Train Acc 0.4765625, Train Loss 0.7620674669742584\n",
      "Batch 25, Train Acc 0.6574519230769231, Train Loss 0.6001719935582235\n",
      "Batch 50, Train Acc 0.7356004901960784, Train Loss 0.5002635222877941\n",
      "Batch 75, Train Acc 0.7708675986842105, Train Loss 0.45364915297709796\n",
      "Batch 100, Train Acc 0.7905321782178217, Train Loss 0.4265145588260476\n",
      "Batch 125, Train Acc 0.8072916666666666, Train Loss 0.3994708299075091\n",
      "Batch 150, Train Acc 0.8169495033112583, Train Loss 0.38578553280688277\n",
      "Batch 175, Train Acc 0.8248845880681818, Train Loss 0.37391214523549104\n",
      "Epoch 0, Train Acc 0.83128, Train Loss 0.3632569414259372\n",
      "Test Acc 0.8782526133011799,\n",
      "Elapsed time (sec):  245.77179074287415\n"
     ]
    }
   ],
   "source": [
    "batch_size = args.batch_size * len(ctx)\n",
    "train_data, test_data = utils.get_dataloader(batch_size, vocabulary, train_dataset, test_dataset)\n",
    "tick = time.time()\n",
    "utils.fit(net, train_data, test_data, args.num_epochs, args.lr, ctx, loss_fn)\n",
    "tock = time.time()\n",
    "print('Elapsed time (sec): ', tock-tick)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-26T22:53:53.190988Z",
     "start_time": "2019-07-26T22:53:53.159462Z"
    },
    "attributes": {
     "classes": [],
     "id": "",
     "n": "20"
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'positive'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utils.predict_sentiment(net, ctx, vocabulary, tokenizer, 'this movie is so great')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Deploy on SageMaker\n",
    "\n",
    "1. Model parameters\n",
    "2. Code with data pre-processing and model inference\n",
    "3. A docker container with dependencies installed\n",
    "4. Launch a serving end-point with SageMaker SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker, tarfile, inspect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 1. Save Model Parameters and Upload to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model was uploaded to s3://sagemaker-us-east-1-397262719838/model/model.tar.gz\n"
     ]
    }
   ],
   "source": [
    "# save parameters, model definition and vocabulary in a zip file\n",
    "net.export('checkpoint')\n",
    "with open('vocab.json', 'w') as f:\n",
    "    f.write(vocabulary.to_json())\n",
    "with tarfile.open(\"model.tar.gz\", \"w:gz\") as tar:\n",
    "    tar.add(\"checkpoint-0000.params\") \n",
    "    tar.add(\"checkpoint-symbol.json\") \n",
    "    tar.add(\"vocab.json\")             \n",
    "# upload the zip file to s3\n",
    "session = sagemaker.Session()\n",
    "uploaded_model = session.upload_data(path='model.tar.gz', key_prefix='model')\n",
    "s3_model_path = 's3://' + session.default_bucket() + '/model/model.tar.gz'\n",
    "print(\"Model was uploaded to\", s3_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 2. the Code for Inference\n",
    "\n",
    "Two functions: \n",
    "1. model_fn() to load model parameters\n",
    "2. transform_fn() to run model inference given an input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "serve.py\r\n"
     ]
    }
   ],
   "source": [
    "# serve.py contains model_fn() and transform_fn()\n",
    "!ls serve.py\n",
    "import serve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 2.1 `model_fn` to Deserialize Checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def model_fn(model_dir):\n",
      "    \"\"\"\n",
      "    Load the gluon model. Called once when hosting service starts.\n",
      "    :param: model_dir The directory where model files are stored.\n",
      "    :return: a Gluon model, and the vocabulary\n",
      "    \"\"\"\n",
      "    prefix = 'checkpoint'\n",
      "    net = mx.gluon.nn.SymbolBlock.imports(prefix + '-symbol.json',\n",
      "                                          ['data0', 'data1', 'data2'],\n",
      "                                          prefix + '-0000.params')\n",
      "    net.load_parameters('%s/'%model_dir + prefix + '-0000.params', ctx=mx.cpu())\n",
      "    vocab_json = open('%s/vocab.json'%model_dir).read()\n",
      "    vocab = nlp.vocab.BERTVocab.from_json(vocab_json)\n",
      "    tokenizer = nlp.data.BERTTokenizer(vocabulary)\n",
      "    return net, vocab\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(inspect.getsource(serve.model_fn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 2.2 `transform_fn` to Run Model Inference Given an Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def transform_fn(model, data, input_content_type, output_content_type):\n",
      "    \"\"\"\n",
      "    Transform a request using the Gluon model. Called once per request.\n",
      "    :param model: The Gluon model and the vocab\n",
      "    :param data: The request payload.\n",
      "    :param input_content_type: The request content type.\n",
      "    :param output_content_type: The (desired) response content type.\n",
      "    :return: response payload and content type.\n",
      "    \"\"\"\n",
      "    # we can use content types to vary input/output handling, but\n",
      "    # here we just assume json for both\n",
      "    net, vocabulary, tokenizer = model\n",
      "    sentence = json.loads(data)\n",
      "    result = predict_sentiment(net, mx.cpu(), vocabulary, tokenizer, sentence)\n",
      "    response_body = json.dumps(result)\n",
      "    return response_body, output_content_type\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(inspect.getsource(serve.transform_fn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 3. Build a Docker Container for Serving"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Let's prepare a docker container with all the dependencies required for model inference. Here we build a docker container based on the SageMaker MXNet inference container, and you can find the list of all available inference containers at https://docs.aws.amazon.com/sagemaker/latest/dg/pre-built-containers-frameworks-deep-learning.html\n",
    "\n",
    "Here we use local mode for demonstration purpose. To deploy on actual instances, you need to login into AWS elastic container registry (ECR) service, and push the container to ECR. \n",
    "\n",
    "```\n",
    "docker build -t $YOUR_EDR_DOCKER_TAG . -f Dockerfile\n",
    "$(aws ecr get-login --no-include-email --region $YOUR_REGION)\n",
    "docker push $YOUR_EDR_DOCKER_TAG\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FROM 763104351884.dkr.ecr.us-east-1.amazonaws.com/mxnet-inference:1.4.1-cpu-py3\n",
      "\n",
      "RUN pip install mxnet-mkl https://github.com/dmlc/gluon-nlp/tarball/master -U --user\n",
      "\n",
      "COPY *.py /opt/ml/model/code/sha256:580482ba6a67051181b8cac872f70fcd55723586671fc806fcc50f747bf4b4ff\n"
     ]
    }
   ],
   "source": [
    "!cat Dockerfile\n",
    "!docker build -t my-docker:inference . -f Dockerfile -q "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Use SageMaker SDK to Deploy the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "We create a MXNet model which can be deployed later, by specifying the docker image, and entry point for the inference code. If serve.py does not work, use dummy_hosting_module.py for debugging purpose. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from sagemaker.mxnet.model import MXNetModel\n",
    "sagemaker_model = MXNetModel(model_data=s3_model_path,    # model parameters\n",
    "                             image='my-docker:inference', # docker images\n",
    "                             role=sagemaker.get_execution_role(), \n",
    "                             py_version='py3',            # python version\n",
    "                             framework_version='1.4.1',   # mxnet version\n",
    "                             entry_point='serve.py',\n",
    "                             source_dir='.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "We use 'local' mode to test our deployment code, where the inference happens on the current instance.\n",
    "If you are ready to deploy the model on a new instance, change the `instance_type` argument to values such as `ml.c4.xlarge`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attaching to tmpkzmd9tww_algo-1-fig7w_1\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:56,199 [INFO ] main com.amazonaws.ml.mms.ModelServer - \n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m MMS Home: /usr/local/lib/python3.6/site-packages\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m Current directory: /\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m Temp directory: /home/model-server/tmp\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m Number of GPUs: 0\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m Number of CPUs: 32\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m Max heap size: 27305 M\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m Python executable: /usr/local/bin/python3.6\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m Config file: /etc/sagemaker-mms.properties\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m Inference address: http://0.0.0.0:8080\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m Management address: http://127.0.0.1:8081\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m Model Store: /.sagemaker/mms/models\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m Initial Models: ALL\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m Log dir: /logs\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m Metrics dir: /logs\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m Netty threads: 0\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m Netty client threads: 0\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m Default workers per model: 32\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m Blacklist Regex: N/A\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m Maximum Response Size: 6553500\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m Maximum Request Size: 6553500\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:56,251 [INFO ] main com.amazonaws.ml.mms.wlm.ModelManager - Model model loaded.\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:56,394 [INFO ] main com.amazonaws.ml.mms.ModelServer - Initialize Inference server with: EpollServerSocketChannel.\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:56,397 [INFO ] W-9006-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Listening on port: /home/model-server/tmp/.mms.sock.9006\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:56,398 [INFO ] W-9006-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - [PID]173\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:56,410 [INFO ] W-9006-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - MXNet worker started.\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:56,410 [INFO ] W-9006-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Python runtime: 3.6.8\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:56,416 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Listening on port: /home/model-server/tmp/.mms.sock.9000\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:56,417 [INFO ] W-9006-model com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.mms.sock.9006\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:56,424 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - [PID]170\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:56,431 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - MXNet worker started.\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:56,433 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Python runtime: 3.6.8\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:56,434 [INFO ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.mms.sock.9000\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:56,439 [INFO ] W-9008-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Listening on port: /home/model-server/tmp/.mms.sock.9008\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:56,439 [INFO ] W-9008-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - [PID]175\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:56,441 [INFO ] W-9008-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - MXNet worker started.\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:56,441 [INFO ] W-9008-model com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.mms.sock.9008\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:56,442 [INFO ] W-9008-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Python runtime: 3.6.8\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:56,443 [INFO ] W-9007-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Listening on port: /home/model-server/tmp/.mms.sock.9007\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:56,443 [INFO ] W-9007-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - [PID]176\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:56,444 [INFO ] W-9007-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - MXNet worker started.\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:56,444 [INFO ] W-9007-model com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.mms.sock.9007\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:56,444 [INFO ] W-9003-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Listening on port: /home/model-server/tmp/.mms.sock.9003\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:56,444 [INFO ] W-9007-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Python runtime: 3.6.8\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:56,444 [INFO ] W-9003-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - [PID]172\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:56,444 [INFO ] W-9022-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Listening on port: /home/model-server/tmp/.mms.sock.9022\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:56,445 [INFO ] W-9003-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - MXNet worker started.\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:56,445 [INFO ] W-9003-model com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.mms.sock.9003\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:56,445 [INFO ] W-9022-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - [PID]223\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:56,445 [INFO ] W-9016-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Listening on port: /home/model-server/tmp/.mms.sock.9016\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:56,446 [INFO ] W-9003-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Python runtime: 3.6.8\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:56,445 [INFO ] W-9001-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Listening on port: /home/model-server/tmp/.mms.sock.9001\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:56,446 [INFO ] W-9022-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - MXNet worker started.\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:56,446 [INFO ] W-9016-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - [PID]215\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:56,446 [INFO ] W-9022-model com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.mms.sock.9022\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:56,446 [INFO ] W-9001-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - [PID]168\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:56,446 [INFO ] W-9016-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - MXNet worker started.\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:56,446 [INFO ] W-9001-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - MXNet worker started.\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:56,446 [INFO ] W-9016-model com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.mms.sock.9016\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:56,446 [INFO ] W-9022-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Python runtime: 3.6.8\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:56,447 [INFO ] W-9001-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Python runtime: 3.6.8\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:56,447 [INFO ] W-9016-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Python runtime: 3.6.8\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:56,447 [INFO ] W-9001-model com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.mms.sock.9001\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:56,458 [INFO ] W-9004-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Listening on port: /home/model-server/tmp/.mms.sock.9004\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:56,459 [INFO ] W-9002-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Listening on port: /home/model-server/tmp/.mms.sock.9002\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:56,459 [INFO ] W-9004-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - [PID]171\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:56,459 [INFO ] W-9004-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - MXNet worker started.\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:56,459 [INFO ] W-9004-model com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.mms.sock.9004\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:56,460 [INFO ] W-9004-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Python runtime: 3.6.8\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:56,460 [INFO ] W-9002-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - [PID]169\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:56,461 [INFO ] W-9002-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - MXNet worker started.\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:56,461 [INFO ] W-9002-model com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.mms.sock.9002\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:56,461 [INFO ] W-9002-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Python runtime: 3.6.8\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:56,464 [INFO ] W-9014-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Listening on port: /home/model-server/tmp/.mms.sock.9014\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:56,464 [INFO ] W-9014-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - [PID]226\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:56,464 [INFO ] W-9014-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - MXNet worker started.\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:56,464 [INFO ] W-9014-model com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.mms.sock.9014\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:56,465 [INFO ] W-9014-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Python runtime: 3.6.8\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:56,473 [INFO ] W-9005-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Listening on port: /home/model-server/tmp/.mms.sock.9005\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:56,473 [INFO ] W-9005-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - [PID]177\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:56,473 [INFO ] W-9005-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - MXNet worker started.\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:56,473 [INFO ] W-9005-model com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.mms.sock.9005\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:56,474 [INFO ] W-9005-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Python runtime: 3.6.8\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:56,479 [INFO ] W-9017-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Listening on port: /home/model-server/tmp/.mms.sock.9017\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:56,479 [INFO ] W-9017-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - [PID]214\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:56,479 [INFO ] W-9017-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - MXNet worker started.\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:56,479 [INFO ] W-9017-model com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.mms.sock.9017\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:56,479 [INFO ] W-9017-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Python runtime: 3.6.8\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:56,483 [INFO ] W-9011-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Listening on port: /home/model-server/tmp/.mms.sock.9011\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:56,483 [INFO ] W-9011-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - [PID]220\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:56,483 [INFO ] W-9011-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - MXNet worker started.\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:56,483 [INFO ] W-9011-model com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.mms.sock.9011\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:56,483 [INFO ] W-9011-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Python runtime: 3.6.8\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:56,485 [INFO ] W-9023-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Listening on port: /home/model-server/tmp/.mms.sock.9023\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:56,485 [INFO ] W-9023-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - [PID]219\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:56,485 [INFO ] W-9023-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - MXNet worker started.\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:56,485 [INFO ] W-9023-model com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.mms.sock.9023\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:56,485 [INFO ] W-9023-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Python runtime: 3.6.8\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:56,486 [INFO ] W-9012-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Listening on port: /home/model-server/tmp/.mms.sock.9012\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:56,487 [INFO ] W-9012-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - [PID]222\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:56,487 [INFO ] W-9012-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - MXNet worker started.\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:56,487 [INFO ] W-9012-model com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.mms.sock.9012\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:56,487 [INFO ] W-9012-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Python runtime: 3.6.8\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:56,492 [INFO ] W-9021-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Listening on port: /home/model-server/tmp/.mms.sock.9021\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:56,493 [INFO ] W-9018-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Listening on port: /home/model-server/tmp/.mms.sock.9018\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:56,493 [INFO ] W-9021-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - [PID]224\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:56,493 [INFO ] W-9021-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - MXNet worker started.\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:56,493 [INFO ] W-9018-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - [PID]221\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:56,493 [INFO ] W-9021-model com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.mms.sock.9021\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:56,493 [INFO ] W-9021-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Python runtime: 3.6.8\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:56,493 [INFO ] W-9018-model com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.mms.sock.9018\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:56,493 [INFO ] W-9018-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - MXNet worker started.\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:56,493 [INFO ] W-9018-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Python runtime: 3.6.8\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:56,494 [INFO ] W-9015-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Listening on port: /home/model-server/tmp/.mms.sock.9015\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:56,494 [INFO ] W-9015-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - [PID]216\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:56,494 [INFO ] W-9015-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - MXNet worker started.\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:56,494 [INFO ] W-9015-model com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.mms.sock.9015\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:56,494 [INFO ] W-9015-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Python runtime: 3.6.8\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:56,495 [INFO ] W-9020-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Listening on port: /home/model-server/tmp/.mms.sock.9020\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:56,495 [INFO ] W-9020-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - [PID]225\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:56,495 [INFO ] W-9020-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - MXNet worker started.\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:56,495 [INFO ] W-9020-model com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.mms.sock.9020\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:56,495 [INFO ] W-9020-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Python runtime: 3.6.8\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:56,496 [INFO ] W-9019-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Listening on port: /home/model-server/tmp/.mms.sock.9019\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:56,496 [INFO ] W-9009-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Listening on port: /home/model-server/tmp/.mms.sock.9009\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:56,496 [INFO ] W-9019-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - [PID]227\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:56,496 [INFO ] W-9009-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - [PID]213\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:56,496 [INFO ] W-9019-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - MXNet worker started.\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:56,496 [INFO ] W-9009-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - MXNet worker started.\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:56,496 [INFO ] W-9010-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Listening on port: /home/model-server/tmp/.mms.sock.9010\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:56,496 [INFO ] W-9019-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Python runtime: 3.6.8\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:56,496 [INFO ] W-9009-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Python runtime: 3.6.8\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:56,496 [INFO ] W-9019-model com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.mms.sock.9019\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:56,497 [INFO ] W-9010-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - [PID]230\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:56,497 [INFO ] W-9009-model com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.mms.sock.9009\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:56,496 [INFO ] W-9024-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Listening on port: /home/model-server/tmp/.mms.sock.9024\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:56,497 [INFO ] W-9010-model com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.mms.sock.9010\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:56,497 [INFO ] W-9024-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - [PID]217\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:56,497 [INFO ] W-9013-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Listening on port: /home/model-server/tmp/.mms.sock.9013\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:56,497 [INFO ] W-9010-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - MXNet worker started.\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:56,497 [INFO ] W-9024-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - MXNet worker started.\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:56,497 [INFO ] W-9024-model com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.mms.sock.9024\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:56,497 [INFO ] W-9013-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - [PID]229\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:56,497 [INFO ] W-9010-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Python runtime: 3.6.8\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:56,497 [INFO ] W-9024-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Python runtime: 3.6.8\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:56,497 [INFO ] W-9013-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - MXNet worker started.\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:56,497 [INFO ] W-9013-model com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.mms.sock.9013\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:56,498 [INFO ] W-9013-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Python runtime: 3.6.8\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:56,506 [INFO ] W-9026-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Listening on port: /home/model-server/tmp/.mms.sock.9026\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:56,506 [INFO ] W-9026-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - [PID]254\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:56,506 [INFO ] W-9026-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - MXNet worker started.\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:56,506 [INFO ] W-9026-model com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.mms.sock.9026\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:56,506 [INFO ] W-9026-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Python runtime: 3.6.8\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:56,507 [INFO ] W-9025-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Listening on port: /home/model-server/tmp/.mms.sock.9025\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:56,507 [INFO ] W-9025-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - [PID]253\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:56,507 [INFO ] W-9025-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - MXNet worker started.\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:56,508 [INFO ] W-9025-model com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.mms.sock.9025\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:56,508 [INFO ] W-9025-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Python runtime: 3.6.8\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:56,516 [INFO ] main com.amazonaws.ml.mms.ModelServer - Inference API bind to: http://0.0.0.0:8080\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:56,516 [INFO ] main com.amazonaws.ml.mms.ModelServer - Initialize Management server with: EpollServerSocketChannel.\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:56,517 [INFO ] W-9026-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.mms.sock.9026.\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:56,517 [INFO ] W-9003-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.mms.sock.9003.\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:56,517 [INFO ] W-9015-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.mms.sock.9015.\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:56,517 [INFO ] W-9016-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.mms.sock.9016.\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:56,517 [INFO ] W-9005-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.mms.sock.9005.\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:56,517 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.mms.sock.9000.\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:56,517 [INFO ] W-9004-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.mms.sock.9004.\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:56,517 [INFO ] W-9010-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.mms.sock.9010.\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:56,517 [INFO ] W-9006-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.mms.sock.9006.\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:56,517 [INFO ] W-9025-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.mms.sock.9025.\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:56,517 [INFO ] W-9009-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.mms.sock.9009.\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:56,517 [INFO ] W-9012-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.mms.sock.9012.\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:56,517 [INFO ] W-9017-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.mms.sock.9017.\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:56,518 [INFO ] W-9011-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.mms.sock.9011.\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:56,518 [INFO ] W-9021-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.mms.sock.9021.\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:56,517 [INFO ] W-9024-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.mms.sock.9024.\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:56,519 [INFO ] W-9013-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.mms.sock.9013.\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:56,520 [INFO ] W-9022-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.mms.sock.9022.\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:56,521 [INFO ] W-9018-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.mms.sock.9018.\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:56,522 [INFO ] W-9008-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.mms.sock.9008.\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:56,522 [INFO ] W-9019-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.mms.sock.9019.\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:56,523 [INFO ] W-9007-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.mms.sock.9007.\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:56,523 [INFO ] W-9002-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.mms.sock.9002.\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:56,523 [INFO ] W-9014-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.mms.sock.9014.\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:56,524 [INFO ] W-9027-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Listening on port: /home/model-server/tmp/.mms.sock.9027\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:56,524 [INFO ] W-9027-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - [PID]262\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:56,524 [INFO ] W-9001-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.mms.sock.9001.\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:56,525 [INFO ] W-9027-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - MXNet worker started.\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:56,525 [INFO ] W-9027-model com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.mms.sock.9027\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:56,526 [INFO ] W-9027-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Python runtime: 3.6.8\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:56,526 [INFO ] W-9023-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.mms.sock.9023.\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:56,526 [INFO ] main com.amazonaws.ml.mms.ModelServer - Management API bind to: http://127.0.0.1:8081\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:56,526 [INFO ] W-9020-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.mms.sock.9020.\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:56,527 [INFO ] W-9027-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.mms.sock.9027.\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m Model server started.\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:56,534 [WARN ] pool-2-thread-1 com.amazonaws.ml.mms.metrics.MetricCollector - worker pid is not available yet.\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:56,541 [INFO ] W-9029-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Listening on port: /home/model-server/tmp/.mms.sock.9029\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:56,542 [INFO ] W-9029-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - [PID]301\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:56,542 [INFO ] W-9029-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - MXNet worker started.\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:56,542 [INFO ] W-9029-model com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.mms.sock.9029\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:56,542 [INFO ] W-9029-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Python runtime: 3.6.8\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:56,544 [INFO ] W-9029-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.mms.sock.9029.\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:56,545 [INFO ] W-9028-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Listening on port: /home/model-server/tmp/.mms.sock.9028\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:56,545 [INFO ] W-9028-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - [PID]291\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:56,545 [INFO ] W-9028-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - MXNet worker started.\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:56,545 [INFO ] W-9028-model com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.mms.sock.9028\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:56,545 [INFO ] W-9028-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Python runtime: 3.6.8\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:56,547 [INFO ] W-9028-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.mms.sock.9028.\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:56,566 [INFO ] W-9030-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Listening on port: /home/model-server/tmp/.mms.sock.9030\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:56,566 [INFO ] W-9030-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - [PID]304\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:56,567 [INFO ] W-9030-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - MXNet worker started.\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:56,567 [INFO ] W-9030-model com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.mms.sock.9030\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:56,567 [INFO ] W-9030-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Python runtime: 3.6.8\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:56,577 [INFO ] W-9031-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Listening on port: /home/model-server/tmp/.mms.sock.9031\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:56,577 [INFO ] W-9031-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - [PID]308\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:56,580 [INFO ] W-9031-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - MXNet worker started.\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:56,581 [INFO ] W-9031-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Python runtime: 3.6.8\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:56,581 [INFO ] W-9031-model com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.mms.sock.9031\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:56,582 [INFO ] W-9030-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.mms.sock.9030.\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:56,588 [INFO ] W-9031-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.mms.sock.9031.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:56,673 [INFO ] pool-1-thread-33 ACCESS_LOG - /172.18.0.1:37396 \"GET /ping HTTP/1.1\" 200 19\r\n",
      "!"
     ]
    }
   ],
   "source": [
    "# Here we use 'local' mode for testing, for real instances use c5.2xlarge, p2.xlarge, etc\n",
    "predictor = sagemaker_model.deploy(initial_instance_count=1,\n",
    "                                   instance_type='local')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:58,596 [INFO ] W-9025-model com.amazonaws.ml.mms.wlm.WorkerThread - Backend response time: 2036\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:58,613 [INFO ] W-9009-model com.amazonaws.ml.mms.wlm.WorkerThread - Backend response time: 2061\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:58,614 [INFO ] W-9011-model com.amazonaws.ml.mms.wlm.WorkerThread - Backend response time: 2054\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:58,619 [INFO ] W-9002-model com.amazonaws.ml.mms.wlm.WorkerThread - Backend response time: 2071\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:58,630 [INFO ] W-9003-model com.amazonaws.ml.mms.wlm.WorkerThread - Backend response time: 2083\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:58,635 [INFO ] W-9023-model com.amazonaws.ml.mms.wlm.WorkerThread - Backend response time: 2083\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:58,642 [WARN ] W-9025-model-stderr com.amazonaws.ml.mms.wlm.WorkerLifeCycle - /root/.local/lib/python3.6/site-packages/mxnet/gluon/block.py:1159: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:58,642 [WARN ] W-9025-model-stderr com.amazonaws.ml.mms.wlm.WorkerLifeCycle - \tdata0: None\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:58,642 [WARN ] W-9025-model-stderr com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   input_sym_arg_type = in_param.infer_type()[0]\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:58,643 [INFO ] W-9015-model com.amazonaws.ml.mms.wlm.WorkerThread - Backend response time: 2080\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:58,646 [INFO ] W-9008-model com.amazonaws.ml.mms.wlm.WorkerThread - Backend response time: 2094\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:58,646 [INFO ] W-9031-model com.amazonaws.ml.mms.wlm.WorkerThread - Backend response time: 2054\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:58,650 [INFO ] W-9005-model com.amazonaws.ml.mms.wlm.WorkerThread - Backend response time: 2098\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:58,657 [INFO ] W-9020-model com.amazonaws.ml.mms.wlm.WorkerThread - Backend response time: 2105\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:58,662 [INFO ] W-9001-model com.amazonaws.ml.mms.wlm.WorkerThread - Backend response time: 2114\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:58,668 [INFO ] W-9024-model com.amazonaws.ml.mms.wlm.WorkerThread - Backend response time: 2115\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:58,671 [INFO ] W-9012-model com.amazonaws.ml.mms.wlm.WorkerThread - Backend response time: 2111\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:58,672 [INFO ] W-9018-model com.amazonaws.ml.mms.wlm.WorkerThread - Backend response time: 2112\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:58,672 [INFO ] W-9029-model com.amazonaws.ml.mms.wlm.WorkerThread - Backend response time: 2124\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:58,681 [INFO ] W-9013-model com.amazonaws.ml.mms.wlm.WorkerThread - Backend response time: 2134\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:58,688 [INFO ] W-9021-model com.amazonaws.ml.mms.wlm.WorkerThread - Backend response time: 2136\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:58,688 [INFO ] W-9028-model com.amazonaws.ml.mms.wlm.WorkerThread - Backend response time: 2141\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:58,698 [INFO ] W-9010-model com.amazonaws.ml.mms.wlm.WorkerThread - Backend response time: 2145\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:58,707 [INFO ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerThread - Backend response time: 2145\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:58,712 [INFO ] W-9004-model com.amazonaws.ml.mms.wlm.WorkerThread - Backend response time: 2160\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:58,718 [INFO ] W-9014-model com.amazonaws.ml.mms.wlm.WorkerThread - Backend response time: 2158\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:58,722 [INFO ] W-9027-model com.amazonaws.ml.mms.wlm.WorkerThread - Backend response time: 2170\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:58,725 [INFO ] W-9006-model com.amazonaws.ml.mms.wlm.WorkerThread - Backend response time: 2178\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:58,733 [INFO ] W-9026-model com.amazonaws.ml.mms.wlm.WorkerThread - Backend response time: 2172\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:58,734 [INFO ] W-9016-model com.amazonaws.ml.mms.wlm.WorkerThread - Backend response time: 2182\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:58,739 [INFO ] W-9007-model com.amazonaws.ml.mms.wlm.WorkerThread - Backend response time: 2179\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:58,739 [INFO ] W-9030-model com.amazonaws.ml.mms.wlm.WorkerThread - Backend response time: 2152\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:58,767 [INFO ] W-9017-model com.amazonaws.ml.mms.wlm.WorkerThread - Backend response time: 2217\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:58,791 [INFO ] W-9022-model com.amazonaws.ml.mms.wlm.WorkerThread - Backend response time: 2223\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:58,810 [INFO ] W-9019-model com.amazonaws.ml.mms.wlm.WorkerThread - Backend response time: 2262\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:59,539 [INFO ] W-9025-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Invoking custom service failed.\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:59,539 [INFO ] W-9025-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Traceback (most recent call last):\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:59,539 [INFO ] W-9025-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File \"/usr/local/lib/python3.6/site-packages/mms/service.py\", line 108, in predict\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:59,539 [INFO ] W-9025-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     ret = self._entry_point(input_batch, self.context)\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:59,539 [INFO ] W-9025-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File \"/usr/local/lib/python3.6/site-packages/sagemaker_inference/default_handler_service.py\", line 31, in handle\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:59,539 [INFO ] W-9025-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     return self._service.transform(data, context)\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:59,539 [INFO ] W-9025-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File \"/usr/local/lib/python3.6/site-packages/sagemaker_inference/transformer.py\", line 55, in transform\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:59,539 [INFO ] W-9025-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     self.validate_and_initialize()\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:59,539 [INFO ] W-9025-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File \"/usr/local/lib/python3.6/site-packages/sagemaker_inference/transformer.py\", line 94, in validate_and_initialize\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:59,539 [INFO ] W-9025-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     self._model = self._model_fn(environment.model_dir)\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:59,539 [INFO ] W-9025-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File \"/opt/ml/model/code/serve.py\", line 19, in model_fn\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:59,539 [INFO ] W-9025-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     tokenizer = nlp.data.BERTTokenizer(vocabulary)\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:59,539 [INFO ] W-9025-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - NameError: name 'vocabulary' is not defined\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:59,540 [INFO ] W-9025-model com.amazonaws.ml.mms.wlm.WorkerThread - Backend response time: 942\n",
      "\u001b[36malgo-1-fig7w_1  |\u001b[0m 2019-10-09 23:01:59,541 [INFO ] W-9025-model ACCESS_LOG - /172.18.0.1:37400 \"POST /invocations HTTP/1.1\" 503 2849\n",
      "\n",
      "Prediction output: {'code': 503, 'type': 'InternalServerException', 'message': 'Prediction failed'}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "output = predictor.predict('The model is deployed. Great!')\n",
    "print('\\nPrediction output: {}\\n\\n'.format(output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Clean Up\n",
    "\n",
    "Remove the endpoint after we are done. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gracefully stopping... (press Ctrl+C again to force)\n"
     ]
    }
   ],
   "source": [
    "predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Resources\n",
    "- Amazon SageMaker https://aws.amazon.com/sagemaker/\n",
    "- Amazon SageMaker Python SDK https://sagemaker.readthedocs.io/\n",
    "- GluonNLP http://gluon-nlp.mxnet.io/\n",
    "- GluonCV http://gluon-cv.mxnet.io/\n",
    "- GluonTS https://gluon-ts.mxnet.io/\n",
    "- Dive into Deep Learning http://d2l.ai/\n",
    "- MXNet Forum https://discuss.mxnet.io/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "## Conclusion\n",
    "\n",
    "In this tutorial, we showed how to fine-tune sentiment analysis model with pre-trained BERT parameters. In GluonNLP, this can be done with such few, simple steps. All we did was apply a BERT-style data transformation to pre-process the data, automatically download the pre-trained model, and feed the transformed data into the model, deploy the model using SageMaker SDK, all within 50 lines of code!\n",
    "\n",
    "For more fine-tuning scripts, visit the [BERT model zoo webpage](http://gluon-nlp.mxnet.io/model_zoo/bert/index.html).\n",
    "\n",
    "## References\n",
    "\n",
    "[1] Devlin, Jacob, et al. \"Bert:\n",
    "Pre-training of deep\n",
    "bidirectional transformers for language understanding.\"\n",
    "arXiv preprint\n",
    "arXiv:1810.04805 (2018).\n",
    "\n",
    "[2] Dolan, William B., and Chris\n",
    "Brockett.\n",
    "\"Automatically constructing a corpus of sentential paraphrases.\"\n",
    "Proceedings of\n",
    "the Third International Workshop on Paraphrasing (IWP2005). 2005.\n",
    "\n",
    "[3] Peters,\n",
    "Matthew E., et al. \"Deep contextualized word representations.\" arXiv\n",
    "preprint\n",
    "arXiv:1802.05365 (2018).\n",
    "\n",
    "[4] Hendrycks, Dan, and Kevin Gimpel. \"Gaussian error linear units (gelus).\" arXiv preprint arXiv:1606.08415 (2016).\n",
    "\n",
    "For fine-tuning, we only need to initialize the last classifier layer from scratch. The other layers are already initialized from the pre-trained model weights."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "conda_mxnet_p36",
   "language": "python",
   "name": "conda_mxnet_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
