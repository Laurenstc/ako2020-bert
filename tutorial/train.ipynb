{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Train and Deploy Your BERT Model with GluonNLP on SageMaker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Fine-tuning BERT for Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "In this section, we fine-tune the BERT Base model for sentiment analysis on the IMDB dataset.\n",
    "\n",
    "## Preparation\n",
    "\n",
    "First, let's install the necessary dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mmxnet-cu100mkl 1.5.1.post0 has requirement numpy<2.0.0,>1.16.0, but you'll have numpy 1.14.5 which is incompatible.\u001b[0m\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 19.2.3 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[31mmxnet-cu100mkl 1.5.1.post0 has requirement numpy<2.0.0,>1.16.0, but you'll have numpy 1.14.5 which is incompatible.\u001b[0m\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 19.2.3 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install mxnet-cu100mkl d2l https://github.com/dmlc/gluon-nlp/tarball/master -U -q\n",
    "!pip install sagemaker-containers -U -q\n",
    "import argparse, time, os, tarfile\n",
    "import d2l\n",
    "import numpy as np\n",
    "import mxnet as mx\n",
    "import gluonnlp as nlp\n",
    "import utils\n",
    "import sagemaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-06T01:36:58.464578Z",
     "start_time": "2019-08-06T01:36:57.258390Z"
    },
    "attributes": {
     "classes": [],
     "id": "",
     "n": "1"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(batch_size=32, lr=5e-05, num_epochs=1)\n"
     ]
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser(description='BERT sentiment analysis fine-tune example.')\n",
    "parser.add_argument('--batch_size', type=int, default=32,\n",
    "                    help='batch size per GPU.')\n",
    "parser.add_argument('--num_epochs', type=int, default=1, \n",
    "                    help='The number of epochs to train')\n",
    "parser.add_argument('--lr', type=float, default=5e-5,\n",
    "                    help='Learning rate')\n",
    "\n",
    "args = parser.parse_args([])\n",
    "print(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Get Pre-trained BERT Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "We can load the pre-trained BERT fairly easily using the model API in GluonNLP, which returns the vocabulary along with the model. We include the pooler layer of the pre-trained model by setting `use_pooler` to `True`.\n",
    "The list of pre-trained BERT models available in GluonNLP can be found [here](../../model_zoo/bert/index.rst).\n",
    "\n",
    "Now that we have loaded the BERT model, we only need to attach an additional layer for classification.\n",
    "The `BERTClassifier` class uses a BERT base model to encode sentence representation, followed by a `nn.Dense` layer for classification. We only need to initialize the classification layer. The encoding layers are already initialized with pre-trained weights. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-26T22:44:54.906532Z",
     "start_time": "2019-07-26T22:44:34.102308Z"
    },
    "attributes": {
     "classes": [],
     "id": "",
     "n": "8"
    },
    "scrolled": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERTClassifier(\n",
      "  (bert): BERTModel(\n",
      "    (encoder): BERTEncoder(\n",
      "      (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "      (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "      (transformer_cells): HybridSequential(\n",
      "        (0): BERTEncoderCell(\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          (attention_cell): MultiHeadAttentionCell(\n",
      "            (_base_cell): DotProductAttentionCell(\n",
      "              (_dropout_layer): Dropout(p = 0.1, axes=())\n",
      "            )\n",
      "            (proj_query): Dense(768 -> 768, linear)\n",
      "            (proj_key): Dense(768 -> 768, linear)\n",
      "            (proj_value): Dense(768 -> 768, linear)\n",
      "          )\n",
      "          (proj): Dense(768 -> 768, linear)\n",
      "          (ffn): BERTPositionwiseFFN(\n",
      "            (ffn_1): Dense(768 -> 3072, linear)\n",
      "            (activation): GELU()\n",
      "            (ffn_2): Dense(3072 -> 768, linear)\n",
      "            (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "            (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "          )\n",
      "          (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "        )\n",
      "        (1): BERTEncoderCell(\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          (attention_cell): MultiHeadAttentionCell(\n",
      "            (_base_cell): DotProductAttentionCell(\n",
      "              (_dropout_layer): Dropout(p = 0.1, axes=())\n",
      "            )\n",
      "            (proj_query): Dense(768 -> 768, linear)\n",
      "            (proj_key): Dense(768 -> 768, linear)\n",
      "            (proj_value): Dense(768 -> 768, linear)\n",
      "          )\n",
      "          (proj): Dense(768 -> 768, linear)\n",
      "          (ffn): BERTPositionwiseFFN(\n",
      "            (ffn_1): Dense(768 -> 3072, linear)\n",
      "            (activation): GELU()\n",
      "            (ffn_2): Dense(3072 -> 768, linear)\n",
      "            (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "            (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "          )\n",
      "          (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "        )\n",
      "        (2): BERTEncoderCell(\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          (attention_cell): MultiHeadAttentionCell(\n",
      "            (_base_cell): DotProductAttentionCell(\n",
      "              (_dropout_layer): Dropout(p = 0.1, axes=())\n",
      "            )\n",
      "            (proj_query): Dense(768 -> 768, linear)\n",
      "            (proj_key): Dense(768 -> 768, linear)\n",
      "            (proj_value): Dense(768 -> 768, linear)\n",
      "          )\n",
      "          (proj): Dense(768 -> 768, linear)\n",
      "          (ffn): BERTPositionwiseFFN(\n",
      "            (ffn_1): Dense(768 -> 3072, linear)\n",
      "            (activation): GELU()\n",
      "            (ffn_2): Dense(3072 -> 768, linear)\n",
      "            (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "            (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "          )\n",
      "          (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "        )\n",
      "        (3): BERTEncoderCell(\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          (attention_cell): MultiHeadAttentionCell(\n",
      "            (_base_cell): DotProductAttentionCell(\n",
      "              (_dropout_layer): Dropout(p = 0.1, axes=())\n",
      "            )\n",
      "            (proj_query): Dense(768 -> 768, linear)\n",
      "            (proj_key): Dense(768 -> 768, linear)\n",
      "            (proj_value): Dense(768 -> 768, linear)\n",
      "          )\n",
      "          (proj): Dense(768 -> 768, linear)\n",
      "          (ffn): BERTPositionwiseFFN(\n",
      "            (ffn_1): Dense(768 -> 3072, linear)\n",
      "            (activation): GELU()\n",
      "            (ffn_2): Dense(3072 -> 768, linear)\n",
      "            (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "            (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "          )\n",
      "          (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "        )\n",
      "        (4): BERTEncoderCell(\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          (attention_cell): MultiHeadAttentionCell(\n",
      "            (_base_cell): DotProductAttentionCell(\n",
      "              (_dropout_layer): Dropout(p = 0.1, axes=())\n",
      "            )\n",
      "            (proj_query): Dense(768 -> 768, linear)\n",
      "            (proj_key): Dense(768 -> 768, linear)\n",
      "            (proj_value): Dense(768 -> 768, linear)\n",
      "          )\n",
      "          (proj): Dense(768 -> 768, linear)\n",
      "          (ffn): BERTPositionwiseFFN(\n",
      "            (ffn_1): Dense(768 -> 3072, linear)\n",
      "            (activation): GELU()\n",
      "            (ffn_2): Dense(3072 -> 768, linear)\n",
      "            (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "            (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "          )\n",
      "          (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "        )\n",
      "        (5): BERTEncoderCell(\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          (attention_cell): MultiHeadAttentionCell(\n",
      "            (_base_cell): DotProductAttentionCell(\n",
      "              (_dropout_layer): Dropout(p = 0.1, axes=())\n",
      "            )\n",
      "            (proj_query): Dense(768 -> 768, linear)\n",
      "            (proj_key): Dense(768 -> 768, linear)\n",
      "            (proj_value): Dense(768 -> 768, linear)\n",
      "          )\n",
      "          (proj): Dense(768 -> 768, linear)\n",
      "          (ffn): BERTPositionwiseFFN(\n",
      "            (ffn_1): Dense(768 -> 3072, linear)\n",
      "            (activation): GELU()\n",
      "            (ffn_2): Dense(3072 -> 768, linear)\n",
      "            (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "            (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "          )\n",
      "          (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "        )\n",
      "        (6): BERTEncoderCell(\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          (attention_cell): MultiHeadAttentionCell(\n",
      "            (_base_cell): DotProductAttentionCell(\n",
      "              (_dropout_layer): Dropout(p = 0.1, axes=())\n",
      "            )\n",
      "            (proj_query): Dense(768 -> 768, linear)\n",
      "            (proj_key): Dense(768 -> 768, linear)\n",
      "            (proj_value): Dense(768 -> 768, linear)\n",
      "          )\n",
      "          (proj): Dense(768 -> 768, linear)\n",
      "          (ffn): BERTPositionwiseFFN(\n",
      "            (ffn_1): Dense(768 -> 3072, linear)\n",
      "            (activation): GELU()\n",
      "            (ffn_2): Dense(3072 -> 768, linear)\n",
      "            (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "            (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "          )\n",
      "          (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "        )\n",
      "        (7): BERTEncoderCell(\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          (attention_cell): MultiHeadAttentionCell(\n",
      "            (_base_cell): DotProductAttentionCell(\n",
      "              (_dropout_layer): Dropout(p = 0.1, axes=())\n",
      "            )\n",
      "            (proj_query): Dense(768 -> 768, linear)\n",
      "            (proj_key): Dense(768 -> 768, linear)\n",
      "            (proj_value): Dense(768 -> 768, linear)\n",
      "          )\n",
      "          (proj): Dense(768 -> 768, linear)\n",
      "          (ffn): BERTPositionwiseFFN(\n",
      "            (ffn_1): Dense(768 -> 3072, linear)\n",
      "            (activation): GELU()\n",
      "            (ffn_2): Dense(3072 -> 768, linear)\n",
      "            (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "            (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "          )\n",
      "          (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "        )\n",
      "        (8): BERTEncoderCell(\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          (attention_cell): MultiHeadAttentionCell(\n",
      "            (_base_cell): DotProductAttentionCell(\n",
      "              (_dropout_layer): Dropout(p = 0.1, axes=())\n",
      "            )\n",
      "            (proj_query): Dense(768 -> 768, linear)\n",
      "            (proj_key): Dense(768 -> 768, linear)\n",
      "            (proj_value): Dense(768 -> 768, linear)\n",
      "          )\n",
      "          (proj): Dense(768 -> 768, linear)\n",
      "          (ffn): BERTPositionwiseFFN(\n",
      "            (ffn_1): Dense(768 -> 3072, linear)\n",
      "            (activation): GELU()\n",
      "            (ffn_2): Dense(3072 -> 768, linear)\n",
      "            (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "            (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "          )\n",
      "          (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "        )\n",
      "        (9): BERTEncoderCell(\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          (attention_cell): MultiHeadAttentionCell(\n",
      "            (_base_cell): DotProductAttentionCell(\n",
      "              (_dropout_layer): Dropout(p = 0.1, axes=())\n",
      "            )\n",
      "            (proj_query): Dense(768 -> 768, linear)\n",
      "            (proj_key): Dense(768 -> 768, linear)\n",
      "            (proj_value): Dense(768 -> 768, linear)\n",
      "          )\n",
      "          (proj): Dense(768 -> 768, linear)\n",
      "          (ffn): BERTPositionwiseFFN(\n",
      "            (ffn_1): Dense(768 -> 3072, linear)\n",
      "            (activation): GELU()\n",
      "            (ffn_2): Dense(3072 -> 768, linear)\n",
      "            (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "            (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "          )\n",
      "          (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "        )\n",
      "        (10): BERTEncoderCell(\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          (attention_cell): MultiHeadAttentionCell(\n",
      "            (_base_cell): DotProductAttentionCell(\n",
      "              (_dropout_layer): Dropout(p = 0.1, axes=())\n",
      "            )\n",
      "            (proj_query): Dense(768 -> 768, linear)\n",
      "            (proj_key): Dense(768 -> 768, linear)\n",
      "            (proj_value): Dense(768 -> 768, linear)\n",
      "          )\n",
      "          (proj): Dense(768 -> 768, linear)\n",
      "          (ffn): BERTPositionwiseFFN(\n",
      "            (ffn_1): Dense(768 -> 3072, linear)\n",
      "            (activation): GELU()\n",
      "            (ffn_2): Dense(3072 -> 768, linear)\n",
      "            (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "            (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "          )\n",
      "          (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "        )\n",
      "        (11): BERTEncoderCell(\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          (attention_cell): MultiHeadAttentionCell(\n",
      "            (_base_cell): DotProductAttentionCell(\n",
      "              (_dropout_layer): Dropout(p = 0.1, axes=())\n",
      "            )\n",
      "            (proj_query): Dense(768 -> 768, linear)\n",
      "            (proj_key): Dense(768 -> 768, linear)\n",
      "            (proj_value): Dense(768 -> 768, linear)\n",
      "          )\n",
      "          (proj): Dense(768 -> 768, linear)\n",
      "          (ffn): BERTPositionwiseFFN(\n",
      "            (ffn_1): Dense(768 -> 3072, linear)\n",
      "            (activation): GELU()\n",
      "            (ffn_2): Dense(3072 -> 768, linear)\n",
      "            (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "            (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "          )\n",
      "          (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (word_embed): HybridSequential(\n",
      "      (0): Embedding(30522 -> 768, float32)\n",
      "      (1): Dropout(p = 0.1, axes=())\n",
      "    )\n",
      "    (token_type_embed): HybridSequential(\n",
      "      (0): Embedding(2 -> 768, float32)\n",
      "      (1): Dropout(p = 0.1, axes=())\n",
      "    )\n",
      "    (pooler): Dense(768 -> 768, Activation(tanh))\n",
      "  )\n",
      "  (classifier): HybridSequential(\n",
      "    (0): Dense(None -> 2, linear)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "ctx = d2l.try_all_gpus()\n",
    "bert_base, vocabulary = nlp.model.get_model('bert_12_768_12',\n",
    "                                            dataset_name='book_corpus_wiki_en_uncased',\n",
    "                                            pretrained=True, ctx=ctx,\n",
    "                                            use_decoder=False, use_classifier=False)\n",
    "loss_fn = mx.gluon.loss.SoftmaxCELoss()\n",
    "net = nlp.model.BERTClassifier(bert_base, 2)\n",
    "net.classifier.initialize(ctx=ctx)\n",
    "net.hybridize()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "To use the pre-trained BERT model, we need to:\n",
    "- tokenize the inputs into words,\n",
    "- insert [CLS] at the beginning of a sentence, \n",
    "- insert [SEP] at the end of a sentence, and\n",
    "- generate segment ids\n",
    "\n",
    "### Data Transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "We again use the IMDB dataset, but for this time, downloading using the GluonNLP data API. We then use the transform API to transform the raw scores to positive labels and negative labels. \n",
    "To process sentences with BERT-style '[CLS]', '[SEP]' tokens, you can use `data.BERTSentenceTransform` API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-26T22:44:57.188028Z",
     "start_time": "2019-07-26T22:44:57.181395Z"
    },
    "attributes": {
     "classes": [],
     "id": "",
     "n": "15"
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "train_dataset_raw = nlp.data.IMDB('train')\n",
    "test_dataset_raw = nlp.data.IMDB('test')\n",
    "\n",
    "tokenizer = nlp.data.BERTTokenizer(vocabulary)\n",
    "transform = nlp.data.BERTSentenceTransform(tokenizer, max_seq_length=128, pad=False, pair=False)\n",
    "\n",
    "def transform_fn(data):\n",
    "    text, label = data\n",
    "    # transform label into position / negative\n",
    "    label = 1 if label >= 5 else 0\n",
    "    data, length, segment_type = transform([text])\n",
    "    return data.astype('float32'), length.astype('float32'), segment_type.astype('float32'), label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-26T22:44:57.197310Z",
     "start_time": "2019-07-26T22:44:57.189448Z"
    },
    "attributes": {
     "classes": [],
     "id": "",
     "n": "16"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original sentence = \n",
      "Bromwell High is a cartoon comedy. It ran at the same time as some other programs about school life, such as \"Teachers\". My 35 years in the teaching profession lead me to believe that Bromwell High's satire is much closer to reality than is \"Teachers\". The scramble to survive financially, the insightful students who can see right through their pathetic teachers' pomp, the pettiness of the whole situation, all remind me of the schools I knew and their students. When I saw the episode in which a student repeatedly tried to burn down the school, I immediately recalled ......... at .......... High. A classic line: INSPECTOR: I'm here to sack one of your teachers. STUDENT: Welcome to Bromwell High. I expect that many adults of my age think that Bromwell High is far fetched. What a pity that it isn't!\n",
      "word indices = \n",
      "[    2 22953  2213  4381  2152  2003  1037  9476  4038  1012  2009  2743\n",
      "  2012  1996  2168  2051  2004  2070  2060  3454  2055  2082  2166  1010\n",
      "  2107  2004  1000  5089  1000  1012  2026  3486  2086  1999  1996  4252\n",
      "  9518  2599  2033  2000  2903  2008 22953  2213  4381  2152  1005  1055\n",
      " 18312  2003  2172  3553  2000  4507  2084  2003  1000  5089  1000  1012\n",
      "  1996 25740  2000  5788 13732  1010  1996 12369  3993  2493  2040  2064\n",
      "  2156  2157  2083  2037 17203  5089  1005 13433  8737  1010  1996  9004\n",
      " 10196  4757  1997  1996  2878  3663  1010  2035 10825  2033  1997  1996\n",
      "  2816  1045  2354  1998  2037  2493  1012  2043  1045  2387  1996  2792\n",
      "  1999  2029  1037  3076  8385  2699  2000  6402  2091  1996  2082  1010\n",
      "  1045  3202  7383  1012  1012  1012  1012     3]\n"
     ]
    }
   ],
   "source": [
    "train_dataset = train_dataset_raw.transform(transform_fn)\n",
    "test_dataset = test_dataset_raw.transform(transform_fn)\n",
    "\n",
    "data, length, _, label = train_dataset[0]\n",
    "print('original sentence = \\n{}'.format(train_dataset_raw[0][0]))\n",
    "print('word indices = \\n{}'.format(data.astype('int32')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Let's Train the Model!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Now we have all the pieces to put together, and we can finally start fine-tuning the\n",
    "model with a few epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-26T22:53:53.156467Z",
     "start_time": "2019-07-26T22:44:57.484026Z"
    },
    "attributes": {
     "classes": [],
     "id": "",
     "n": "19"
    },
    "scrolled": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0, Train Acc 0.5546875, Train Loss 0.7107145041227341\n",
      "Batch 25, Train Acc 0.6682692307692307, Train Loss 0.5863065511847918\n",
      "Batch 50, Train Acc 0.7225796568627451, Train Loss 0.5350419924977947\n",
      "Batch 75, Train Acc 0.7552425986842105, Train Loss 0.49032151713771255\n",
      "Batch 100, Train Acc 0.773128094059406, Train Loss 0.46394537477800163\n",
      "Batch 125, Train Acc 0.7899925595238095, Train Loss 0.43633691333825625\n",
      "Batch 150, Train Acc 0.8017901490066225, Train Loss 0.4163205347560494\n",
      "Batch 175, Train Acc 0.8115678267045454, Train Loss 0.3999007060615854\n",
      "Epoch 0, Train Acc 0.81832, Train Loss 0.38640599939687065\n",
      "Test Acc 0.8814174885652504,\n",
      "Elapsed time (sec):  245.78527092933655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process ForkPoolWorker-8:\n",
      "Process ForkPoolWorker-7:\n",
      "Process ForkPoolWorker-4:\n",
      "Process ForkPoolWorker-1:\n",
      "Process ForkPoolWorker-5:\n",
      "Process ForkPoolWorker-3:\n",
      "Process ForkPoolWorker-6:\n",
      "Process ForkPoolWorker-2:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "batch_size = args.batch_size * len(ctx)\n",
    "train_data, test_data = utils.get_dataloader(batch_size, vocabulary, train_dataset, test_dataset)\n",
    "tick = time.time()\n",
    "utils.fit(net, train_data, test_data, args.num_epochs, args.lr, ctx, loss_fn)\n",
    "tock = time.time()\n",
    "print('Elapsed time (sec): ', tock-tick)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-26T22:53:53.190988Z",
     "start_time": "2019-07-26T22:53:53.159462Z"
    },
    "attributes": {
     "classes": [],
     "id": "",
     "n": "20"
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'positive'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utils.predict_sentiment(net, ctx, vocabulary, tokenizer, 'this movie is so great')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Deploy on SageMaker\n",
    "### Save Model Checkpoint and Upload to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model was uploaded to s3://sagemaker-us-east-1-397262719838/model/model.tar.gz\n"
     ]
    }
   ],
   "source": [
    "net.export('checkpoint')\n",
    "with open('vocab.json', 'w') as f:\n",
    "    f.write(vocabulary.to_json())\n",
    "with tarfile.open(\"model.tar.gz\", \"w:gz\") as tar:\n",
    "    tar.add(\"checkpoint-0000.params\") # parameters\n",
    "    tar.add(\"checkpoint-symbol.json\") # model definition\n",
    "    tar.add(\"vocab.json\")             # vocabulary\n",
    "\n",
    "session = sagemaker.Session()\n",
    "uploaded_model = session.upload_data(path='model.tar.gz', key_prefix='model')\n",
    "s3_path = 's3://' + session.default_bucket() + '/model/model.tar.gz'\n",
    "print(\"Model was uploaded to\", s3_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## serve.py - the Code for Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import inspect\n",
    "from serve import model_fn, transform_fn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### model_fn to Deserialize Checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def model_fn(model_dir):\n",
      "    \"\"\"\n",
      "    Load the gluon model. Called once when hosting service starts.\n",
      "    :param: model_dir The directory where model files are stored.\n",
      "    :return: a Gluon model and the vocabulary\n",
      "    \"\"\"\n",
      "    prefix = 'checkpoint'\n",
      "    net = mx.gluon.nn.SymbolBlock.imports(prefix + '-symbol.json',\n",
      "                                          ['data0', 'data1', 'data2'],\n",
      "                                          prefix + '-0000.params')\n",
      "    net.load_parameters('%s/'%model_dir + prefix + '-0000.params', ctx=mx.cpu())\n",
      "    vocab_json = open('%s/vocab.json'%model_dir).read()\n",
      "    vocab = nlp.vocab.BERTVocab.from_json(vocab_json)\n",
      "    return net, vocab\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(inspect.getsource(model_fn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### transform_fn to Run Model Inference for an Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def transform_fn(model, data, input_content_type, output_content_type):\n",
      "    \"\"\"\n",
      "    Transform a request using the Gluon model. Called once per request.\n",
      "    :param net: The Gluon model and the vocab\n",
      "    :param data: The request payload.\n",
      "    :param input_content_type: The request content type.\n",
      "    :param output_content_type: The (desired) response content type.\n",
      "    :return: response payload and content type.\n",
      "    \"\"\"\n",
      "    net, vocabulary = model\n",
      "    sentence = json.loads(data)\n",
      "    tokenizer = nlp.data.BERTTokenizer(vocabulary)\n",
      "    result = predict_sentiment(net, mx.cpu(), vocabulary, tokenizer, sentence)\n",
      "    response_body = json.dumps(result)\n",
      "    return response_body, output_content_type\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(inspect.getsource(transform_fn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Build a Docker Container for Serving"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Let's prepare a docker container with all the dependencies required for model inference. Here we build a docker container based on the SageMaker MXNet inference container, and you can find the list of all available inference containers at https://docs.aws.amazon.com/sagemaker/latest/dg/pre-built-containers-frameworks-deep-learning.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FROM 763104351884.dkr.ecr.us-east-1.amazonaws.com/mxnet-inference:1.4.1-cpu-py3\r\n",
      "\r\n",
      "RUN pip install mxnet-mkl d2l https://github.com/dmlc/gluon-nlp/tarball/master -U --user\r\n",
      "\r\n",
      "COPY *.py /opt/ml/model/code/"
     ]
    }
   ],
   "source": [
    "!cat Dockerfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "And login to elastic container registry service to register the container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING! Using --password via the CLI is insecure. Use --password-stdin.\n",
      "WARNING! Your password will be stored unencrypted in /home/ec2-user/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n",
      "Login Succeeded\n",
      "Sending build context to Docker daemon  845.5MB\n",
      "Step 1/3 : FROM 763104351884.dkr.ecr.us-east-1.amazonaws.com/mxnet-inference:1.4.1-cpu-py3\n",
      " ---> 9a2aa1c6893e\n",
      "Step 2/3 : RUN pip install mxnet-mkl d2l https://github.com/dmlc/gluon-nlp/tarball/master -U --user\n",
      " ---> Using cache\n",
      " ---> c268be8e81fb\n",
      "Step 3/3 : COPY *.py /opt/ml/model/code/\n",
      " ---> Using cache\n",
      " ---> eb923b16f903\n",
      "Successfully built eb923b16f903\n",
      "Successfully tagged 397262719838.dkr.ecr.us-east-1.amazonaws.com/haibin-test:inference\n",
      "The push refers to repository [397262719838.dkr.ecr.us-east-1.amazonaws.com/haibin-test]\n",
      "\n",
      "\u001b[1B1c1c1537: Preparing \n",
      "\u001b[1B96fe5fd5: Preparing \n",
      "\u001b[1B7d751557: Preparing \n",
      "\u001b[1B513002ec: Preparing \n",
      "\u001b[1Bb180e24b: Preparing \n",
      "\u001b[1B32742db8: Preparing \n",
      "\u001b[1B32c12889: Preparing \n",
      "\u001b[1Bf7480aac: Preparing \n",
      "\u001b[1Be6c202db: Preparing \n",
      "\u001b[1B937fef50: Preparing \n",
      "\u001b[1Bb1acf2ed: Preparing \n",
      "\u001b[1B204a31d2: Preparing \n",
      "\u001b[8B32742db8: Waiting g \n",
      "\u001b[8B32c12889: Waiting g \n",
      "\u001b[6B937fef50: Waiting g \n",
      "\u001b[2B7de5faec: Layer already exists K\u001b[9A\u001b[1K\u001b[K\u001b[5A\u001b[1K\u001b[K\u001b[2A\u001b[1K\u001b[Kinference: digest: sha256:a10fe6540da7352ca07404c5703259c6047bc925f08fb6cc1cbc92aafad3156d size: 3666\n"
     ]
    }
   ],
   "source": [
    "!$(aws ecr get-login --no-include-email --region us-east-1)\n",
    "!docker build -t 397262719838.dkr.ecr.us-east-1.amazonaws.com/haibin-test:inference . -f Dockerfile\n",
    "!docker push 397262719838.dkr.ecr.us-east-1.amazonaws.com/haibin-test:inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Use SageMaker SDK to Deploy the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "We create a MXNet model which can be deployed later, by specifying the docker image, and entry point for the inference code. If serve.py does not work, use dummy_hosting_module.py for debugging purpose. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from sagemaker.mxnet.model import MXNetModel\n",
    "sagemaker_model = MXNetModel(model_data=s3_path,\n",
    "                             image='397262719838.dkr.ecr.us-east-1.amazonaws.com/haibin-test:inference',\n",
    "                             role=sagemaker.get_execution_role(),\n",
    "                             py_version='py3',\n",
    "                             framework_version='1.4.1',\n",
    "                             entry_point='serve.py',\n",
    "                             source_dir='.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "We use 'local' mode to test our deployment code, where the inference happens on the current instance.\n",
    "If you are ready to deploy the model on a new instance, change the `instance_type` argument to values such as `ml.c4.xlarge`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attaching to tmpqsvetadr_algo-1-fsz17_1\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:15,836 [INFO ] main com.amazonaws.ml.mms.ModelServer - \n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m MMS Home: /usr/local/lib/python3.6/site-packages\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m Current directory: /\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m Temp directory: /home/model-server/tmp\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m Number of GPUs: 0\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m Number of CPUs: 32\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m Max heap size: 27305 M\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m Python executable: /usr/local/bin/python3.6\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m Config file: /etc/sagemaker-mms.properties\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m Inference address: http://0.0.0.0:8080\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m Management address: http://127.0.0.1:8081\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m Model Store: /.sagemaker/mms/models\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m Initial Models: ALL\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m Log dir: /logs\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m Metrics dir: /logs\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m Netty threads: 0\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m Netty client threads: 0\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m Default workers per model: 32\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m Blacklist Regex: N/A\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m Maximum Response Size: 6553500\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m Maximum Request Size: 6553500\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:15,889 [INFO ] main com.amazonaws.ml.mms.wlm.ModelManager - Model model loaded.\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:16,025 [INFO ] main com.amazonaws.ml.mms.ModelServer - Initialize Inference server with: EpollServerSocketChannel.\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:16,057 [INFO ] W-9010-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Listening on port: /home/model-server/tmp/.mms.sock.9010\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:16,058 [INFO ] W-9010-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - [PID]178\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:16,061 [INFO ] W-9010-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - MXNet worker started.\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:16,061 [INFO ] W-9010-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Python runtime: 3.6.8\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:16,086 [INFO ] W-9008-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Listening on port: /home/model-server/tmp/.mms.sock.9008\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:16,087 [INFO ] W-9008-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - [PID]173\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:16,089 [INFO ] W-9001-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Listening on port: /home/model-server/tmp/.mms.sock.9001\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:16,090 [INFO ] W-9001-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - [PID]177\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:16,090 [INFO ] W-9007-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Listening on port: /home/model-server/tmp/.mms.sock.9007\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:16,090 [INFO ] W-9002-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Listening on port: /home/model-server/tmp/.mms.sock.9002\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:16,091 [INFO ] W-9007-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - [PID]172\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:16,091 [INFO ] W-9002-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - [PID]169\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:16,094 [INFO ] W-9010-model com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.mms.sock.9010\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:16,096 [INFO ] W-9004-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Listening on port: /home/model-server/tmp/.mms.sock.9004\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:16,097 [INFO ] W-9004-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - [PID]171\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:16,097 [INFO ] W-9006-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Listening on port: /home/model-server/tmp/.mms.sock.9006\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:16,097 [INFO ] W-9006-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - [PID]174\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:16,099 [INFO ] W-9002-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - MXNet worker started.\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:16,100 [INFO ] W-9007-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - MXNet worker started.\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:16,100 [INFO ] W-9007-model com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.mms.sock.9007\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:16,100 [INFO ] W-9007-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Python runtime: 3.6.8\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:16,100 [INFO ] W-9002-model com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.mms.sock.9002\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:16,100 [INFO ] W-9002-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Python runtime: 3.6.8\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:16,103 [INFO ] W-9005-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Listening on port: /home/model-server/tmp/.mms.sock.9005\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:16,103 [INFO ] W-9023-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Listening on port: /home/model-server/tmp/.mms.sock.9023\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:16,103 [INFO ] W-9005-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - [PID]175\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:16,104 [INFO ] W-9023-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - [PID]215\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:16,104 [INFO ] W-9001-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - MXNet worker started.\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:16,105 [INFO ] W-9001-model com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.mms.sock.9001\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:16,104 [INFO ] W-9008-model com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.mms.sock.9008\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:16,105 [INFO ] W-9001-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Python runtime: 3.6.8\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:16,105 [INFO ] W-9023-model com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.mms.sock.9023\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:16,104 [INFO ] W-9008-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - MXNet worker started.\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:16,105 [INFO ] W-9023-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - MXNet worker started.\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:16,105 [INFO ] W-9008-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Python runtime: 3.6.8\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:16,105 [INFO ] W-9023-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Python runtime: 3.6.8\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:16,108 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Listening on port: /home/model-server/tmp/.mms.sock.9000\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:16,108 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - [PID]168\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:16,111 [INFO ] W-9005-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - MXNet worker started.\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:16,111 [INFO ] W-9005-model com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.mms.sock.9005\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:16,115 [INFO ] W-9005-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Python runtime: 3.6.8\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:16,115 [INFO ] W-9006-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - MXNet worker started.\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:16,116 [INFO ] W-9006-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Python runtime: 3.6.8\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:16,115 [INFO ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.mms.sock.9000\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:16,115 [INFO ] W-9004-model com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.mms.sock.9004\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:16,115 [INFO ] W-9006-model com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.mms.sock.9006\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:16,115 [INFO ] W-9004-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - MXNet worker started.\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:16,115 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - MXNet worker started.\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:16,117 [INFO ] W-9004-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Python runtime: 3.6.8\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:16,117 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Python runtime: 3.6.8\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:16,125 [INFO ] W-9003-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Listening on port: /home/model-server/tmp/.mms.sock.9003\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:16,126 [INFO ] W-9003-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - [PID]209\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:16,126 [INFO ] W-9003-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - MXNet worker started.\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:16,126 [INFO ] W-9003-model com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.mms.sock.9003\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:16,126 [INFO ] W-9003-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Python runtime: 3.6.8\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:16,126 [INFO ] W-9016-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Listening on port: /home/model-server/tmp/.mms.sock.9016\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:16,127 [INFO ] W-9016-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - [PID]221\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:16,127 [INFO ] W-9016-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - MXNet worker started.\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:16,127 [INFO ] W-9016-model com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.mms.sock.9016\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:16,127 [INFO ] W-9016-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Python runtime: 3.6.8\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:16,130 [INFO ] W-9025-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Listening on port: /home/model-server/tmp/.mms.sock.9025\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:16,130 [INFO ] W-9025-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - [PID]216\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:16,130 [INFO ] W-9025-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - MXNet worker started.\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:16,130 [INFO ] W-9025-model com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.mms.sock.9025\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:16,130 [INFO ] W-9025-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Python runtime: 3.6.8\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:16,135 [INFO ] W-9019-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Listening on port: /home/model-server/tmp/.mms.sock.9019\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:16,136 [INFO ] W-9019-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - [PID]214\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:16,136 [INFO ] W-9019-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - MXNet worker started.\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:16,136 [INFO ] W-9019-model com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.mms.sock.9019\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:16,136 [INFO ] W-9019-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Python runtime: 3.6.8\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:16,136 [INFO ] W-9014-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Listening on port: /home/model-server/tmp/.mms.sock.9014\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:16,137 [INFO ] W-9014-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - [PID]225\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:16,137 [INFO ] W-9014-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - MXNet worker started.\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:16,137 [INFO ] W-9014-model com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.mms.sock.9014\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:16,137 [INFO ] W-9014-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Python runtime: 3.6.8\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:16,140 [INFO ] W-9009-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Listening on port: /home/model-server/tmp/.mms.sock.9009\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:16,140 [INFO ] W-9009-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - [PID]224\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:16,140 [INFO ] W-9009-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - MXNet worker started.\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:16,140 [INFO ] W-9009-model com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.mms.sock.9009\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:16,140 [INFO ] W-9009-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Python runtime: 3.6.8\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:16,142 [INFO ] W-9015-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Listening on port: /home/model-server/tmp/.mms.sock.9015\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:16,142 [INFO ] W-9015-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - [PID]212\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:16,143 [INFO ] W-9015-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - MXNet worker started.\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:16,143 [INFO ] W-9021-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Listening on port: /home/model-server/tmp/.mms.sock.9021\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:16,143 [INFO ] W-9015-model com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.mms.sock.9015\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:16,143 [INFO ] W-9015-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Python runtime: 3.6.8\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:16,143 [INFO ] W-9021-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - [PID]211\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:16,143 [INFO ] W-9021-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - MXNet worker started.\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:16,143 [INFO ] W-9021-model com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.mms.sock.9021\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:16,143 [INFO ] W-9021-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Python runtime: 3.6.8\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:16,144 [INFO ] W-9013-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Listening on port: /home/model-server/tmp/.mms.sock.9013\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:16,144 [INFO ] W-9026-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Listening on port: /home/model-server/tmp/.mms.sock.9026\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:16,144 [INFO ] W-9013-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - [PID]226\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:16,144 [INFO ] W-9026-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - [PID]213\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:16,144 [INFO ] W-9013-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - MXNet worker started.\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:16,144 [INFO ] W-9026-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - MXNet worker started.\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:16,144 [INFO ] W-9026-model com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.mms.sock.9026\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:16,144 [INFO ] W-9013-model com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.mms.sock.9013\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:16,144 [INFO ] W-9012-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Listening on port: /home/model-server/tmp/.mms.sock.9012\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:16,145 [INFO ] W-9012-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - [PID]223\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:16,145 [INFO ] W-9012-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - MXNet worker started.\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:16,144 [INFO ] W-9013-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Python runtime: 3.6.8\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:16,145 [INFO ] W-9012-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Python runtime: 3.6.8\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:16,145 [INFO ] W-9012-model com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.mms.sock.9012\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:16,146 [INFO ] W-9020-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Listening on port: /home/model-server/tmp/.mms.sock.9020\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:16,146 [INFO ] W-9029-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Listening on port: /home/model-server/tmp/.mms.sock.9029\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:16,145 [INFO ] W-9017-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Listening on port: /home/model-server/tmp/.mms.sock.9017\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:16,146 [INFO ] W-9020-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - [PID]220\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:16,146 [INFO ] W-9029-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - [PID]236\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:16,144 [INFO ] W-9026-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Python runtime: 3.6.8\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:16,145 [INFO ] W-9011-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Listening on port: /home/model-server/tmp/.mms.sock.9011\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:16,146 [INFO ] W-9027-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Listening on port: /home/model-server/tmp/.mms.sock.9027\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:16,146 [INFO ] W-9018-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Listening on port: /home/model-server/tmp/.mms.sock.9018\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:16,146 [INFO ] W-9024-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Listening on port: /home/model-server/tmp/.mms.sock.9024\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:16,146 [INFO ] W-9029-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - MXNet worker started.\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:16,147 [INFO ] W-9018-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - [PID]222\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:16,146 [INFO ] W-9017-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - [PID]217\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:16,147 [INFO ] W-9029-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Python runtime: 3.6.8\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:16,147 [INFO ] W-9018-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - MXNet worker started.\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:16,147 [INFO ] W-9017-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - MXNet worker started.\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:16,146 [INFO ] W-9028-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Listening on port: /home/model-server/tmp/.mms.sock.9028\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:16,147 [INFO ] W-9017-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Python runtime: 3.6.8\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:16,146 [INFO ] W-9022-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Listening on port: /home/model-server/tmp/.mms.sock.9022\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:16,147 [INFO ] W-9028-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - [PID]231\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:16,146 [INFO ] W-9020-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - MXNet worker started.\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:16,146 [INFO ] W-9020-model com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.mms.sock.9020\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:16,146 [INFO ] W-9029-model com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.mms.sock.9029\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:16,149 [INFO ] W-9020-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Python runtime: 3.6.8\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:16,146 [INFO ] W-9011-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - [PID]227\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:16,147 [INFO ] W-9027-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - [PID]219\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:16,147 [INFO ] W-9024-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - [PID]210\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:16,147 [INFO ] W-9018-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Python runtime: 3.6.8\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:16,147 [INFO ] W-9017-model com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.mms.sock.9017\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:16,147 [INFO ] W-9018-model com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.mms.sock.9018\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:16,147 [INFO ] W-9022-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - [PID]218\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:16,149 [INFO ] W-9022-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - MXNet worker started.\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:16,147 [INFO ] W-9028-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - MXNet worker started.\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:16,147 [INFO ] W-9028-model com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.mms.sock.9028\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:16,150 [INFO ] W-9028-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Python runtime: 3.6.8\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:16,149 [INFO ] W-9022-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Python runtime: 3.6.8\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:16,149 [INFO ] W-9022-model com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.mms.sock.9022\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:16,149 [INFO ] W-9027-model com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.mms.sock.9027\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:16,149 [INFO ] W-9024-model com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.mms.sock.9024\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:16,149 [INFO ] W-9027-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - MXNet worker started.\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:16,149 [INFO ] W-9024-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - MXNet worker started.\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:16,150 [INFO ] W-9027-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Python runtime: 3.6.8\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:16,149 [INFO ] W-9011-model com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.mms.sock.9011\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:16,150 [INFO ] W-9024-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Python runtime: 3.6.8\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:16,149 [INFO ] W-9011-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - MXNet worker started.\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:16,150 [INFO ] W-9011-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Python runtime: 3.6.8\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:16,161 [INFO ] main com.amazonaws.ml.mms.ModelServer - Inference API bind to: http://0.0.0.0:8080\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:16,162 [INFO ] main com.amazonaws.ml.mms.ModelServer - Initialize Management server with: EpollServerSocketChannel.\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:16,163 [INFO ] W-9023-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.mms.sock.9023.\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:16,163 [INFO ] W-9019-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.mms.sock.9019.\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:16,163 [INFO ] W-9005-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.mms.sock.9005.\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:16,163 [INFO ] W-9021-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.mms.sock.9021.\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:16,163 [INFO ] W-9012-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.mms.sock.9012.\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:16,163 [INFO ] W-9011-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.mms.sock.9011.\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:16,163 [INFO ] W-9001-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.mms.sock.9001.\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:16,163 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.mms.sock.9000.\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:16,163 [INFO ] W-9008-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.mms.sock.9008.\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:16,163 [INFO ] W-9009-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.mms.sock.9009.\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:16,163 [INFO ] W-9018-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.mms.sock.9018.\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:16,164 [INFO ] W-9004-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.mms.sock.9004.\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:16,164 [INFO ] W-9026-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.mms.sock.9026.\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:16,164 [INFO ] W-9013-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.mms.sock.9013.\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:16,165 [INFO ] W-9003-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.mms.sock.9003.\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:16,165 [INFO ] W-9020-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.mms.sock.9020.\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:16,165 [INFO ] W-9025-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.mms.sock.9025.\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:16,165 [INFO ] W-9024-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.mms.sock.9024.\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:16,166 [INFO ] W-9017-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.mms.sock.9017.\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:16,166 [INFO ] W-9010-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.mms.sock.9010.\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:16,166 [INFO ] W-9027-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.mms.sock.9027.\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:16,166 [INFO ] W-9006-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.mms.sock.9006.\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:16,166 [INFO ] W-9028-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.mms.sock.9028.\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:16,166 [INFO ] W-9014-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.mms.sock.9014.\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:16,167 [INFO ] W-9015-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.mms.sock.9015.\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:16,167 [INFO ] W-9029-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.mms.sock.9029.\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:16,168 [INFO ] W-9016-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.mms.sock.9016.\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:16,168 [INFO ] W-9022-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.mms.sock.9022.\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:16,169 [INFO ] W-9002-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.mms.sock.9002.\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:16,169 [INFO ] W-9030-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Listening on port: /home/model-server/tmp/.mms.sock.9030\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:16,169 [INFO ] main com.amazonaws.ml.mms.ModelServer - Management API bind to: http://127.0.0.1:8081\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:16,169 [INFO ] W-9030-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - [PID]277\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:16,169 [INFO ] W-9030-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - MXNet worker started.\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:16,169 [INFO ] W-9030-model com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.mms.sock.9030\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:16,169 [INFO ] W-9030-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Python runtime: 3.6.8\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:16,169 [INFO ] W-9007-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.mms.sock.9007.\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:16,170 [INFO ] W-9030-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.mms.sock.9030.\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m Model server started.\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:16,175 [WARN ] pool-2-thread-1 com.amazonaws.ml.mms.metrics.MetricCollector - worker pid is not available yet.\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:16,197 [INFO ] W-9031-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Listening on port: /home/model-server/tmp/.mms.sock.9031\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:16,197 [INFO ] W-9031-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - [PID]294\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:16,197 [INFO ] W-9031-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - MXNet worker started.\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:16,197 [INFO ] W-9031-model com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.mms.sock.9031\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:16,197 [INFO ] W-9031-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Python runtime: 3.6.8\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:16,212 [INFO ] W-9031-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.mms.sock.9031.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:18,130 [INFO ] pool-1-thread-33 ACCESS_LOG - /172.18.0.1:35958 \"GET /ping HTTP/1.1\" 200 57\r\n",
      "!"
     ]
    }
   ],
   "source": [
    "predictor = sagemaker_model.deploy(initial_instance_count=1, instance_type='local')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:18,264 [INFO ] W-9003-model com.amazonaws.ml.mms.wlm.WorkerThread - Backend response time: 2073\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:18,271 [INFO ] W-9011-model com.amazonaws.ml.mms.wlm.WorkerThread - Backend response time: 2075\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:18,278 [INFO ] W-9029-model com.amazonaws.ml.mms.wlm.WorkerThread - Backend response time: 2083\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:18,292 [INFO ] W-9002-model com.amazonaws.ml.mms.wlm.WorkerThread - Backend response time: 2100\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:18,297 [INFO ] W-9028-model com.amazonaws.ml.mms.wlm.WorkerThread - Backend response time: 2101\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:18,302 [INFO ] W-9026-model com.amazonaws.ml.mms.wlm.WorkerThread - Backend response time: 2111\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:18,309 [WARN ] W-9003-model-stderr com.amazonaws.ml.mms.wlm.WorkerLifeCycle - /root/.local/lib/python3.6/site-packages/mxnet/gluon/block.py:1159: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:18,309 [WARN ] W-9003-model-stderr com.amazonaws.ml.mms.wlm.WorkerLifeCycle - \tdata0: None\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:18,309 [WARN ] W-9003-model-stderr com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   input_sym_arg_type = in_param.infer_type()[0]\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:18,313 [INFO ] W-9019-model com.amazonaws.ml.mms.wlm.WorkerThread - Backend response time: 2115\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:18,328 [INFO ] W-9015-model com.amazonaws.ml.mms.wlm.WorkerThread - Backend response time: 2132\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:18,328 [INFO ] W-9018-model com.amazonaws.ml.mms.wlm.WorkerThread - Backend response time: 2135\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:18,328 [INFO ] W-9014-model com.amazonaws.ml.mms.wlm.WorkerThread - Backend response time: 2132\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:18,332 [INFO ] W-9016-model com.amazonaws.ml.mms.wlm.WorkerThread - Backend response time: 2137\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:18,338 [INFO ] W-9007-model com.amazonaws.ml.mms.wlm.WorkerThread - Backend response time: 2142\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:18,344 [INFO ] W-9013-model com.amazonaws.ml.mms.wlm.WorkerThread - Backend response time: 2148\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:18,345 [INFO ] W-9031-model com.amazonaws.ml.mms.wlm.WorkerThread - Backend response time: 2130\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:18,345 [INFO ] W-9004-model com.amazonaws.ml.mms.wlm.WorkerThread - Backend response time: 2150\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:18,346 [INFO ] W-9025-model com.amazonaws.ml.mms.wlm.WorkerThread - Backend response time: 2151\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:18,354 [INFO ] W-9010-model com.amazonaws.ml.mms.wlm.WorkerThread - Backend response time: 2158\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:18,359 [INFO ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerThread - Backend response time: 2164\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:18,359 [INFO ] W-9005-model com.amazonaws.ml.mms.wlm.WorkerThread - Backend response time: 2163\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:18,360 [INFO ] W-9009-model com.amazonaws.ml.mms.wlm.WorkerThread - Backend response time: 2168\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:18,363 [INFO ] W-9001-model com.amazonaws.ml.mms.wlm.WorkerThread - Backend response time: 2154\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:18,370 [INFO ] W-9027-model com.amazonaws.ml.mms.wlm.WorkerThread - Backend response time: 2179\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:18,374 [INFO ] W-9030-model com.amazonaws.ml.mms.wlm.WorkerThread - Backend response time: 2175\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:18,376 [INFO ] W-9012-model com.amazonaws.ml.mms.wlm.WorkerThread - Backend response time: 2184\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:18,385 [INFO ] W-9022-model com.amazonaws.ml.mms.wlm.WorkerThread - Backend response time: 2189\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:18,386 [INFO ] W-9006-model com.amazonaws.ml.mms.wlm.WorkerThread - Backend response time: 2191\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:18,390 [INFO ] W-9024-model com.amazonaws.ml.mms.wlm.WorkerThread - Backend response time: 2194\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:18,390 [INFO ] W-9021-model com.amazonaws.ml.mms.wlm.WorkerThread - Backend response time: 2194\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:18,417 [INFO ] W-9020-model com.amazonaws.ml.mms.wlm.WorkerThread - Backend response time: 2221\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:18,424 [INFO ] W-9017-model com.amazonaws.ml.mms.wlm.WorkerThread - Backend response time: 2216\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:18,437 [INFO ] W-9023-model com.amazonaws.ml.mms.wlm.WorkerThread - Backend response time: 2225\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:18,496 [INFO ] W-9008-model com.amazonaws.ml.mms.wlm.WorkerThread - Backend response time: 2298\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:19,326 [INFO ] W-9003-model com.amazonaws.ml.mms.wlm.WorkerThread - Backend response time: 1060\n",
      "\n",
      "Prediction output: positive\n",
      "\n",
      "\u001b[36malgo-1-fsz17_1  |\u001b[0m 2019-10-09 18:31:19,326 [INFO ] W-9003-model ACCESS_LOG - /172.18.0.1:35964 \"POST /invocations HTTP/1.1\" 200 1155\n",
      "\n"
     ]
    }
   ],
   "source": [
    "output = predictor.predict('The model is deployed. Great!')\n",
    "print('\\nPrediction output: {}\\n\\n'.format(output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Clean Up\n",
    "\n",
    "Remove the endpoint after we are done. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gracefully stopping... (press Ctrl+C again to force)\n"
     ]
    }
   ],
   "source": [
    "predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "## Conclusion\n",
    "\n",
    "In this tutorial, we showed how to fine-tune sentiment analysis model with pre-trained BERT parameters. In GluonNLP, this can be done with such few, simple steps. All we did was apply a BERT-style data transformation to pre-process the data, automatically download the pre-trained model, and feed the transformed data into the model, all within 50 lines of code!\n",
    "\n",
    "For more fine-tuning scripts, visit the [BERT model zoo webpage](http://gluon-nlp.mxnet.io/model_zoo/bert/index.html).\n",
    "\n",
    "## References\n",
    "\n",
    "[1] Devlin, Jacob, et al. \"Bert:\n",
    "Pre-training of deep\n",
    "bidirectional transformers for language understanding.\"\n",
    "arXiv preprint\n",
    "arXiv:1810.04805 (2018).\n",
    "\n",
    "[2] Dolan, William B., and Chris\n",
    "Brockett.\n",
    "\"Automatically constructing a corpus of sentential paraphrases.\"\n",
    "Proceedings of\n",
    "the Third International Workshop on Paraphrasing (IWP2005). 2005.\n",
    "\n",
    "[3] Peters,\n",
    "Matthew E., et al. \"Deep contextualized word representations.\" arXiv\n",
    "preprint\n",
    "arXiv:1802.05365 (2018).\n",
    "\n",
    "[4] Hendrycks, Dan, and Kevin Gimpel. \"Gaussian error linear units (gelus).\" arXiv preprint arXiv:1606.08415 (2016).\n",
    "\n",
    "For fine-tuning, we only need to initialize the last classifier layer from scratch. The other layers are already initialized from the pre-trained model weights."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "conda_mxnet_p36",
   "language": "python",
   "name": "conda_mxnet_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
