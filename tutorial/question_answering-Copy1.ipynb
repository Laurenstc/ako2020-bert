{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Hands-on: Training and deploying Question Answering with BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pre-trained language representations have been shown to improve many downstream NLP tasks such as question answering, and natural language inference. Devlin, Jacob, et al proposed BERT [1] (Bidirectional Encoder Representations from Transformers), which fine-tunes deep bidirectional representations on a wide range of tasks with minimal task-specific parameters, and obtained state- of-the-art results.\n",
    "\n",
    "In this tutorial, we will focus on adapting the BERT model for the question answering task on the SQuAD dataset. Specifically, we will:\n",
    "\n",
    "- understand how to pre-process the SQuAD dataset to leverage the learnt representation in BERT,\n",
    "- adapt the BERT model to the question answering task, and\n",
    "- load a trained model to perform inference on the SQuAD dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keras-mxnet                        2.2.4.2       \n",
      "mxnet-cu101                        1.6.0b20191122\n",
      "mxnet-model-server                 1.0.5         \n",
      "\u001b[33mYou are using pip version 10.0.1, however version 19.3.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "gluonnlp                           0.9.0.dev0    \n",
      "\u001b[33mYou are using pip version 10.0.1, however version 19.3.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# this notebook requires mxnet-cu101 >= 1.6.0b20191102, gluonnlp >= 0.8.1\n",
    "# we can create a sagemaker notebook instance with the lifecycle configuration file: sagemaker-lifecycle.config\n",
    "!pip list | grep mxnet\n",
    "!pip list | grep gluonnlp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Load MXNet and GluonNLP\n",
    "\n",
    "We first import the libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse, collections, time, logging\n",
    "import json\n",
    "import os\n",
    "import io\n",
    "import copy\n",
    "import random\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import gluonnlp as nlp\n",
    "import mxnet as mx\n",
    "import bert\n",
    "import qa_utils\n",
    "\n",
    "from gluonnlp.data import SQuAD\n",
    "from bert.model.qa import BertForQALoss, BertForQA\n",
    "from bert.data.qa import SQuADTransform, preprocess_dataset\n",
    "from bert.bert_qa_evaluate import get_F1_EM, predict, PredResult\n",
    "\n",
    "# Hyperparameters\n",
    "parser = argparse.ArgumentParser('BERT finetuning')\n",
    "parser.add_argument('--epochs', type=int, default=3)\n",
    "parser.add_argument('--batch_size', default=32)\n",
    "parser.add_argument('--num_epochs', default=1)\n",
    "parser.add_argument('--lr', default=5e-5)\n",
    "\n",
    "parser.add_argument('--output_dir',\n",
    "                    type=str,\n",
    "                    default='./output_dir',\n",
    "                    help='The output directory where the model params will be written.'\n",
    "                    ' default is ./output_dir')\n",
    "parser.add_argument('--test_batch_size',\n",
    "                    type=int,\n",
    "                    default=24,\n",
    "                    help='Test batch size. default is 24')\n",
    "parser.add_argument('--optimizer',\n",
    "                    type=str,\n",
    "                    default='bertadam',\n",
    "                    help='optimization algorithm. default is bertadam')\n",
    "parser.add_argument('--accumulate',\n",
    "                    type=int,\n",
    "                    default=None,\n",
    "                    help='The number of batches for '\n",
    "                    'gradients accumulation to simulate large batch size. Default is None')\n",
    "parser.add_argument('--warmup_ratio',\n",
    "                    type=float,\n",
    "                    default=0.1,\n",
    "                    help='ratio of warmup steps that linearly increase learning rate from '\n",
    "                    '0 to target learning rate. default is 0.1')\n",
    "parser.add_argument('--log_interval',\n",
    "                    type=int,\n",
    "                    default=50,\n",
    "                    help='report interval. default is 50')\n",
    "parser.add_argument('--max_seq_length',\n",
    "                    type=int,\n",
    "                    default=384,\n",
    "                    help='The maximum total input sequence length after WordPiece tokenization.'\n",
    "                    'Sequences longer than this will be truncated, and sequences shorter '\n",
    "                    'than this will be padded. default is 384')\n",
    "parser.add_argument('--doc_stride',\n",
    "                    type=int,\n",
    "                    default=128,\n",
    "                    help='When splitting up a long document into chunks, how much stride to '\n",
    "                    'take between chunks. default is 128')\n",
    "parser.add_argument('--max_query_length',\n",
    "                    type=int,\n",
    "                    default=64,\n",
    "                    help='The maximum number of tokens for the question. Questions longer than '\n",
    "                    'this will be truncated to this length. default is 64')\n",
    "parser.add_argument('--n_best_size',\n",
    "                    type=int,\n",
    "                    default=20,\n",
    "                    help='The total number of n-best predictions to generate in the '\n",
    "                    'nbest_predictions.json output file. default is 20')\n",
    "parser.add_argument('--max_answer_length',\n",
    "                    type=int,\n",
    "                    default=30,\n",
    "                    help='The maximum length of an answer that can be generated. This is needed '\n",
    "                    'because the start and end predictions are not conditioned on one another.'\n",
    "                    ' default is 30')\n",
    "# parser.add_argument('--version_2',\n",
    "#                     action='store_true',\n",
    "#                     help='SQuAD examples whether contain some that do not have an answer.')\n",
    "parser.add_argument('--null_score_diff_threshold',\n",
    "                    type=float,\n",
    "                    default=0.0,\n",
    "                    help='If null_score - best_non_null is greater than the threshold predict null.'\n",
    "                    'Typical values are between -1.0 and -5.0. default is 0.0')\n",
    "parser.add_argument('--sentencepiece',\n",
    "                    type=str,\n",
    "                    default=None,\n",
    "                    help='Path to the sentencepiece .model file for both tokenization and vocab.')\n",
    "# parser.add_argument('--debug',\n",
    "#                     action='store_true',\n",
    "#                     help='Run the example in test mode for sanity checks')\n",
    "\n",
    "\n",
    "args = parser.parse_args([])\n",
    "\n",
    "\n",
    "epochs = args.epochs\n",
    "batch_size = args.batch_size\n",
    "num_epochs = args.num_epochs\n",
    "lr = args.lr\n",
    "\n",
    "output_dir = args.output_dir\n",
    "if not os.path.exists(output_dir):\n",
    "    os.mkdir(output_dir)\n",
    "test_batch_size = args.test_batch_size\n",
    "optimizer = args.optimizer\n",
    "accumulate = args.accumulate\n",
    "warmup_ratio = args.warmup_ratio\n",
    "log_interval = args.log_interval\n",
    "max_seq_length = args.max_seq_length\n",
    "doc_stride = args.doc_stride\n",
    "max_query_length = args.max_query_length\n",
    "n_best_size = args.n_best_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Inspect the SQuAD Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Then we take a look at the Stanford Question Answering Dataset (SQuAD). The dataset can be downloaded using the `nlp.data.SQuAD` API. In this tutorial, we create a small dataset with 3 samples from the SQuAD dataset for demonstration purpose.\n",
    "\n",
    "The question answering task on the SQuAD dataset is setup the following way. For each sample in the dataset, a context is provided. The context is usually a long paragraph which contains lots of information. Then a question asked based on the context. The goal is to find the text span in the context that answers the question in the sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T01:45:27.555133Z",
     "start_time": "2019-06-14T01:45:27.418706Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples in the created dataset subsampled from SQuAD = 3\n"
     ]
    }
   ],
   "source": [
    "full_data = nlp.data.SQuAD(segment='dev', version='1.1')\n",
    "# loading a subset of the dev set of SQuAD\n",
    "num_target_samples = 3\n",
    "target_samples = [full_data[i] for i in range(num_target_samples)]\n",
    "dataset = mx.gluon.data.SimpleDataset(target_samples)\n",
    "print('Number of samples in the created dataset subsampled from SQuAD = %d'%len(dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Let's take a look at a sample from the dataset. In this sample, the question is about the location of the game, with a description about the Super Bowl 50 game as the context. Note that three different answer spans are correct for this question, and they start from index 403, 355 and 355 in the context respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T01:45:27.560564Z",
     "start_time": "2019-06-14T01:45:27.557274Z"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Context:\n",
      "\n",
      "Super Bowl 50 was an American football game to determine the champion of the National Football League (NFL) for the 2015 season. The American Football Conference (AFC) champion Denver Broncos defeated the National Football Conference (NFC) champion Carolina Panthers 24–10 to earn their third Super Bowl title. The game was played on February 7, 2016, at Levi's Stadium in the San Francisco Bay Area at Santa Clara, California. As this was the 50th Super Bowl, the league emphasized the \"golden anniversary\" with various gold-themed initiatives, as well as temporarily suspending the tradition of naming each Super Bowl game with Roman numerals (under which the game would have been known as \"Super Bowl L\"), so that the logo could prominently feature the Arabic numerals 50.\n"
     ]
    }
   ],
   "source": [
    "sample = dataset[2]\n",
    "\n",
    "context_idx = 3\n",
    "\n",
    "print('\\nContext:\\n')\n",
    "print(sample[context_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T01:45:27.567303Z",
     "start_time": "2019-06-14T01:45:27.562425Z"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Question\n",
      "Where did Super Bowl 50 take place?\n",
      "\n",
      "Correct Answer Spans\n",
      "['Santa Clara, California', \"Levi's Stadium\", \"Levi's Stadium in the San Francisco Bay Area at Santa Clara, California.\"]\n",
      "\n",
      "Answer Span Start Indices:\n",
      "[403, 355, 355]\n"
     ]
    }
   ],
   "source": [
    "question_idx = 2\n",
    "answer_idx = 4\n",
    "answer_pos_idx = 5\n",
    "\n",
    "print(\"\\nQuestion\")\n",
    "print(sample[question_idx])\n",
    "print(\"\\nCorrect Answer Spans\")\n",
    "print(sample[answer_idx])\n",
    "print(\"\\nAnswer Span Start Indices:\")\n",
    "print(sample[answer_pos_idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## Data Pre-processing for QA with BERT\n",
    "\n",
    "Recall that during BERT pre-training, it takes a sentence pair as the input, separated by the 'SEP' special token. For SQuAD, we can feed the context-question pair as the sentence pair input. To use BERT to predict the starting and ending span of the answer, we can add a classification layer for each token in the context texts, to predict if a token is the start or the end of the answer span. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T01:30:12.299493Z",
     "start_time": "2019-06-14T01:30:12.183419Z"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![qa](natural_language_understanding/qa.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "In the next few code blocks, we will work on pre-processing the samples in the SQuAD dataset in the desired format with these special separators. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Pre-trained BERT Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "First, let's use the *get_model* API in GluonNLP to get the model definition for BERT, and the vocabulary used for the BERT model. Note that we discard the pooler and classifier layers used for the next sentence prediction task, as well as the decoder layers for the masked language model task during the BERT pre-training phase. These layers are not useful for predicting the starting and ending indices of the answer span.\n",
    "\n",
    "The list of pre-trained BERT models available in GluonNLP can be found [here](http://gluon-nlp.mxnet.io/model_zoo/bert/index.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T01:45:27.715444Z",
     "start_time": "2019-06-14T01:45:27.569118Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "bert_model, vocab = nlp.model.get_model('bert_12_768_12',\n",
    "                                        dataset_name='book_corpus_wiki_en_uncased',\n",
    "                                        use_classifier=False,\n",
    "                                        use_decoder=False,\n",
    "                                        use_pooler=False,\n",
    "                                        pretrained=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Note that there are several special tokens in the vocabulary for BERT. In particular, the `[SEP]` token is used for separating the sentence pairs, and the `[CLS]` token is added at the beginning of the sentence pairs. They will be used to pre-process the SQuAD dataset later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T01:45:27.720137Z",
     "start_time": "2019-06-14T01:45:27.717192Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab(size=30522, unk=\"[UNK]\", reserved=\"['[CLS]', '[SEP]', '[MASK]', '[PAD]']\")\n"
     ]
    }
   ],
   "source": [
    "print(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "The second step is to process the samples using the same tokenizer used for BERT, which is provided as the `BERTTokenizer` API in GluonNLP. Note that instead of word level and character level representation, BERT uses subwords to represent a word, separated `##`. \n",
    "\n",
    "In the following example, the word `suspending` is tokenized as two subwords (`suspend` and `##ing`), and `numerals` is tokenized as three subwords (`nu`, `##meral`, `##s`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T01:45:27.731724Z",
     "start_time": "2019-06-14T01:45:27.721690Z"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['as',\n",
       " 'well',\n",
       " 'as',\n",
       " 'temporarily',\n",
       " 'suspend',\n",
       " '##ing',\n",
       " 'the',\n",
       " 'tradition',\n",
       " 'of',\n",
       " 'naming',\n",
       " 'each',\n",
       " 'super',\n",
       " 'bowl',\n",
       " 'game',\n",
       " 'with',\n",
       " 'roman',\n",
       " 'nu',\n",
       " '##meral',\n",
       " '##s']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = nlp.data.BERTTokenizer(vocab=vocab, lower=True)\n",
    "\n",
    "tokenizer(\"as well as temporarily suspending the tradition of naming each Super Bowl game with Roman numerals\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Sentence Pair Composition\n",
    "\n",
    "With the tokenizer inplace, we are ready to process the question-context texts and compose sentence pairs. The functionality is available via the `SQuADTransform` API. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T01:45:27.897684Z",
     "start_time": "2019-06-14T01:45:27.734029Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done! Transform dataset costs 0.17 seconds.\n"
     ]
    }
   ],
   "source": [
    "transform = bert.data.qa.SQuADTransform(tokenizer, is_pad=False, is_training=False, do_lookup=False)\n",
    "dev_data_transform, _ = bert.data.qa.preprocess_dataset(dataset, transform)\n",
    "logging.info('The number of examples after preprocessing:{}'.format(len(dev_data_transform)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Let's take a look at the sample after the transformation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T01:45:27.904353Z",
     "start_time": "2019-06-14T01:45:27.899992Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "segment type: \n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "\n",
      "text length: 168\n",
      "\n",
      "sentence pair: \n",
      "['[CLS]', 'where', 'did', 'super', 'bowl', '50', 'take', 'place', '?', '[SEP]', 'super', 'bowl', '50', 'was', 'an', 'american', 'football', 'game', 'to', 'determine', 'the', 'champion', 'of', 'the', 'national', 'football', 'league', '(', 'nfl', ')', 'for', 'the', '2015', 'season', '.', 'the', 'american', 'football', 'conference', '(', 'afc', ')', 'champion', 'denver', 'broncos', 'defeated', 'the', 'national', 'football', 'conference', '(', 'nfc', ')', 'champion', 'carolina', 'panthers', '24', '–', '10', 'to', 'earn', 'their', 'third', 'super', 'bowl', 'title', '.', 'the', 'game', 'was', 'played', 'on', 'february', '7', ',', '2016', ',', 'at', 'levi', \"'\", 's', 'stadium', 'in', 'the', 'san', 'francisco', 'bay', 'area', 'at', 'santa', 'clara', ',', 'california', '.', 'as', 'this', 'was', 'the', '50th', 'super', 'bowl', ',', 'the', 'league', 'emphasized', 'the', '\"', 'golden', 'anniversary', '\"', 'with', 'various', 'gold', '-', 'themed', 'initiatives', ',', 'as', 'well', 'as', 'temporarily', 'suspend', '##ing', 'the', 'tradition', 'of', 'naming', 'each', 'super', 'bowl', 'game', 'with', 'roman', 'nu', '##meral', '##s', '(', 'under', 'which', 'the', 'game', 'would', 'have', 'been', 'known', 'as', '\"', 'super', 'bowl', 'l', '\"', ')', ',', 'so', 'that', 'the', 'logo', 'could', 'prominently', 'feature', 'the', 'arabic', 'nu', '##meral', '##s', '50', '.', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "sample = dev_data_transform[2]\n",
    "print('\\nsegment type: \\n' + str(sample[2]))\n",
    "print('\\ntext length: ' + str(sample[3]))\n",
    "print('\\nsentence pair: \\n' + str(sample[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Vocabulary Lookup\n",
    "\n",
    "Finally, we convert the transformed texts to subword indices, which are used to contructor NDArrays as the inputs to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T01:45:27.910853Z",
     "start_time": "2019-06-14T01:45:27.906127Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 2073, 2106, 3565, 4605, 2753, 2202, 2173, 1029, 3, 3565, 4605, 2753, 2001, 2019, 2137, 2374, 2208, 2000, 5646, 1996, 3410, 1997, 1996, 2120, 2374, 2223, 1006, 5088, 1007, 2005, 1996, 2325, 2161, 1012, 1996, 2137, 2374, 3034, 1006, 10511, 1007, 3410, 7573, 14169, 3249, 1996, 2120, 2374, 3034, 1006, 22309, 1007, 3410, 3792, 12915, 2484, 1516, 2184, 2000, 7796, 2037, 2353, 3565, 4605, 2516, 1012, 1996, 2208, 2001, 2209, 2006, 2337, 1021, 1010, 2355, 1010, 2012, 11902, 1005, 1055, 3346, 1999, 1996, 2624, 3799, 3016, 2181, 2012, 4203, 10254, 1010, 2662, 1012, 2004, 2023, 2001, 1996, 12951, 3565, 4605, 1010, 1996, 2223, 13155, 1996, 1000, 3585, 5315, 1000, 2007, 2536, 2751, 1011, 11773, 11107, 1010, 2004, 2092, 2004, 8184, 28324, 2075, 1996, 4535, 1997, 10324, 2169, 3565, 4605, 2208, 2007, 3142, 16371, 28990, 2015, 1006, 2104, 2029, 1996, 2208, 2052, 2031, 2042, 2124, 2004, 1000, 3565, 4605, 1048, 1000, 1007, 1010, 2061, 2008, 1996, 8154, 2071, 14500, 3444, 1996, 5640, 16371, 28990, 2015, 2753, 1012, 3]\n"
     ]
    }
   ],
   "source": [
    "def vocab_lookup(example_id, subwords, type_ids, length, start, end):\n",
    "    indices = vocab[subwords]\n",
    "    return example_id, indices, type_ids, length, start, end\n",
    "\n",
    "dev_data_transform = dev_data_transform.transform(vocab_lookup, lazy=False)\n",
    "print(dev_data_transform[2][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Model Definition\n",
    "\n",
    "After the data is processed, we can define the model that uses the representation produced by BERT for predicting the starting and ending positions of the answer span."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T01:45:27.921076Z",
     "start_time": "2019-06-14T01:45:27.912650Z"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We download a BERT model trained on the SQuAD dataset, prepare the dataloader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T01:45:32.221383Z",
     "start_time": "2019-06-14T01:45:27.922825Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded checkpoint to ./temp/bert_qa-7eb11865.params\n"
     ]
    }
   ],
   "source": [
    "net = BertForQA(bert_model)\n",
    "\n",
    "ctx = mx.gpu(0)\n",
    "## multi-gpu training\n",
    "# GPU_COUNT = 4 # increase if you have more\n",
    "# ctx = [mx.gpu(i) for i in range(GPU_COUNT)]\n",
    "\n",
    "ckpt = qa_utils.download_qa_ckpt()\n",
    "net.load_parameters(ckpt, ctx=ctx)\n",
    "\n",
    "batch_size = 1\n",
    "dev_dataloader = mx.gluon.data.DataLoader(\n",
    "    dev_data_transform, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T01:45:32.575976Z",
     "start_time": "2019-06-14T01:45:32.223336Z"
    }
   },
   "outputs": [],
   "source": [
    "# all_results = collections.defaultdict(list)\n",
    "\n",
    "# total_num = 0\n",
    "# for data in dev_dataloader:\n",
    "#     example_ids, inputs, token_types, valid_length, _, _ = data\n",
    "#     total_num += len(inputs)\n",
    "#     batch_size = inputs.shape[0]\n",
    "#     pred_start, pred_end = net(inputs.astype('float32').as_in_context(ctx),\n",
    "#                                token_types.astype('float32').as_in_context(ctx),\n",
    "#                                valid_length.astype('float32').as_in_context(ctx))\n",
    "\n",
    "#     example_ids = example_ids.asnumpy().tolist()\n",
    "#     pred_start = pred_start.reshape(batch_size, -1).asnumpy()\n",
    "#     pred_end = pred_end.reshape(batch_size, -1).asnumpy()\n",
    "    \n",
    "#     for example_id, start, end in zip(example_ids, pred_start, pred_end):\n",
    "#         all_results[example_id].append(PredResult(start=start, end=end))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T01:45:32.623482Z",
     "start_time": "2019-06-14T01:45:32.578002Z"
    }
   },
   "outputs": [],
   "source": [
    "# qa_utils.predict(dataset, all_results, vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's Train the Model\n",
    "\n",
    "Now we can put all the pieces together, and start fine-tuning the model with a few epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/mxnet/gluon/parameter.py:887: UserWarning: Parameter 'bertforqa0_dense0_weight' is already initialized, ignoring. Set force_reinit=True to re-initialize.\n",
      "  v.initialize(None, ctx, init, force_reinit=force_reinit)\n",
      "/home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/mxnet/gluon/parameter.py:887: UserWarning: Parameter 'bertforqa0_dense0_bias' is already initialized, ignoring. Set force_reinit=True to re-initialize.\n",
      "  v.initialize(None, ctx, init, force_reinit=force_reinit)\n"
     ]
    }
   ],
   "source": [
    "# net = BertForQA(bert=bert_model)\n",
    "# nlp.utils.load_parameters(net, pretrained_bert_parameters, ctx=ctx,\n",
    "#                           ignore_extra=True, cast_dtype=True)\n",
    "net.span_classifier.initialize(init=mx.init.Normal(0.02), ctx=ctx)\n",
    "net.hybridize(static_alloc=True)\n",
    "\n",
    "loss_function = BertForQALoss()\n",
    "loss_function.hybridize(static_alloc=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gluonnlp:Loading train data...\n",
      "INFO:gluonnlp:Number of records in Train data:87599\n",
      "INFO:gluonnlp:The number of examples after preprocessing:88641\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done! Transform dataset costs 57.50 seconds.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "batchify_fn = nlp.data.batchify.Tuple(\n",
    "    nlp.data.batchify.Stack(),\n",
    "    nlp.data.batchify.Pad(axis=0, pad_val=vocab[vocab.padding_token]),\n",
    "    nlp.data.batchify.Pad(axis=0, pad_val=vocab[vocab.padding_token]),\n",
    "    nlp.data.batchify.Stack('float32'),\n",
    "    nlp.data.batchify.Stack('float32'),\n",
    "    nlp.data.batchify.Stack('float32'))\n",
    "\n",
    "np.random.seed(6)\n",
    "random.seed(6)\n",
    "mx.random.seed(6)\n",
    "\n",
    "log = logging.getLogger('gluonnlp')\n",
    "log.setLevel(logging.DEBUG)\n",
    "formatter = logging.Formatter(\n",
    "    fmt='%(levelname)s:%(name)s:%(asctime)s %(message)s', datefmt='%H:%M:%S')\n",
    "\n",
    "\n",
    "segment = 'train'  # if not args.debug else 'dev'\n",
    "log.info('Loading %s data...', segment)\n",
    "#     if version_2:\n",
    "#         train_data = SQuAD(segment, version='2.0')\n",
    "#     else:\n",
    "train_data = SQuAD(segment, version='1.1')\n",
    "#     if args.debug:\n",
    "#         sampled_data = [train_data[i] for i in range(1000)]\n",
    "#         train_data = mx.gluon.data.SimpleDataset(sampled_data)\n",
    "log.info('Number of records in Train data:{}'.format(len(train_data)))\n",
    "\n",
    "train_data_transform, _ = preprocess_dataset(\n",
    "    train_data, SQuADTransform(\n",
    "        copy.copy(tokenizer),\n",
    "        max_seq_length=max_seq_length,\n",
    "        doc_stride=doc_stride,\n",
    "        max_query_length=max_query_length,\n",
    "        is_pad=True,\n",
    "        is_training=True))\n",
    "log.info('The number of examples after preprocessing:{}'.format(\n",
    "    len(train_data_transform)))\n",
    "\n",
    "train_dataloader = mx.gluon.data.DataLoader(\n",
    "    train_data_transform, batchify_fn=batchify_fn,\n",
    "    batch_size=batch_size, num_workers=4, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gluonnlp:Start Training\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 49/88641, Loss=0.6069, lr=0.0000001 Time cost=10.9 Thoughput=4.59 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 99/88641, Loss=0.6334, lr=0.0000002 Time cost=4.1 Thoughput=12.11 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 149/88641, Loss=0.7261, lr=0.0000003 Time cost=4.1 Thoughput=12.06 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 199/88641, Loss=0.5254, lr=0.0000004 Time cost=4.3 Thoughput=11.62 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 249/88641, Loss=0.5394, lr=0.0000005 Time cost=4.1 Thoughput=12.08 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 299/88641, Loss=0.4510, lr=0.0000006 Time cost=4.1 Thoughput=12.27 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 349/88641, Loss=0.7645, lr=0.0000007 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 399/88641, Loss=0.6211, lr=0.0000008 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 449/88641, Loss=0.6223, lr=0.0000008 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 499/88641, Loss=0.6369, lr=0.0000009 Time cost=4.1 Thoughput=12.27 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 549/88641, Loss=0.4073, lr=0.0000010 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 599/88641, Loss=0.4105, lr=0.0000011 Time cost=4.1 Thoughput=12.22 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 649/88641, Loss=0.5736, lr=0.0000012 Time cost=4.1 Thoughput=12.13 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 699/88641, Loss=0.2645, lr=0.0000013 Time cost=4.8 Thoughput=10.52 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 749/88641, Loss=0.7508, lr=0.0000014 Time cost=4.1 Thoughput=12.20 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 799/88641, Loss=0.5913, lr=0.0000015 Time cost=4.1 Thoughput=12.21 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 849/88641, Loss=0.5214, lr=0.0000016 Time cost=4.2 Thoughput=11.95 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 899/88641, Loss=0.7807, lr=0.0000017 Time cost=4.1 Thoughput=12.17 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 949/88641, Loss=0.5499, lr=0.0000018 Time cost=4.1 Thoughput=12.20 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 999/88641, Loss=0.9787, lr=0.0000019 Time cost=4.1 Thoughput=12.19 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 1049/88641, Loss=0.5709, lr=0.0000020 Time cost=4.1 Thoughput=12.22 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 1099/88641, Loss=0.2711, lr=0.0000021 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 1149/88641, Loss=0.6655, lr=0.0000022 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 1199/88641, Loss=0.7862, lr=0.0000023 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 1249/88641, Loss=0.6963, lr=0.0000024 Time cost=4.1 Thoughput=12.27 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 1299/88641, Loss=1.0049, lr=0.0000024 Time cost=4.1 Thoughput=12.17 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 1349/88641, Loss=0.3926, lr=0.0000025 Time cost=4.2 Thoughput=11.88 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 1399/88641, Loss=0.6855, lr=0.0000026 Time cost=4.1 Thoughput=12.22 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 1449/88641, Loss=0.6130, lr=0.0000027 Time cost=4.1 Thoughput=12.06 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 1499/88641, Loss=0.9379, lr=0.0000028 Time cost=4.2 Thoughput=11.98 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 1549/88641, Loss=0.6526, lr=0.0000029 Time cost=4.2 Thoughput=11.99 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 1599/88641, Loss=0.4951, lr=0.0000030 Time cost=4.2 Thoughput=12.04 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 1649/88641, Loss=0.7473, lr=0.0000031 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 1699/88641, Loss=0.5098, lr=0.0000032 Time cost=4.1 Thoughput=12.12 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 1749/88641, Loss=0.8733, lr=0.0000033 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 1799/88641, Loss=0.8423, lr=0.0000034 Time cost=4.2 Thoughput=11.93 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 1849/88641, Loss=0.8298, lr=0.0000035 Time cost=4.2 Thoughput=11.84 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 1899/88641, Loss=1.1933, lr=0.0000036 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 1949/88641, Loss=0.2767, lr=0.0000037 Time cost=4.1 Thoughput=12.08 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 1999/88641, Loss=1.0248, lr=0.0000038 Time cost=4.1 Thoughput=12.30 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 2049/88641, Loss=1.2207, lr=0.0000039 Time cost=4.1 Thoughput=12.18 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 2099/88641, Loss=0.7661, lr=0.0000039 Time cost=4.1 Thoughput=12.10 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 2149/88641, Loss=1.3836, lr=0.0000040 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 2199/88641, Loss=0.5975, lr=0.0000041 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 2249/88641, Loss=0.8464, lr=0.0000042 Time cost=4.1 Thoughput=12.20 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 2299/88641, Loss=0.5271, lr=0.0000043 Time cost=4.1 Thoughput=12.21 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 2349/88641, Loss=0.7342, lr=0.0000044 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 2399/88641, Loss=0.7089, lr=0.0000045 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 2449/88641, Loss=0.7096, lr=0.0000046 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 2499/88641, Loss=0.7368, lr=0.0000047 Time cost=4.1 Thoughput=12.12 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 2549/88641, Loss=0.9773, lr=0.0000048 Time cost=4.1 Thoughput=12.08 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 2599/88641, Loss=0.5497, lr=0.0000049 Time cost=4.2 Thoughput=11.87 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 2649/88641, Loss=0.6703, lr=0.0000050 Time cost=4.1 Thoughput=12.10 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 2699/88641, Loss=0.8298, lr=0.0000051 Time cost=4.1 Thoughput=12.20 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 2749/88641, Loss=0.8804, lr=0.0000052 Time cost=4.1 Thoughput=12.21 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 2799/88641, Loss=0.6825, lr=0.0000053 Time cost=4.1 Thoughput=12.21 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 2849/88641, Loss=0.9912, lr=0.0000054 Time cost=4.1 Thoughput=12.20 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 2899/88641, Loss=0.7991, lr=0.0000055 Time cost=4.1 Thoughput=12.19 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 2949/88641, Loss=0.8185, lr=0.0000055 Time cost=4.1 Thoughput=12.21 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 2999/88641, Loss=1.1171, lr=0.0000056 Time cost=4.1 Thoughput=12.22 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 3049/88641, Loss=0.8847, lr=0.0000057 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 3099/88641, Loss=0.7821, lr=0.0000058 Time cost=4.1 Thoughput=12.05 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 3149/88641, Loss=1.2328, lr=0.0000059 Time cost=4.1 Thoughput=12.21 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 3199/88641, Loss=1.0166, lr=0.0000060 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 3249/88641, Loss=0.5471, lr=0.0000061 Time cost=4.1 Thoughput=12.20 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 3299/88641, Loss=0.7974, lr=0.0000062 Time cost=4.1 Thoughput=12.27 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 3349/88641, Loss=0.7558, lr=0.0000063 Time cost=4.1 Thoughput=12.22 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 3399/88641, Loss=1.1485, lr=0.0000064 Time cost=4.1 Thoughput=12.22 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 3449/88641, Loss=0.9238, lr=0.0000065 Time cost=4.1 Thoughput=12.20 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 3499/88641, Loss=0.7857, lr=0.0000066 Time cost=4.2 Thoughput=12.00 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 3549/88641, Loss=1.0331, lr=0.0000067 Time cost=4.1 Thoughput=12.27 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 3599/88641, Loss=1.3075, lr=0.0000068 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 3649/88641, Loss=0.7379, lr=0.0000069 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 3699/88641, Loss=1.2482, lr=0.0000070 Time cost=4.1 Thoughput=12.28 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 3749/88641, Loss=0.8936, lr=0.0000071 Time cost=4.1 Thoughput=12.28 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 3799/88641, Loss=0.8531, lr=0.0000071 Time cost=4.1 Thoughput=12.26 samples/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gluonnlp:Epoch: 0, Batch: 3849/88641, Loss=1.1156, lr=0.0000072 Time cost=4.1 Thoughput=12.27 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 3899/88641, Loss=0.9664, lr=0.0000073 Time cost=4.1 Thoughput=12.13 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 3949/88641, Loss=0.4874, lr=0.0000074 Time cost=4.1 Thoughput=12.09 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 3999/88641, Loss=0.7005, lr=0.0000075 Time cost=4.1 Thoughput=12.17 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 4049/88641, Loss=1.0819, lr=0.0000076 Time cost=4.1 Thoughput=12.20 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 4099/88641, Loss=0.6048, lr=0.0000077 Time cost=4.1 Thoughput=12.14 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 4149/88641, Loss=0.8377, lr=0.0000078 Time cost=4.1 Thoughput=12.15 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 4199/88641, Loss=0.6581, lr=0.0000079 Time cost=4.1 Thoughput=12.27 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 4249/88641, Loss=0.9878, lr=0.0000080 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 4299/88641, Loss=0.6331, lr=0.0000081 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 4349/88641, Loss=0.9655, lr=0.0000082 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 4399/88641, Loss=1.1211, lr=0.0000083 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 4449/88641, Loss=0.7675, lr=0.0000084 Time cost=4.1 Thoughput=12.20 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 4499/88641, Loss=1.0036, lr=0.0000085 Time cost=4.1 Thoughput=12.19 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 4549/88641, Loss=0.9094, lr=0.0000086 Time cost=4.6 Thoughput=10.86 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 4599/88641, Loss=1.0284, lr=0.0000086 Time cost=4.1 Thoughput=12.06 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 4649/88641, Loss=0.6939, lr=0.0000087 Time cost=4.2 Thoughput=12.00 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 4699/88641, Loss=1.5450, lr=0.0000088 Time cost=4.2 Thoughput=12.02 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 4749/88641, Loss=0.7739, lr=0.0000089 Time cost=4.1 Thoughput=12.06 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 4799/88641, Loss=0.7291, lr=0.0000090 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 4849/88641, Loss=1.1798, lr=0.0000091 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 4899/88641, Loss=1.5712, lr=0.0000092 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 4949/88641, Loss=0.7607, lr=0.0000093 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 4999/88641, Loss=0.8242, lr=0.0000094 Time cost=4.1 Thoughput=12.22 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 5049/88641, Loss=0.8197, lr=0.0000095 Time cost=4.1 Thoughput=12.21 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 5099/88641, Loss=1.2785, lr=0.0000096 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 5149/88641, Loss=1.0090, lr=0.0000097 Time cost=4.1 Thoughput=12.28 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 5199/88641, Loss=0.7606, lr=0.0000098 Time cost=4.1 Thoughput=12.27 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 5249/88641, Loss=0.9917, lr=0.0000099 Time cost=4.2 Thoughput=11.99 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 5299/88641, Loss=1.1118, lr=0.0000100 Time cost=4.2 Thoughput=11.94 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 5349/88641, Loss=1.0275, lr=0.0000101 Time cost=4.2 Thoughput=12.01 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 5399/88641, Loss=0.9489, lr=0.0000102 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 5449/88641, Loss=0.8182, lr=0.0000102 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 5499/88641, Loss=1.0890, lr=0.0000103 Time cost=4.1 Thoughput=12.19 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 5549/88641, Loss=1.1321, lr=0.0000104 Time cost=4.1 Thoughput=12.16 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 5599/88641, Loss=1.4861, lr=0.0000105 Time cost=4.1 Thoughput=12.21 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 5649/88641, Loss=0.8367, lr=0.0000106 Time cost=4.1 Thoughput=12.14 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 5699/88641, Loss=0.5612, lr=0.0000107 Time cost=4.2 Thoughput=11.99 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 5749/88641, Loss=1.0914, lr=0.0000108 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 5799/88641, Loss=1.0321, lr=0.0000109 Time cost=4.2 Thoughput=12.05 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 5849/88641, Loss=1.0224, lr=0.0000110 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 5899/88641, Loss=1.1236, lr=0.0000111 Time cost=4.1 Thoughput=12.27 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 5949/88641, Loss=0.9800, lr=0.0000112 Time cost=4.1 Thoughput=12.30 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 5999/88641, Loss=0.5102, lr=0.0000113 Time cost=4.1 Thoughput=12.17 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 6049/88641, Loss=0.9254, lr=0.0000114 Time cost=4.2 Thoughput=11.94 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 6099/88641, Loss=0.7753, lr=0.0000115 Time cost=4.2 Thoughput=12.03 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 6149/88641, Loss=0.4143, lr=0.0000116 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 6199/88641, Loss=0.7866, lr=0.0000117 Time cost=4.1 Thoughput=12.20 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 6249/88641, Loss=0.9017, lr=0.0000118 Time cost=4.1 Thoughput=12.17 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 6299/88641, Loss=0.6548, lr=0.0000118 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 6349/88641, Loss=1.0493, lr=0.0000119 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 6399/88641, Loss=0.7841, lr=0.0000120 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 6449/88641, Loss=1.6702, lr=0.0000121 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 6499/88641, Loss=1.0199, lr=0.0000122 Time cost=4.1 Thoughput=12.27 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 6549/88641, Loss=0.9009, lr=0.0000123 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 6599/88641, Loss=0.9458, lr=0.0000124 Time cost=4.1 Thoughput=12.06 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 6649/88641, Loss=1.0251, lr=0.0000125 Time cost=4.1 Thoughput=12.29 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 6699/88641, Loss=0.8790, lr=0.0000126 Time cost=4.1 Thoughput=12.20 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 6749/88641, Loss=1.2285, lr=0.0000127 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 6799/88641, Loss=1.2160, lr=0.0000128 Time cost=4.1 Thoughput=12.28 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 6849/88641, Loss=0.7267, lr=0.0000129 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 6899/88641, Loss=0.9038, lr=0.0000130 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 6949/88641, Loss=0.8204, lr=0.0000131 Time cost=4.1 Thoughput=12.21 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 6999/88641, Loss=0.8954, lr=0.0000132 Time cost=4.1 Thoughput=12.17 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 7049/88641, Loss=1.3914, lr=0.0000133 Time cost=4.1 Thoughput=12.22 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 7099/88641, Loss=1.0900, lr=0.0000133 Time cost=4.1 Thoughput=12.29 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 7149/88641, Loss=1.0688, lr=0.0000134 Time cost=4.1 Thoughput=12.30 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 7199/88641, Loss=0.8243, lr=0.0000135 Time cost=4.2 Thoughput=12.04 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 7249/88641, Loss=1.1281, lr=0.0000136 Time cost=4.7 Thoughput=10.73 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 7299/88641, Loss=1.2806, lr=0.0000137 Time cost=4.1 Thoughput=12.21 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 7349/88641, Loss=0.9058, lr=0.0000138 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 7399/88641, Loss=0.9762, lr=0.0000139 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 7449/88641, Loss=1.1289, lr=0.0000140 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 7499/88641, Loss=0.8985, lr=0.0000141 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 7549/88641, Loss=0.4803, lr=0.0000142 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 7599/88641, Loss=1.2343, lr=0.0000143 Time cost=4.2 Thoughput=12.02 samples/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gluonnlp:Epoch: 0, Batch: 7649/88641, Loss=1.2989, lr=0.0000144 Time cost=4.1 Thoughput=12.10 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 7699/88641, Loss=0.7474, lr=0.0000145 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 7749/88641, Loss=0.8412, lr=0.0000146 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 7799/88641, Loss=1.1350, lr=0.0000147 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 7849/88641, Loss=0.9285, lr=0.0000148 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 7899/88641, Loss=1.0477, lr=0.0000149 Time cost=4.2 Thoughput=11.99 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 7949/88641, Loss=0.8970, lr=0.0000149 Time cost=4.1 Thoughput=12.27 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 7999/88641, Loss=0.9430, lr=0.0000150 Time cost=4.1 Thoughput=12.30 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 8049/88641, Loss=0.8372, lr=0.0000151 Time cost=4.1 Thoughput=12.30 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 8099/88641, Loss=1.1069, lr=0.0000152 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 8149/88641, Loss=0.9224, lr=0.0000153 Time cost=4.2 Thoughput=11.98 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 8199/88641, Loss=0.7040, lr=0.0000154 Time cost=4.1 Thoughput=12.10 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 8249/88641, Loss=1.1855, lr=0.0000155 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 8299/88641, Loss=1.6761, lr=0.0000156 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 8349/88641, Loss=0.5706, lr=0.0000157 Time cost=4.1 Thoughput=12.22 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 8399/88641, Loss=0.8162, lr=0.0000158 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 8449/88641, Loss=0.8981, lr=0.0000159 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 8499/88641, Loss=0.7565, lr=0.0000160 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 8549/88641, Loss=0.8712, lr=0.0000161 Time cost=4.1 Thoughput=12.22 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 8599/88641, Loss=1.1045, lr=0.0000162 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 8649/88641, Loss=0.4887, lr=0.0000163 Time cost=4.1 Thoughput=12.27 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 8699/88641, Loss=1.5207, lr=0.0000164 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 8749/88641, Loss=0.9054, lr=0.0000165 Time cost=4.1 Thoughput=12.27 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 8799/88641, Loss=1.1595, lr=0.0000165 Time cost=4.1 Thoughput=12.27 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 8849/88641, Loss=0.7745, lr=0.0000166 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 8899/88641, Loss=1.6580, lr=0.0000167 Time cost=4.1 Thoughput=12.21 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 8949/88641, Loss=0.6414, lr=0.0000168 Time cost=4.1 Thoughput=12.15 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 8999/88641, Loss=1.1540, lr=0.0000169 Time cost=4.2 Thoughput=11.96 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 9049/88641, Loss=1.8816, lr=0.0000170 Time cost=4.1 Thoughput=12.21 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 9099/88641, Loss=0.9542, lr=0.0000171 Time cost=4.1 Thoughput=12.11 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 9149/88641, Loss=1.0230, lr=0.0000172 Time cost=4.2 Thoughput=11.96 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 9199/88641, Loss=1.1176, lr=0.0000173 Time cost=4.2 Thoughput=11.95 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 9249/88641, Loss=0.9211, lr=0.0000174 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 9299/88641, Loss=1.2645, lr=0.0000175 Time cost=4.1 Thoughput=12.22 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 9349/88641, Loss=1.0047, lr=0.0000176 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 9399/88641, Loss=1.0877, lr=0.0000177 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 9449/88641, Loss=1.1152, lr=0.0000178 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 9499/88641, Loss=1.1600, lr=0.0000179 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 9549/88641, Loss=0.8476, lr=0.0000180 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 9599/88641, Loss=1.3181, lr=0.0000181 Time cost=4.2 Thoughput=12.01 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 9649/88641, Loss=0.8994, lr=0.0000181 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 9699/88641, Loss=1.0438, lr=0.0000182 Time cost=4.3 Thoughput=11.54 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 9749/88641, Loss=0.8241, lr=0.0000183 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 9799/88641, Loss=1.3005, lr=0.0000184 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 9849/88641, Loss=1.3864, lr=0.0000185 Time cost=4.1 Thoughput=12.17 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 9899/88641, Loss=1.2681, lr=0.0000186 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 9949/88641, Loss=1.5252, lr=0.0000187 Time cost=4.1 Thoughput=12.22 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 9999/88641, Loss=1.0477, lr=0.0000188 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 10049/88641, Loss=1.2000, lr=0.0000189 Time cost=4.1 Thoughput=12.22 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 10099/88641, Loss=1.1721, lr=0.0000190 Time cost=4.2 Thoughput=11.83 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 10149/88641, Loss=1.3075, lr=0.0000191 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 10199/88641, Loss=0.9949, lr=0.0000192 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 10249/88641, Loss=1.5987, lr=0.0000193 Time cost=4.1 Thoughput=12.19 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 10299/88641, Loss=1.3771, lr=0.0000194 Time cost=4.1 Thoughput=12.19 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 10349/88641, Loss=1.3923, lr=0.0000195 Time cost=4.1 Thoughput=12.19 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 10399/88641, Loss=1.3788, lr=0.0000196 Time cost=4.1 Thoughput=12.21 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 10449/88641, Loss=0.6034, lr=0.0000196 Time cost=4.1 Thoughput=12.22 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 10499/88641, Loss=1.2630, lr=0.0000197 Time cost=4.1 Thoughput=12.21 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 10549/88641, Loss=0.8558, lr=0.0000198 Time cost=4.1 Thoughput=12.16 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 10599/88641, Loss=0.9375, lr=0.0000199 Time cost=4.1 Thoughput=12.16 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 10649/88641, Loss=0.8387, lr=0.0000200 Time cost=4.1 Thoughput=12.12 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 10699/88641, Loss=1.2181, lr=0.0000201 Time cost=4.1 Thoughput=12.19 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 10749/88641, Loss=0.8602, lr=0.0000202 Time cost=4.1 Thoughput=12.19 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 10799/88641, Loss=1.2659, lr=0.0000203 Time cost=4.1 Thoughput=12.21 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 10849/88641, Loss=1.3951, lr=0.0000204 Time cost=4.1 Thoughput=12.20 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 10899/88641, Loss=1.3768, lr=0.0000205 Time cost=4.1 Thoughput=12.18 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 10949/88641, Loss=1.2376, lr=0.0000206 Time cost=4.1 Thoughput=12.21 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 10999/88641, Loss=1.1665, lr=0.0000207 Time cost=4.1 Thoughput=12.21 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 11049/88641, Loss=1.2464, lr=0.0000208 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 11099/88641, Loss=0.9744, lr=0.0000209 Time cost=4.6 Thoughput=10.89 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 11149/88641, Loss=1.6440, lr=0.0000210 Time cost=4.1 Thoughput=12.28 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 11199/88641, Loss=1.2594, lr=0.0000211 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 11249/88641, Loss=0.7092, lr=0.0000212 Time cost=4.1 Thoughput=12.21 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 11299/88641, Loss=1.0535, lr=0.0000212 Time cost=4.2 Thoughput=12.01 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 11349/88641, Loss=1.1221, lr=0.0000213 Time cost=4.1 Thoughput=12.14 samples/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gluonnlp:Epoch: 0, Batch: 11399/88641, Loss=1.2425, lr=0.0000214 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 11449/88641, Loss=1.1879, lr=0.0000215 Time cost=4.1 Thoughput=12.28 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 11499/88641, Loss=1.3414, lr=0.0000216 Time cost=4.1 Thoughput=12.29 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 11549/88641, Loss=1.2133, lr=0.0000217 Time cost=4.1 Thoughput=12.27 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 11599/88641, Loss=0.6397, lr=0.0000218 Time cost=4.1 Thoughput=12.21 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 11649/88641, Loss=1.3349, lr=0.0000219 Time cost=4.1 Thoughput=12.19 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 11699/88641, Loss=1.9567, lr=0.0000220 Time cost=4.1 Thoughput=12.20 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 11749/88641, Loss=0.9104, lr=0.0000221 Time cost=4.1 Thoughput=12.17 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 11799/88641, Loss=1.2024, lr=0.0000222 Time cost=4.1 Thoughput=12.19 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 11849/88641, Loss=1.0785, lr=0.0000223 Time cost=4.1 Thoughput=12.10 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 11899/88641, Loss=1.0391, lr=0.0000224 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 11949/88641, Loss=1.1193, lr=0.0000225 Time cost=4.1 Thoughput=12.22 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 11999/88641, Loss=1.1051, lr=0.0000226 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 12049/88641, Loss=1.5140, lr=0.0000227 Time cost=4.1 Thoughput=12.29 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 12099/88641, Loss=1.2817, lr=0.0000228 Time cost=4.1 Thoughput=12.22 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 12149/88641, Loss=1.1305, lr=0.0000228 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 12199/88641, Loss=1.9498, lr=0.0000229 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 12249/88641, Loss=1.2881, lr=0.0000230 Time cost=4.1 Thoughput=12.20 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 12299/88641, Loss=1.0773, lr=0.0000231 Time cost=4.2 Thoughput=11.78 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 12349/88641, Loss=1.3073, lr=0.0000232 Time cost=4.1 Thoughput=12.20 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 12399/88641, Loss=1.2255, lr=0.0000233 Time cost=4.1 Thoughput=12.27 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 12449/88641, Loss=1.1875, lr=0.0000234 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 12499/88641, Loss=1.5638, lr=0.0000235 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 12549/88641, Loss=1.0234, lr=0.0000236 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 12599/88641, Loss=1.0901, lr=0.0000237 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 12649/88641, Loss=1.1761, lr=0.0000238 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 12699/88641, Loss=1.0932, lr=0.0000239 Time cost=4.1 Thoughput=12.28 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 12749/88641, Loss=1.3034, lr=0.0000240 Time cost=4.1 Thoughput=12.13 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 12799/88641, Loss=1.1953, lr=0.0000241 Time cost=4.1 Thoughput=12.27 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 12849/88641, Loss=1.0015, lr=0.0000242 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 12899/88641, Loss=1.4223, lr=0.0000243 Time cost=4.1 Thoughput=12.22 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 12949/88641, Loss=1.1540, lr=0.0000243 Time cost=4.1 Thoughput=12.21 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 12999/88641, Loss=1.0876, lr=0.0000244 Time cost=4.1 Thoughput=12.12 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 13049/88641, Loss=1.8753, lr=0.0000245 Time cost=4.2 Thoughput=11.96 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 13099/88641, Loss=0.7919, lr=0.0000246 Time cost=4.1 Thoughput=12.20 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 13149/88641, Loss=1.0531, lr=0.0000247 Time cost=4.1 Thoughput=12.21 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 13199/88641, Loss=1.4312, lr=0.0000248 Time cost=4.1 Thoughput=12.19 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 13249/88641, Loss=1.2324, lr=0.0000249 Time cost=4.1 Thoughput=12.17 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 13299/88641, Loss=1.7370, lr=0.0000250 Time cost=4.1 Thoughput=12.12 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 13349/88641, Loss=1.2653, lr=0.0000251 Time cost=4.1 Thoughput=12.20 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 13399/88641, Loss=1.5668, lr=0.0000252 Time cost=4.1 Thoughput=12.22 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 13449/88641, Loss=1.5047, lr=0.0000253 Time cost=4.1 Thoughput=12.21 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 13499/88641, Loss=1.5221, lr=0.0000254 Time cost=4.1 Thoughput=12.21 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 13549/88641, Loss=1.0286, lr=0.0000255 Time cost=4.1 Thoughput=12.20 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 13599/88641, Loss=1.3751, lr=0.0000256 Time cost=4.1 Thoughput=12.14 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 13649/88641, Loss=1.4000, lr=0.0000257 Time cost=4.2 Thoughput=11.98 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 13699/88641, Loss=1.2943, lr=0.0000258 Time cost=4.2 Thoughput=11.97 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 13749/88641, Loss=1.2650, lr=0.0000259 Time cost=4.1 Thoughput=12.19 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 13799/88641, Loss=1.5362, lr=0.0000259 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 13849/88641, Loss=1.1290, lr=0.0000260 Time cost=4.6 Thoughput=10.95 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 13899/88641, Loss=1.6912, lr=0.0000261 Time cost=4.1 Thoughput=12.22 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 13949/88641, Loss=1.7918, lr=0.0000262 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 13999/88641, Loss=0.9954, lr=0.0000263 Time cost=4.1 Thoughput=12.07 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 14049/88641, Loss=1.3840, lr=0.0000264 Time cost=4.2 Thoughput=11.94 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 14099/88641, Loss=1.1745, lr=0.0000265 Time cost=4.2 Thoughput=11.98 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 14149/88641, Loss=1.2717, lr=0.0000266 Time cost=4.1 Thoughput=12.05 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 14199/88641, Loss=1.3965, lr=0.0000267 Time cost=4.1 Thoughput=12.18 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 14249/88641, Loss=2.0557, lr=0.0000268 Time cost=4.1 Thoughput=12.18 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 14299/88641, Loss=1.2429, lr=0.0000269 Time cost=4.1 Thoughput=12.13 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 14349/88641, Loss=1.1342, lr=0.0000270 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 14399/88641, Loss=1.3921, lr=0.0000271 Time cost=4.1 Thoughput=12.29 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 14449/88641, Loss=1.4371, lr=0.0000272 Time cost=4.2 Thoughput=12.05 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 14499/88641, Loss=1.1823, lr=0.0000273 Time cost=4.2 Thoughput=12.04 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 14549/88641, Loss=0.9587, lr=0.0000274 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 14599/88641, Loss=2.1084, lr=0.0000275 Time cost=4.1 Thoughput=12.18 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 14649/88641, Loss=0.9709, lr=0.0000275 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 14699/88641, Loss=1.3924, lr=0.0000276 Time cost=4.1 Thoughput=12.18 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 14749/88641, Loss=1.3479, lr=0.0000277 Time cost=4.1 Thoughput=12.21 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 14799/88641, Loss=1.7299, lr=0.0000278 Time cost=4.1 Thoughput=12.20 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 14849/88641, Loss=1.3367, lr=0.0000279 Time cost=4.1 Thoughput=12.19 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 14899/88641, Loss=1.8966, lr=0.0000280 Time cost=4.1 Thoughput=12.22 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 14949/88641, Loss=1.4244, lr=0.0000281 Time cost=4.1 Thoughput=12.27 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 14999/88641, Loss=1.1858, lr=0.0000282 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 15049/88641, Loss=1.3501, lr=0.0000283 Time cost=4.1 Thoughput=12.21 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 15099/88641, Loss=1.3318, lr=0.0000284 Time cost=4.1 Thoughput=12.24 samples/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gluonnlp:Epoch: 0, Batch: 15149/88641, Loss=2.1788, lr=0.0000285 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 15199/88641, Loss=1.1626, lr=0.0000286 Time cost=4.1 Thoughput=12.06 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 15249/88641, Loss=1.7322, lr=0.0000287 Time cost=4.2 Thoughput=12.02 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 15299/88641, Loss=1.3035, lr=0.0000288 Time cost=4.2 Thoughput=12.01 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 15349/88641, Loss=0.9746, lr=0.0000289 Time cost=4.2 Thoughput=12.00 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 15399/88641, Loss=1.1667, lr=0.0000290 Time cost=4.1 Thoughput=12.22 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 15449/88641, Loss=1.1696, lr=0.0000291 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 15499/88641, Loss=1.2949, lr=0.0000291 Time cost=4.1 Thoughput=12.28 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 15549/88641, Loss=1.4785, lr=0.0000292 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 15599/88641, Loss=1.4122, lr=0.0000293 Time cost=4.1 Thoughput=12.18 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 15649/88641, Loss=1.6469, lr=0.0000294 Time cost=4.1 Thoughput=12.16 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 15699/88641, Loss=1.3682, lr=0.0000295 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 15749/88641, Loss=1.3830, lr=0.0000296 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 15799/88641, Loss=1.1830, lr=0.0000297 Time cost=4.1 Thoughput=12.28 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 15849/88641, Loss=1.8054, lr=0.0000298 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 15899/88641, Loss=1.5537, lr=0.0000299 Time cost=4.1 Thoughput=12.27 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 15949/88641, Loss=1.2928, lr=0.0000300 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 15999/88641, Loss=1.4573, lr=0.0000301 Time cost=4.1 Thoughput=12.28 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 16049/88641, Loss=1.1224, lr=0.0000302 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 16099/88641, Loss=1.2532, lr=0.0000303 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 16149/88641, Loss=1.4154, lr=0.0000304 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 16199/88641, Loss=1.5788, lr=0.0000305 Time cost=4.1 Thoughput=12.22 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 16249/88641, Loss=1.4539, lr=0.0000306 Time cost=4.2 Thoughput=12.04 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 16299/88641, Loss=1.5131, lr=0.0000306 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 16349/88641, Loss=1.1307, lr=0.0000307 Time cost=4.1 Thoughput=12.22 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 16399/88641, Loss=1.8453, lr=0.0000308 Time cost=4.1 Thoughput=12.15 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 16449/88641, Loss=1.7168, lr=0.0000309 Time cost=4.1 Thoughput=12.17 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 16499/88641, Loss=0.7015, lr=0.0000310 Time cost=4.1 Thoughput=12.28 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 16549/88641, Loss=1.2725, lr=0.0000311 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 16599/88641, Loss=1.5146, lr=0.0000312 Time cost=4.1 Thoughput=12.15 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 16649/88641, Loss=1.0083, lr=0.0000313 Time cost=4.2 Thoughput=11.79 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 16699/88641, Loss=1.9088, lr=0.0000314 Time cost=4.3 Thoughput=11.67 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 16749/88641, Loss=1.3524, lr=0.0000315 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 16799/88641, Loss=1.8547, lr=0.0000316 Time cost=4.1 Thoughput=12.28 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 16849/88641, Loss=1.3308, lr=0.0000317 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 16899/88641, Loss=1.6607, lr=0.0000318 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 16949/88641, Loss=1.2505, lr=0.0000319 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 16999/88641, Loss=1.3612, lr=0.0000320 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 17049/88641, Loss=0.8882, lr=0.0000321 Time cost=4.1 Thoughput=12.22 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 17099/88641, Loss=2.2006, lr=0.0000322 Time cost=4.1 Thoughput=12.27 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 17149/88641, Loss=1.2159, lr=0.0000322 Time cost=4.1 Thoughput=12.27 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 17199/88641, Loss=2.2146, lr=0.0000323 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 17249/88641, Loss=1.2057, lr=0.0000324 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 17299/88641, Loss=1.5299, lr=0.0000325 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 17349/88641, Loss=1.1994, lr=0.0000326 Time cost=4.1 Thoughput=12.27 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 17399/88641, Loss=2.0517, lr=0.0000327 Time cost=4.1 Thoughput=12.28 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 17449/88641, Loss=1.3855, lr=0.0000328 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 17499/88641, Loss=1.2080, lr=0.0000329 Time cost=4.1 Thoughput=12.29 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 17549/88641, Loss=0.9763, lr=0.0000330 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 17599/88641, Loss=1.1829, lr=0.0000331 Time cost=4.1 Thoughput=12.30 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 17649/88641, Loss=1.2150, lr=0.0000332 Time cost=4.1 Thoughput=12.15 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 17699/88641, Loss=1.7803, lr=0.0000333 Time cost=4.6 Thoughput=10.89 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 17749/88641, Loss=1.4097, lr=0.0000334 Time cost=4.1 Thoughput=12.21 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 17799/88641, Loss=1.6024, lr=0.0000335 Time cost=4.1 Thoughput=12.19 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 17849/88641, Loss=1.9019, lr=0.0000336 Time cost=4.1 Thoughput=12.22 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 17899/88641, Loss=1.5577, lr=0.0000337 Time cost=4.1 Thoughput=12.21 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 17949/88641, Loss=1.7929, lr=0.0000338 Time cost=4.1 Thoughput=12.21 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 17999/88641, Loss=1.3003, lr=0.0000338 Time cost=4.1 Thoughput=12.20 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 18049/88641, Loss=1.2501, lr=0.0000339 Time cost=4.1 Thoughput=12.22 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 18099/88641, Loss=1.5751, lr=0.0000340 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 18149/88641, Loss=1.9159, lr=0.0000341 Time cost=4.1 Thoughput=12.18 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 18199/88641, Loss=1.9233, lr=0.0000342 Time cost=4.1 Thoughput=12.17 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 18249/88641, Loss=1.6886, lr=0.0000343 Time cost=4.2 Thoughput=12.02 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 18299/88641, Loss=1.6420, lr=0.0000344 Time cost=4.1 Thoughput=12.10 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 18349/88641, Loss=1.1546, lr=0.0000345 Time cost=4.1 Thoughput=12.17 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 18399/88641, Loss=1.4911, lr=0.0000346 Time cost=4.1 Thoughput=12.17 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 18449/88641, Loss=1.7669, lr=0.0000347 Time cost=4.1 Thoughput=12.18 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 18499/88641, Loss=2.1096, lr=0.0000348 Time cost=4.1 Thoughput=12.18 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 18549/88641, Loss=2.0160, lr=0.0000349 Time cost=4.1 Thoughput=12.21 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 18599/88641, Loss=1.8125, lr=0.0000350 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 18649/88641, Loss=1.6317, lr=0.0000351 Time cost=4.2 Thoughput=11.99 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 18699/88641, Loss=1.3603, lr=0.0000352 Time cost=4.1 Thoughput=12.22 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 18749/88641, Loss=1.7228, lr=0.0000353 Time cost=4.1 Thoughput=12.22 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 18799/88641, Loss=1.1636, lr=0.0000353 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 18849/88641, Loss=1.3656, lr=0.0000354 Time cost=4.2 Thoughput=12.02 samples/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gluonnlp:Epoch: 0, Batch: 18899/88641, Loss=1.6568, lr=0.0000355 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 18949/88641, Loss=1.9663, lr=0.0000356 Time cost=4.1 Thoughput=12.27 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 18999/88641, Loss=1.1927, lr=0.0000357 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 19049/88641, Loss=1.3611, lr=0.0000358 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 19099/88641, Loss=1.4417, lr=0.0000359 Time cost=4.1 Thoughput=12.20 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 19149/88641, Loss=1.5373, lr=0.0000360 Time cost=4.1 Thoughput=12.14 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 19199/88641, Loss=1.2282, lr=0.0000361 Time cost=4.1 Thoughput=12.12 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 19249/88641, Loss=1.6397, lr=0.0000362 Time cost=4.1 Thoughput=12.19 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 19299/88641, Loss=1.1250, lr=0.0000363 Time cost=4.1 Thoughput=12.16 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 19349/88641, Loss=1.8819, lr=0.0000364 Time cost=4.1 Thoughput=12.16 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 19399/88641, Loss=1.3358, lr=0.0000365 Time cost=4.1 Thoughput=12.16 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 19449/88641, Loss=1.9617, lr=0.0000366 Time cost=4.1 Thoughput=12.21 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 19499/88641, Loss=1.1937, lr=0.0000367 Time cost=4.1 Thoughput=12.28 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 19549/88641, Loss=1.6653, lr=0.0000368 Time cost=4.1 Thoughput=12.20 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 19599/88641, Loss=2.0733, lr=0.0000369 Time cost=4.1 Thoughput=12.14 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 19649/88641, Loss=1.6333, lr=0.0000369 Time cost=4.2 Thoughput=12.02 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 19699/88641, Loss=1.8530, lr=0.0000370 Time cost=4.2 Thoughput=12.02 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 19749/88641, Loss=1.4217, lr=0.0000371 Time cost=4.1 Thoughput=12.14 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 19799/88641, Loss=1.5260, lr=0.0000372 Time cost=4.1 Thoughput=12.27 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 19849/88641, Loss=1.4486, lr=0.0000373 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 19899/88641, Loss=2.0748, lr=0.0000374 Time cost=4.1 Thoughput=12.21 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 19949/88641, Loss=1.2954, lr=0.0000375 Time cost=4.1 Thoughput=12.22 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 19999/88641, Loss=1.4247, lr=0.0000376 Time cost=4.1 Thoughput=12.21 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 20049/88641, Loss=1.6941, lr=0.0000377 Time cost=4.1 Thoughput=12.18 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 20099/88641, Loss=1.5214, lr=0.0000378 Time cost=4.2 Thoughput=11.92 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 20149/88641, Loss=0.9878, lr=0.0000379 Time cost=4.2 Thoughput=11.99 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 20199/88641, Loss=2.1325, lr=0.0000380 Time cost=4.2 Thoughput=11.98 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 20249/88641, Loss=1.7590, lr=0.0000381 Time cost=4.2 Thoughput=11.99 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 20299/88641, Loss=1.8638, lr=0.0000382 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 20349/88641, Loss=1.3376, lr=0.0000383 Time cost=4.1 Thoughput=12.28 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 20399/88641, Loss=1.1608, lr=0.0000384 Time cost=4.6 Thoughput=10.97 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 20449/88641, Loss=1.9119, lr=0.0000385 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 20499/88641, Loss=1.3593, lr=0.0000385 Time cost=4.1 Thoughput=12.30 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 20549/88641, Loss=1.6339, lr=0.0000386 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 20599/88641, Loss=1.8210, lr=0.0000387 Time cost=4.1 Thoughput=12.17 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 20649/88641, Loss=0.9217, lr=0.0000388 Time cost=4.1 Thoughput=12.13 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 20699/88641, Loss=1.9640, lr=0.0000389 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 20749/88641, Loss=1.6744, lr=0.0000390 Time cost=4.1 Thoughput=12.30 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 20799/88641, Loss=1.6158, lr=0.0000391 Time cost=4.1 Thoughput=12.15 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 20849/88641, Loss=1.7183, lr=0.0000392 Time cost=4.1 Thoughput=12.12 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 20899/88641, Loss=1.4958, lr=0.0000393 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 20949/88641, Loss=1.1618, lr=0.0000394 Time cost=4.1 Thoughput=12.29 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 20999/88641, Loss=1.5381, lr=0.0000395 Time cost=4.1 Thoughput=12.11 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 21049/88641, Loss=1.6548, lr=0.0000396 Time cost=4.3 Thoughput=11.61 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 21099/88641, Loss=1.6862, lr=0.0000397 Time cost=4.1 Thoughput=12.16 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 21149/88641, Loss=1.4908, lr=0.0000398 Time cost=4.1 Thoughput=12.27 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 21199/88641, Loss=1.2414, lr=0.0000399 Time cost=4.1 Thoughput=12.27 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 21249/88641, Loss=1.4916, lr=0.0000400 Time cost=4.1 Thoughput=12.27 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 21299/88641, Loss=1.7024, lr=0.0000400 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 21349/88641, Loss=1.2778, lr=0.0000401 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 21399/88641, Loss=1.5294, lr=0.0000402 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 21449/88641, Loss=1.9843, lr=0.0000403 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 21499/88641, Loss=1.8065, lr=0.0000404 Time cost=4.1 Thoughput=12.27 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 21549/88641, Loss=1.6915, lr=0.0000405 Time cost=4.1 Thoughput=12.28 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 21599/88641, Loss=1.4080, lr=0.0000406 Time cost=4.1 Thoughput=12.27 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 21649/88641, Loss=2.4539, lr=0.0000407 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 21699/88641, Loss=1.2455, lr=0.0000408 Time cost=4.1 Thoughput=12.18 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 21749/88641, Loss=2.0538, lr=0.0000409 Time cost=4.1 Thoughput=12.21 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 21799/88641, Loss=1.7472, lr=0.0000410 Time cost=4.1 Thoughput=12.20 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 21849/88641, Loss=1.9603, lr=0.0000411 Time cost=4.1 Thoughput=12.22 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 21899/88641, Loss=1.6128, lr=0.0000412 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 21949/88641, Loss=1.3307, lr=0.0000413 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 21999/88641, Loss=1.3191, lr=0.0000414 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 22049/88641, Loss=1.6707, lr=0.0000415 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 22099/88641, Loss=1.7964, lr=0.0000416 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 22149/88641, Loss=1.7485, lr=0.0000416 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 22199/88641, Loss=1.6792, lr=0.0000417 Time cost=4.1 Thoughput=12.20 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 22249/88641, Loss=1.3266, lr=0.0000418 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 22299/88641, Loss=2.8256, lr=0.0000419 Time cost=4.1 Thoughput=12.17 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 22349/88641, Loss=1.4960, lr=0.0000420 Time cost=4.1 Thoughput=12.17 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 22399/88641, Loss=1.6726, lr=0.0000421 Time cost=4.2 Thoughput=11.92 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 22449/88641, Loss=1.5131, lr=0.0000422 Time cost=4.1 Thoughput=12.07 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 22499/88641, Loss=1.8004, lr=0.0000423 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 22549/88641, Loss=2.1317, lr=0.0000424 Time cost=4.1 Thoughput=12.22 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 22599/88641, Loss=1.4471, lr=0.0000425 Time cost=4.1 Thoughput=12.27 samples/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gluonnlp:Epoch: 0, Batch: 22649/88641, Loss=2.0125, lr=0.0000426 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 22699/88641, Loss=1.6710, lr=0.0000427 Time cost=4.1 Thoughput=12.27 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 22749/88641, Loss=1.8365, lr=0.0000428 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 22799/88641, Loss=1.6007, lr=0.0000429 Time cost=4.1 Thoughput=12.14 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 22849/88641, Loss=1.2620, lr=0.0000430 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 22899/88641, Loss=1.5063, lr=0.0000431 Time cost=4.1 Thoughput=12.27 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 22949/88641, Loss=1.2442, lr=0.0000432 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 22999/88641, Loss=1.2672, lr=0.0000432 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 23049/88641, Loss=1.6810, lr=0.0000433 Time cost=4.1 Thoughput=12.20 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 23099/88641, Loss=2.0138, lr=0.0000434 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 23149/88641, Loss=1.7267, lr=0.0000435 Time cost=4.1 Thoughput=12.21 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 23199/88641, Loss=1.9896, lr=0.0000436 Time cost=4.2 Thoughput=11.95 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 23249/88641, Loss=1.5743, lr=0.0000437 Time cost=4.1 Thoughput=12.13 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 23299/88641, Loss=2.1826, lr=0.0000438 Time cost=4.1 Thoughput=12.17 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 23349/88641, Loss=1.6076, lr=0.0000439 Time cost=4.1 Thoughput=12.16 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 23399/88641, Loss=2.2425, lr=0.0000440 Time cost=4.1 Thoughput=12.18 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 23449/88641, Loss=1.5748, lr=0.0000441 Time cost=4.1 Thoughput=12.20 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 23499/88641, Loss=0.9161, lr=0.0000442 Time cost=4.1 Thoughput=12.14 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 23549/88641, Loss=1.9169, lr=0.0000443 Time cost=4.1 Thoughput=12.10 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 23599/88641, Loss=1.8563, lr=0.0000444 Time cost=4.1 Thoughput=12.15 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 23649/88641, Loss=1.3286, lr=0.0000445 Time cost=4.1 Thoughput=12.22 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 23699/88641, Loss=1.4492, lr=0.0000446 Time cost=4.1 Thoughput=12.17 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 23749/88641, Loss=2.0178, lr=0.0000447 Time cost=4.1 Thoughput=12.15 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 23799/88641, Loss=1.7474, lr=0.0000448 Time cost=4.1 Thoughput=12.19 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 23849/88641, Loss=2.0223, lr=0.0000448 Time cost=4.1 Thoughput=12.19 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 23899/88641, Loss=1.9513, lr=0.0000449 Time cost=4.2 Thoughput=11.81 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 23949/88641, Loss=1.8209, lr=0.0000450 Time cost=4.2 Thoughput=11.98 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 23999/88641, Loss=1.2873, lr=0.0000451 Time cost=4.2 Thoughput=11.96 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 24049/88641, Loss=1.4336, lr=0.0000452 Time cost=4.2 Thoughput=11.94 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 24099/88641, Loss=1.6912, lr=0.0000453 Time cost=4.1 Thoughput=12.13 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 24149/88641, Loss=1.5286, lr=0.0000454 Time cost=4.1 Thoughput=12.22 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 24199/88641, Loss=2.0828, lr=0.0000455 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 24249/88641, Loss=1.6313, lr=0.0000456 Time cost=4.6 Thoughput=10.93 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 24299/88641, Loss=1.4567, lr=0.0000457 Time cost=4.1 Thoughput=12.29 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 24349/88641, Loss=2.5945, lr=0.0000458 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 24399/88641, Loss=1.9801, lr=0.0000459 Time cost=4.1 Thoughput=12.27 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 24449/88641, Loss=1.8878, lr=0.0000460 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 24499/88641, Loss=1.5801, lr=0.0000461 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 24549/88641, Loss=2.1490, lr=0.0000462 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 24599/88641, Loss=2.1898, lr=0.0000463 Time cost=4.2 Thoughput=12.01 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 24649/88641, Loss=1.8984, lr=0.0000463 Time cost=4.2 Thoughput=12.02 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 24699/88641, Loss=2.1335, lr=0.0000464 Time cost=4.2 Thoughput=11.99 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 24749/88641, Loss=1.6273, lr=0.0000465 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 24799/88641, Loss=1.9552, lr=0.0000466 Time cost=4.1 Thoughput=12.22 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 24849/88641, Loss=2.5915, lr=0.0000467 Time cost=4.2 Thoughput=11.79 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 24899/88641, Loss=1.7054, lr=0.0000468 Time cost=4.1 Thoughput=12.21 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 24949/88641, Loss=1.9436, lr=0.0000469 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 24999/88641, Loss=2.0125, lr=0.0000470 Time cost=4.1 Thoughput=12.17 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 25049/88641, Loss=1.8198, lr=0.0000471 Time cost=4.1 Thoughput=12.18 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 25099/88641, Loss=2.3063, lr=0.0000472 Time cost=4.1 Thoughput=12.17 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 25149/88641, Loss=1.6069, lr=0.0000473 Time cost=4.1 Thoughput=12.21 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 25199/88641, Loss=1.6405, lr=0.0000474 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 25249/88641, Loss=2.6610, lr=0.0000475 Time cost=4.1 Thoughput=12.16 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 25299/88641, Loss=1.4214, lr=0.0000476 Time cost=4.1 Thoughput=12.20 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 25349/88641, Loss=1.7797, lr=0.0000477 Time cost=4.2 Thoughput=12.00 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 25399/88641, Loss=2.5497, lr=0.0000478 Time cost=4.2 Thoughput=11.85 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 25449/88641, Loss=2.1768, lr=0.0000479 Time cost=4.1 Thoughput=12.18 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 25499/88641, Loss=1.1537, lr=0.0000479 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 25549/88641, Loss=2.6394, lr=0.0000480 Time cost=4.2 Thoughput=11.86 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 25599/88641, Loss=1.7962, lr=0.0000481 Time cost=4.1 Thoughput=12.13 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 25649/88641, Loss=1.9107, lr=0.0000482 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 25699/88641, Loss=1.7100, lr=0.0000483 Time cost=4.1 Thoughput=12.18 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 25749/88641, Loss=2.3908, lr=0.0000484 Time cost=4.1 Thoughput=12.16 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 25799/88641, Loss=2.1639, lr=0.0000485 Time cost=4.1 Thoughput=12.12 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 25849/88641, Loss=1.7001, lr=0.0000486 Time cost=4.2 Thoughput=11.81 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 25899/88641, Loss=1.7320, lr=0.0000487 Time cost=4.1 Thoughput=12.10 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 25949/88641, Loss=1.8465, lr=0.0000488 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 25999/88641, Loss=1.7430, lr=0.0000489 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 26049/88641, Loss=1.9866, lr=0.0000490 Time cost=4.1 Thoughput=12.19 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 26099/88641, Loss=2.3176, lr=0.0000491 Time cost=4.1 Thoughput=12.11 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 26149/88641, Loss=1.8646, lr=0.0000492 Time cost=4.2 Thoughput=12.02 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 26199/88641, Loss=1.6446, lr=0.0000493 Time cost=4.1 Thoughput=12.18 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 26249/88641, Loss=2.2506, lr=0.0000494 Time cost=4.1 Thoughput=12.21 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 26299/88641, Loss=2.0452, lr=0.0000495 Time cost=4.1 Thoughput=12.21 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 26349/88641, Loss=2.0019, lr=0.0000495 Time cost=4.1 Thoughput=12.24 samples/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gluonnlp:Epoch: 0, Batch: 26399/88641, Loss=2.4368, lr=0.0000496 Time cost=4.1 Thoughput=12.27 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 26449/88641, Loss=1.7032, lr=0.0000497 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 26499/88641, Loss=2.0771, lr=0.0000498 Time cost=4.1 Thoughput=12.20 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 26549/88641, Loss=1.8851, lr=0.0000499 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 26599/88641, Loss=1.9358, lr=0.0000500 Time cost=4.1 Thoughput=12.27 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 26649/88641, Loss=1.3837, lr=0.0000500 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 26699/88641, Loss=2.0859, lr=0.0000500 Time cost=4.1 Thoughput=12.20 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 26749/88641, Loss=1.7014, lr=0.0000500 Time cost=4.2 Thoughput=11.94 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 26799/88641, Loss=1.7931, lr=0.0000500 Time cost=4.2 Thoughput=11.93 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 26849/88641, Loss=1.7849, lr=0.0000499 Time cost=4.2 Thoughput=11.94 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 26899/88641, Loss=1.8910, lr=0.0000499 Time cost=4.2 Thoughput=11.94 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 26949/88641, Loss=1.4852, lr=0.0000499 Time cost=4.7 Thoughput=10.69 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 26999/88641, Loss=1.7786, lr=0.0000499 Time cost=4.2 Thoughput=12.05 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 27049/88641, Loss=2.2244, lr=0.0000499 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 27099/88641, Loss=1.6674, lr=0.0000499 Time cost=4.1 Thoughput=12.10 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 27149/88641, Loss=1.8133, lr=0.0000499 Time cost=4.2 Thoughput=12.04 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 27199/88641, Loss=2.6760, lr=0.0000499 Time cost=4.1 Thoughput=12.08 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 27249/88641, Loss=2.3292, lr=0.0000499 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 27299/88641, Loss=1.7345, lr=0.0000499 Time cost=4.1 Thoughput=12.12 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 27349/88641, Loss=1.7853, lr=0.0000498 Time cost=4.1 Thoughput=12.29 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 27399/88641, Loss=2.5850, lr=0.0000498 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 27449/88641, Loss=1.5722, lr=0.0000498 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 27499/88641, Loss=1.9074, lr=0.0000498 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 27549/88641, Loss=1.6714, lr=0.0000498 Time cost=4.1 Thoughput=12.11 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 27599/88641, Loss=2.0311, lr=0.0000498 Time cost=4.2 Thoughput=11.81 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 27649/88641, Loss=2.1574, lr=0.0000498 Time cost=4.1 Thoughput=12.19 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 27699/88641, Loss=1.8405, lr=0.0000498 Time cost=4.1 Thoughput=12.07 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 27749/88641, Loss=2.0234, lr=0.0000498 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 27799/88641, Loss=1.7850, lr=0.0000497 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 27849/88641, Loss=2.1069, lr=0.0000497 Time cost=4.1 Thoughput=12.28 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 27899/88641, Loss=2.0934, lr=0.0000497 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 27949/88641, Loss=1.8204, lr=0.0000497 Time cost=4.1 Thoughput=12.27 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 27999/88641, Loss=1.9503, lr=0.0000497 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 28049/88641, Loss=1.9419, lr=0.0000497 Time cost=4.2 Thoughput=12.04 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 28099/88641, Loss=1.9970, lr=0.0000497 Time cost=4.2 Thoughput=12.01 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 28149/88641, Loss=1.9976, lr=0.0000497 Time cost=4.1 Thoughput=12.19 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 28199/88641, Loss=1.9131, lr=0.0000497 Time cost=4.1 Thoughput=12.30 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 28249/88641, Loss=1.9850, lr=0.0000497 Time cost=4.1 Thoughput=12.29 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 28299/88641, Loss=2.2735, lr=0.0000496 Time cost=4.1 Thoughput=12.28 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 28349/88641, Loss=1.8334, lr=0.0000496 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 28399/88641, Loss=2.2610, lr=0.0000496 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 28449/88641, Loss=2.2288, lr=0.0000496 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 28499/88641, Loss=1.4327, lr=0.0000496 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 28549/88641, Loss=1.7710, lr=0.0000496 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 28599/88641, Loss=1.6690, lr=0.0000496 Time cost=4.2 Thoughput=12.01 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 28649/88641, Loss=2.5159, lr=0.0000496 Time cost=4.2 Thoughput=11.99 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 28699/88641, Loss=2.0302, lr=0.0000496 Time cost=4.2 Thoughput=11.99 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 28749/88641, Loss=1.6784, lr=0.0000495 Time cost=4.2 Thoughput=11.97 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 28799/88641, Loss=2.0031, lr=0.0000495 Time cost=4.2 Thoughput=11.98 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 28849/88641, Loss=1.8926, lr=0.0000495 Time cost=4.2 Thoughput=12.05 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 28899/88641, Loss=3.0314, lr=0.0000495 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 28949/88641, Loss=1.8655, lr=0.0000495 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 28999/88641, Loss=1.5572, lr=0.0000495 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 29049/88641, Loss=2.1422, lr=0.0000495 Time cost=4.1 Thoughput=12.21 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 29099/88641, Loss=1.1384, lr=0.0000495 Time cost=4.2 Thoughput=11.87 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 29149/88641, Loss=1.6591, lr=0.0000495 Time cost=4.2 Thoughput=11.82 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 29199/88641, Loss=2.0599, lr=0.0000495 Time cost=4.1 Thoughput=12.18 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 29249/88641, Loss=2.2282, lr=0.0000494 Time cost=4.1 Thoughput=12.22 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 29299/88641, Loss=1.9505, lr=0.0000494 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 29349/88641, Loss=2.0715, lr=0.0000494 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 29399/88641, Loss=2.0261, lr=0.0000494 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 29449/88641, Loss=1.8581, lr=0.0000494 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 29499/88641, Loss=2.2325, lr=0.0000494 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 29549/88641, Loss=1.9365, lr=0.0000494 Time cost=4.1 Thoughput=12.21 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 29599/88641, Loss=1.8380, lr=0.0000494 Time cost=4.1 Thoughput=12.20 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 29649/88641, Loss=2.0680, lr=0.0000494 Time cost=4.1 Thoughput=12.18 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 29699/88641, Loss=1.5616, lr=0.0000494 Time cost=4.1 Thoughput=12.20 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 29749/88641, Loss=1.9560, lr=0.0000493 Time cost=4.2 Thoughput=11.90 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 29799/88641, Loss=1.6801, lr=0.0000493 Time cost=4.1 Thoughput=12.16 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 29849/88641, Loss=2.3007, lr=0.0000493 Time cost=4.1 Thoughput=12.19 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 29899/88641, Loss=1.6498, lr=0.0000493 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 29949/88641, Loss=1.7626, lr=0.0000493 Time cost=4.1 Thoughput=12.21 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 29999/88641, Loss=1.4395, lr=0.0000493 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 30049/88641, Loss=1.7182, lr=0.0000493 Time cost=4.1 Thoughput=12.10 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 30099/88641, Loss=2.1893, lr=0.0000493 Time cost=4.2 Thoughput=12.04 samples/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gluonnlp:Epoch: 0, Batch: 30149/88641, Loss=2.0343, lr=0.0000493 Time cost=4.1 Thoughput=12.08 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 30199/88641, Loss=1.9917, lr=0.0000492 Time cost=4.1 Thoughput=12.18 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 30249/88641, Loss=1.7873, lr=0.0000492 Time cost=4.1 Thoughput=12.19 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 30299/88641, Loss=1.6265, lr=0.0000492 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 30349/88641, Loss=2.1594, lr=0.0000492 Time cost=4.1 Thoughput=12.22 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 30399/88641, Loss=2.5669, lr=0.0000492 Time cost=4.1 Thoughput=12.21 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 30449/88641, Loss=1.5214, lr=0.0000492 Time cost=4.1 Thoughput=12.20 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 30499/88641, Loss=2.2081, lr=0.0000492 Time cost=4.1 Thoughput=12.22 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 30549/88641, Loss=2.3224, lr=0.0000492 Time cost=4.1 Thoughput=12.21 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 30599/88641, Loss=1.8878, lr=0.0000492 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 30649/88641, Loss=2.1492, lr=0.0000492 Time cost=4.1 Thoughput=12.18 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 30699/88641, Loss=1.4477, lr=0.0000491 Time cost=4.1 Thoughput=12.20 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 30749/88641, Loss=2.1281, lr=0.0000491 Time cost=4.1 Thoughput=12.18 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 30799/88641, Loss=2.1059, lr=0.0000491 Time cost=4.6 Thoughput=10.87 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 30849/88641, Loss=1.6261, lr=0.0000491 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 30899/88641, Loss=1.6290, lr=0.0000491 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 30949/88641, Loss=2.1185, lr=0.0000491 Time cost=4.1 Thoughput=12.28 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 30999/88641, Loss=2.0909, lr=0.0000491 Time cost=4.1 Thoughput=12.28 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 31049/88641, Loss=1.9054, lr=0.0000491 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 31099/88641, Loss=2.3033, lr=0.0000491 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 31149/88641, Loss=1.8545, lr=0.0000490 Time cost=4.2 Thoughput=11.96 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 31199/88641, Loss=1.6834, lr=0.0000490 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 31249/88641, Loss=1.6281, lr=0.0000490 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 31299/88641, Loss=1.6671, lr=0.0000490 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 31349/88641, Loss=1.8455, lr=0.0000490 Time cost=4.1 Thoughput=12.19 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 31399/88641, Loss=1.6991, lr=0.0000490 Time cost=4.1 Thoughput=12.19 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 31449/88641, Loss=1.6405, lr=0.0000490 Time cost=4.1 Thoughput=12.17 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 31499/88641, Loss=2.0765, lr=0.0000490 Time cost=4.1 Thoughput=12.19 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 31549/88641, Loss=2.2976, lr=0.0000490 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 31599/88641, Loss=2.1668, lr=0.0000490 Time cost=4.1 Thoughput=12.29 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 31649/88641, Loss=2.0736, lr=0.0000489 Time cost=4.1 Thoughput=12.22 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 31699/88641, Loss=1.6137, lr=0.0000489 Time cost=4.1 Thoughput=12.29 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 31749/88641, Loss=1.5261, lr=0.0000489 Time cost=4.2 Thoughput=12.01 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 31799/88641, Loss=2.3900, lr=0.0000489 Time cost=4.2 Thoughput=11.98 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 31849/88641, Loss=1.4931, lr=0.0000489 Time cost=4.2 Thoughput=11.97 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 31899/88641, Loss=1.7358, lr=0.0000489 Time cost=4.2 Thoughput=12.04 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 31949/88641, Loss=2.0109, lr=0.0000489 Time cost=4.2 Thoughput=11.97 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 31999/88641, Loss=2.3862, lr=0.0000489 Time cost=4.2 Thoughput=11.90 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 32049/88641, Loss=2.1364, lr=0.0000489 Time cost=4.2 Thoughput=11.97 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 32099/88641, Loss=2.2575, lr=0.0000488 Time cost=4.1 Thoughput=12.28 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 32149/88641, Loss=2.0267, lr=0.0000488 Time cost=4.1 Thoughput=12.27 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 32199/88641, Loss=1.6764, lr=0.0000488 Time cost=4.1 Thoughput=12.29 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 32249/88641, Loss=1.6234, lr=0.0000488 Time cost=4.1 Thoughput=12.27 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 32299/88641, Loss=2.2092, lr=0.0000488 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 32349/88641, Loss=2.1258, lr=0.0000488 Time cost=4.1 Thoughput=12.27 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 32399/88641, Loss=1.6157, lr=0.0000488 Time cost=4.1 Thoughput=12.27 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 32449/88641, Loss=2.1504, lr=0.0000488 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 32499/88641, Loss=1.3379, lr=0.0000488 Time cost=4.2 Thoughput=11.96 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 32549/88641, Loss=2.2901, lr=0.0000488 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 32599/88641, Loss=2.0086, lr=0.0000487 Time cost=4.1 Thoughput=12.22 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 32649/88641, Loss=1.7704, lr=0.0000487 Time cost=4.1 Thoughput=12.22 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 32699/88641, Loss=2.6051, lr=0.0000487 Time cost=4.1 Thoughput=12.19 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 32749/88641, Loss=1.3781, lr=0.0000487 Time cost=4.1 Thoughput=12.20 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 32799/88641, Loss=2.1822, lr=0.0000487 Time cost=4.2 Thoughput=11.97 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 32849/88641, Loss=1.9412, lr=0.0000487 Time cost=4.2 Thoughput=11.90 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 32899/88641, Loss=1.6154, lr=0.0000487 Time cost=4.1 Thoughput=12.22 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 32949/88641, Loss=1.4866, lr=0.0000487 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 32999/88641, Loss=2.1929, lr=0.0000487 Time cost=4.1 Thoughput=12.15 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 33049/88641, Loss=2.3216, lr=0.0000487 Time cost=4.1 Thoughput=12.13 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 33099/88641, Loss=1.5414, lr=0.0000486 Time cost=4.1 Thoughput=12.15 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 33149/88641, Loss=1.6320, lr=0.0000486 Time cost=4.1 Thoughput=12.18 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 33199/88641, Loss=1.7454, lr=0.0000486 Time cost=4.1 Thoughput=12.16 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 33249/88641, Loss=2.1845, lr=0.0000486 Time cost=4.1 Thoughput=12.11 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 33299/88641, Loss=2.1804, lr=0.0000486 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 33349/88641, Loss=1.6136, lr=0.0000486 Time cost=4.1 Thoughput=12.17 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 33399/88641, Loss=2.6858, lr=0.0000486 Time cost=4.2 Thoughput=12.04 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 33449/88641, Loss=1.9269, lr=0.0000486 Time cost=4.2 Thoughput=12.03 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 33499/88641, Loss=1.8414, lr=0.0000486 Time cost=4.7 Thoughput=10.74 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 33549/88641, Loss=1.9735, lr=0.0000485 Time cost=4.2 Thoughput=11.90 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 33599/88641, Loss=1.8505, lr=0.0000485 Time cost=4.2 Thoughput=11.84 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 33649/88641, Loss=1.6404, lr=0.0000485 Time cost=4.2 Thoughput=11.92 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 33699/88641, Loss=1.8095, lr=0.0000485 Time cost=4.1 Thoughput=12.28 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 33749/88641, Loss=2.2415, lr=0.0000485 Time cost=4.1 Thoughput=12.27 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 33799/88641, Loss=1.6267, lr=0.0000485 Time cost=4.1 Thoughput=12.27 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 33849/88641, Loss=2.4917, lr=0.0000485 Time cost=4.1 Thoughput=12.24 samples/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gluonnlp:Epoch: 0, Batch: 33899/88641, Loss=1.8574, lr=0.0000485 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 33949/88641, Loss=1.9037, lr=0.0000485 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 33999/88641, Loss=1.7972, lr=0.0000485 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 34049/88641, Loss=1.3396, lr=0.0000484 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 34099/88641, Loss=1.9498, lr=0.0000484 Time cost=4.1 Thoughput=12.20 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 34149/88641, Loss=2.2625, lr=0.0000484 Time cost=4.2 Thoughput=11.99 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 34199/88641, Loss=1.4953, lr=0.0000484 Time cost=4.1 Thoughput=12.16 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 34249/88641, Loss=1.9169, lr=0.0000484 Time cost=4.1 Thoughput=12.22 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 34299/88641, Loss=2.8526, lr=0.0000484 Time cost=4.1 Thoughput=12.22 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 34349/88641, Loss=1.8767, lr=0.0000484 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 34399/88641, Loss=2.1742, lr=0.0000484 Time cost=4.1 Thoughput=12.20 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 34449/88641, Loss=2.1073, lr=0.0000484 Time cost=4.1 Thoughput=12.22 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 34499/88641, Loss=2.1173, lr=0.0000483 Time cost=4.1 Thoughput=12.22 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 34549/88641, Loss=1.8637, lr=0.0000483 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 34599/88641, Loss=2.4444, lr=0.0000483 Time cost=4.1 Thoughput=12.08 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 34649/88641, Loss=2.0993, lr=0.0000483 Time cost=4.2 Thoughput=11.99 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 34699/88641, Loss=2.1342, lr=0.0000483 Time cost=4.1 Thoughput=12.14 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 34749/88641, Loss=1.4871, lr=0.0000483 Time cost=4.1 Thoughput=12.21 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 34799/88641, Loss=2.1170, lr=0.0000483 Time cost=4.1 Thoughput=12.22 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 34849/88641, Loss=1.7339, lr=0.0000483 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 34899/88641, Loss=2.2047, lr=0.0000483 Time cost=4.1 Thoughput=12.08 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 34949/88641, Loss=1.9275, lr=0.0000483 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 34999/88641, Loss=1.8818, lr=0.0000482 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 35049/88641, Loss=1.7844, lr=0.0000482 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 35099/88641, Loss=2.1943, lr=0.0000482 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 35149/88641, Loss=2.5637, lr=0.0000482 Time cost=4.1 Thoughput=12.21 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 35199/88641, Loss=2.0969, lr=0.0000482 Time cost=4.2 Thoughput=12.05 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 35249/88641, Loss=2.6862, lr=0.0000482 Time cost=4.2 Thoughput=11.99 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 35299/88641, Loss=2.1351, lr=0.0000482 Time cost=4.2 Thoughput=11.98 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 35349/88641, Loss=2.0103, lr=0.0000482 Time cost=4.2 Thoughput=12.03 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 35399/88641, Loss=1.7108, lr=0.0000482 Time cost=4.1 Thoughput=12.10 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 35449/88641, Loss=1.6089, lr=0.0000481 Time cost=4.1 Thoughput=12.14 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 35499/88641, Loss=2.5129, lr=0.0000481 Time cost=4.1 Thoughput=12.20 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 35549/88641, Loss=2.1098, lr=0.0000481 Time cost=4.1 Thoughput=12.19 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 35599/88641, Loss=2.0436, lr=0.0000481 Time cost=4.3 Thoughput=11.75 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 35649/88641, Loss=2.3980, lr=0.0000481 Time cost=4.1 Thoughput=12.22 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 35699/88641, Loss=1.7522, lr=0.0000481 Time cost=4.1 Thoughput=12.17 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 35749/88641, Loss=2.3425, lr=0.0000481 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 35799/88641, Loss=1.9257, lr=0.0000481 Time cost=4.1 Thoughput=12.21 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 35849/88641, Loss=2.2262, lr=0.0000481 Time cost=4.1 Thoughput=12.19 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 35899/88641, Loss=2.1408, lr=0.0000481 Time cost=4.1 Thoughput=12.12 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 35949/88641, Loss=2.3620, lr=0.0000480 Time cost=4.2 Thoughput=12.03 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 35999/88641, Loss=2.1656, lr=0.0000480 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 36049/88641, Loss=2.3203, lr=0.0000480 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 36099/88641, Loss=1.6330, lr=0.0000480 Time cost=4.2 Thoughput=11.97 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 36149/88641, Loss=2.0279, lr=0.0000480 Time cost=4.1 Thoughput=12.11 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 36199/88641, Loss=2.2798, lr=0.0000480 Time cost=4.1 Thoughput=12.22 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 36249/88641, Loss=1.7367, lr=0.0000480 Time cost=4.1 Thoughput=12.14 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 36299/88641, Loss=2.2591, lr=0.0000480 Time cost=4.2 Thoughput=11.99 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 36349/88641, Loss=1.6536, lr=0.0000480 Time cost=4.3 Thoughput=11.74 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 36399/88641, Loss=1.5986, lr=0.0000480 Time cost=4.2 Thoughput=11.85 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 36449/88641, Loss=2.3751, lr=0.0000479 Time cost=4.2 Thoughput=11.80 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 36499/88641, Loss=1.3512, lr=0.0000479 Time cost=4.1 Thoughput=12.22 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 36549/88641, Loss=2.2607, lr=0.0000479 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 36599/88641, Loss=2.1264, lr=0.0000479 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 36649/88641, Loss=2.1978, lr=0.0000479 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 36699/88641, Loss=2.2720, lr=0.0000479 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 36749/88641, Loss=1.9297, lr=0.0000479 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 36799/88641, Loss=2.4733, lr=0.0000479 Time cost=4.1 Thoughput=12.10 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 36849/88641, Loss=1.9333, lr=0.0000479 Time cost=4.1 Thoughput=12.20 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 36899/88641, Loss=2.0625, lr=0.0000478 Time cost=4.1 Thoughput=12.10 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 36949/88641, Loss=1.7667, lr=0.0000478 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 36999/88641, Loss=2.2516, lr=0.0000478 Time cost=4.1 Thoughput=12.18 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 37049/88641, Loss=2.2194, lr=0.0000478 Time cost=4.1 Thoughput=12.21 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 37099/88641, Loss=1.5916, lr=0.0000478 Time cost=4.1 Thoughput=12.21 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 37149/88641, Loss=2.5558, lr=0.0000478 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 37199/88641, Loss=2.2953, lr=0.0000478 Time cost=4.1 Thoughput=12.20 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 37249/88641, Loss=2.1995, lr=0.0000478 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 37299/88641, Loss=1.9030, lr=0.0000478 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 37349/88641, Loss=2.3110, lr=0.0000478 Time cost=4.6 Thoughput=10.87 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 37399/88641, Loss=1.8344, lr=0.0000477 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 37449/88641, Loss=2.4839, lr=0.0000477 Time cost=4.1 Thoughput=12.17 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 37499/88641, Loss=2.2395, lr=0.0000477 Time cost=4.1 Thoughput=12.18 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 37549/88641, Loss=1.8552, lr=0.0000477 Time cost=4.1 Thoughput=12.20 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 37599/88641, Loss=2.3970, lr=0.0000477 Time cost=4.1 Thoughput=12.20 samples/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gluonnlp:Epoch: 0, Batch: 37649/88641, Loss=1.7576, lr=0.0000477 Time cost=4.1 Thoughput=12.27 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 37699/88641, Loss=2.1445, lr=0.0000477 Time cost=4.1 Thoughput=12.27 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 37749/88641, Loss=2.1158, lr=0.0000477 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 37799/88641, Loss=2.0637, lr=0.0000477 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 37849/88641, Loss=2.1947, lr=0.0000476 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 37899/88641, Loss=1.8968, lr=0.0000476 Time cost=4.3 Thoughput=11.62 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 37949/88641, Loss=2.3330, lr=0.0000476 Time cost=4.1 Thoughput=12.19 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 37999/88641, Loss=2.0611, lr=0.0000476 Time cost=4.1 Thoughput=12.15 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 38049/88641, Loss=1.7274, lr=0.0000476 Time cost=4.1 Thoughput=12.09 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 38099/88641, Loss=2.0281, lr=0.0000476 Time cost=4.1 Thoughput=12.20 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 38149/88641, Loss=2.0839, lr=0.0000476 Time cost=4.1 Thoughput=12.21 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 38199/88641, Loss=2.1941, lr=0.0000476 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 38249/88641, Loss=2.1409, lr=0.0000476 Time cost=4.1 Thoughput=12.10 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 38299/88641, Loss=2.2462, lr=0.0000476 Time cost=4.1 Thoughput=12.18 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 38349/88641, Loss=2.2635, lr=0.0000475 Time cost=4.1 Thoughput=12.14 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 38399/88641, Loss=2.3132, lr=0.0000475 Time cost=4.1 Thoughput=12.20 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 38449/88641, Loss=1.9371, lr=0.0000475 Time cost=4.1 Thoughput=12.20 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 38499/88641, Loss=1.8611, lr=0.0000475 Time cost=4.2 Thoughput=11.81 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 38549/88641, Loss=2.4636, lr=0.0000475 Time cost=4.1 Thoughput=12.16 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 38599/88641, Loss=1.6100, lr=0.0000475 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 38649/88641, Loss=1.8934, lr=0.0000475 Time cost=4.1 Thoughput=12.27 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 38699/88641, Loss=2.0690, lr=0.0000475 Time cost=4.1 Thoughput=12.27 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 38749/88641, Loss=1.3436, lr=0.0000475 Time cost=4.1 Thoughput=12.28 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 38799/88641, Loss=2.4067, lr=0.0000474 Time cost=4.1 Thoughput=12.29 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 38849/88641, Loss=2.3370, lr=0.0000474 Time cost=4.1 Thoughput=12.27 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 38899/88641, Loss=1.7274, lr=0.0000474 Time cost=4.2 Thoughput=12.01 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 38949/88641, Loss=2.6338, lr=0.0000474 Time cost=4.2 Thoughput=12.03 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 38999/88641, Loss=2.3009, lr=0.0000474 Time cost=4.2 Thoughput=12.04 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 39049/88641, Loss=2.7732, lr=0.0000474 Time cost=4.2 Thoughput=12.00 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 39099/88641, Loss=1.6285, lr=0.0000474 Time cost=4.2 Thoughput=12.00 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 39149/88641, Loss=2.4138, lr=0.0000474 Time cost=4.1 Thoughput=12.16 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 39199/88641, Loss=1.8233, lr=0.0000474 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 39249/88641, Loss=1.9263, lr=0.0000474 Time cost=4.1 Thoughput=12.28 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 39299/88641, Loss=1.9358, lr=0.0000473 Time cost=4.1 Thoughput=12.29 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 39349/88641, Loss=1.9268, lr=0.0000473 Time cost=4.1 Thoughput=12.27 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 39399/88641, Loss=2.2730, lr=0.0000473 Time cost=4.1 Thoughput=12.29 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 39449/88641, Loss=1.5191, lr=0.0000473 Time cost=4.1 Thoughput=12.27 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 39499/88641, Loss=1.8370, lr=0.0000473 Time cost=4.1 Thoughput=12.20 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 39549/88641, Loss=1.6383, lr=0.0000473 Time cost=4.2 Thoughput=11.96 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 39599/88641, Loss=2.1924, lr=0.0000473 Time cost=4.2 Thoughput=11.94 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 39649/88641, Loss=1.4153, lr=0.0000473 Time cost=4.2 Thoughput=11.93 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 39699/88641, Loss=1.9078, lr=0.0000473 Time cost=4.2 Thoughput=11.77 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 39749/88641, Loss=2.3946, lr=0.0000473 Time cost=4.2 Thoughput=11.93 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 39799/88641, Loss=1.8111, lr=0.0000472 Time cost=4.2 Thoughput=11.91 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 39849/88641, Loss=1.7882, lr=0.0000472 Time cost=4.2 Thoughput=11.96 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 39899/88641, Loss=2.5260, lr=0.0000472 Time cost=4.7 Thoughput=10.72 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 39949/88641, Loss=1.8802, lr=0.0000472 Time cost=4.3 Thoughput=11.67 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 39999/88641, Loss=1.7979, lr=0.0000472 Time cost=4.1 Thoughput=12.17 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 40049/88641, Loss=2.5229, lr=0.0000472 Time cost=4.6 Thoughput=10.93 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 40099/88641, Loss=1.7361, lr=0.0000472 Time cost=4.1 Thoughput=12.22 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 40149/88641, Loss=2.2258, lr=0.0000472 Time cost=4.1 Thoughput=12.27 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 40199/88641, Loss=2.8091, lr=0.0000472 Time cost=4.1 Thoughput=12.28 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 40249/88641, Loss=1.7439, lr=0.0000471 Time cost=4.1 Thoughput=12.29 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 40299/88641, Loss=2.4536, lr=0.0000471 Time cost=4.1 Thoughput=12.28 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 40349/88641, Loss=2.2959, lr=0.0000471 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 40399/88641, Loss=2.3606, lr=0.0000471 Time cost=4.1 Thoughput=12.19 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 40449/88641, Loss=1.9478, lr=0.0000471 Time cost=4.1 Thoughput=12.27 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 40499/88641, Loss=1.6484, lr=0.0000471 Time cost=4.1 Thoughput=12.28 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 40549/88641, Loss=2.1443, lr=0.0000471 Time cost=4.1 Thoughput=12.29 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 40599/88641, Loss=2.2573, lr=0.0000471 Time cost=4.1 Thoughput=12.31 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 40649/88641, Loss=2.1761, lr=0.0000471 Time cost=4.1 Thoughput=12.06 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 40699/88641, Loss=1.7446, lr=0.0000471 Time cost=4.1 Thoughput=12.20 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 40749/88641, Loss=1.7608, lr=0.0000470 Time cost=4.2 Thoughput=11.93 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 40799/88641, Loss=1.3890, lr=0.0000470 Time cost=4.2 Thoughput=11.94 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 40849/88641, Loss=1.9888, lr=0.0000470 Time cost=4.1 Thoughput=12.21 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 40899/88641, Loss=1.7686, lr=0.0000470 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 40949/88641, Loss=2.1814, lr=0.0000470 Time cost=4.1 Thoughput=12.08 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 40999/88641, Loss=2.2646, lr=0.0000470 Time cost=4.2 Thoughput=12.04 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 41049/88641, Loss=1.8150, lr=0.0000470 Time cost=4.2 Thoughput=12.02 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 41099/88641, Loss=2.0277, lr=0.0000470 Time cost=4.1 Thoughput=12.20 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 41149/88641, Loss=1.9783, lr=0.0000470 Time cost=4.1 Thoughput=12.18 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 41199/88641, Loss=2.0895, lr=0.0000469 Time cost=4.1 Thoughput=12.19 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 41249/88641, Loss=2.7182, lr=0.0000469 Time cost=4.1 Thoughput=12.21 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 41299/88641, Loss=1.4164, lr=0.0000469 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 41349/88641, Loss=1.5281, lr=0.0000469 Time cost=4.1 Thoughput=12.29 samples/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gluonnlp:Epoch: 0, Batch: 41399/88641, Loss=2.9395, lr=0.0000469 Time cost=4.1 Thoughput=12.22 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 41449/88641, Loss=2.2784, lr=0.0000469 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 41499/88641, Loss=1.7505, lr=0.0000469 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 41549/88641, Loss=1.8032, lr=0.0000469 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 41599/88641, Loss=2.0588, lr=0.0000469 Time cost=4.1 Thoughput=12.21 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 41649/88641, Loss=2.0898, lr=0.0000469 Time cost=4.2 Thoughput=11.77 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 41699/88641, Loss=2.4149, lr=0.0000468 Time cost=4.1 Thoughput=12.06 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 41749/88641, Loss=1.9368, lr=0.0000468 Time cost=4.1 Thoughput=12.15 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 41799/88641, Loss=2.1717, lr=0.0000468 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 41849/88641, Loss=1.9455, lr=0.0000468 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 41899/88641, Loss=2.5127, lr=0.0000468 Time cost=4.1 Thoughput=12.09 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 41949/88641, Loss=2.2449, lr=0.0000468 Time cost=4.2 Thoughput=12.00 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 41999/88641, Loss=2.6092, lr=0.0000468 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 42049/88641, Loss=1.7793, lr=0.0000468 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 42099/88641, Loss=2.1053, lr=0.0000468 Time cost=4.2 Thoughput=12.00 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 42149/88641, Loss=1.7105, lr=0.0000467 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 42199/88641, Loss=2.4381, lr=0.0000467 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 42249/88641, Loss=1.4798, lr=0.0000467 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 42299/88641, Loss=1.9651, lr=0.0000467 Time cost=4.1 Thoughput=12.22 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 42349/88641, Loss=2.0318, lr=0.0000467 Time cost=4.1 Thoughput=12.22 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 42399/88641, Loss=2.1621, lr=0.0000467 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 42449/88641, Loss=1.6137, lr=0.0000467 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 42499/88641, Loss=1.4797, lr=0.0000467 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 42549/88641, Loss=2.1901, lr=0.0000467 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 42599/88641, Loss=1.8680, lr=0.0000467 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 42649/88641, Loss=2.2280, lr=0.0000466 Time cost=4.1 Thoughput=12.22 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 42699/88641, Loss=1.7991, lr=0.0000466 Time cost=4.1 Thoughput=12.22 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 42749/88641, Loss=1.8291, lr=0.0000466 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 42799/88641, Loss=2.2256, lr=0.0000466 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 42849/88641, Loss=2.5768, lr=0.0000466 Time cost=4.2 Thoughput=11.92 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 42899/88641, Loss=1.8134, lr=0.0000466 Time cost=4.1 Thoughput=12.27 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 42949/88641, Loss=2.6393, lr=0.0000466 Time cost=4.1 Thoughput=12.20 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 42999/88641, Loss=2.0376, lr=0.0000466 Time cost=4.1 Thoughput=12.16 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 43049/88641, Loss=1.9822, lr=0.0000466 Time cost=4.1 Thoughput=12.13 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 43099/88641, Loss=2.0126, lr=0.0000466 Time cost=4.2 Thoughput=12.00 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 43149/88641, Loss=1.7051, lr=0.0000465 Time cost=4.2 Thoughput=11.98 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 43199/88641, Loss=1.8204, lr=0.0000465 Time cost=4.1 Thoughput=12.19 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 43249/88641, Loss=2.0552, lr=0.0000465 Time cost=4.1 Thoughput=12.21 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 43299/88641, Loss=2.0361, lr=0.0000465 Time cost=4.2 Thoughput=11.97 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 43349/88641, Loss=2.4873, lr=0.0000465 Time cost=4.1 Thoughput=12.18 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 43399/88641, Loss=1.8439, lr=0.0000465 Time cost=4.1 Thoughput=12.22 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 43449/88641, Loss=1.7602, lr=0.0000465 Time cost=4.1 Thoughput=12.10 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 43499/88641, Loss=2.7076, lr=0.0000465 Time cost=4.1 Thoughput=12.21 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 43549/88641, Loss=2.3070, lr=0.0000465 Time cost=4.1 Thoughput=12.16 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 43599/88641, Loss=2.5529, lr=0.0000464 Time cost=4.1 Thoughput=12.19 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 43649/88641, Loss=2.1264, lr=0.0000464 Time cost=4.1 Thoughput=12.22 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 43699/88641, Loss=2.3194, lr=0.0000464 Time cost=4.2 Thoughput=12.01 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 43749/88641, Loss=1.8993, lr=0.0000464 Time cost=4.1 Thoughput=12.20 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 43799/88641, Loss=2.2576, lr=0.0000464 Time cost=4.1 Thoughput=12.22 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 43849/88641, Loss=2.0086, lr=0.0000464 Time cost=4.1 Thoughput=12.19 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 43899/88641, Loss=2.3400, lr=0.0000464 Time cost=4.6 Thoughput=10.90 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 43949/88641, Loss=1.8860, lr=0.0000464 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 43999/88641, Loss=2.2423, lr=0.0000464 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 44049/88641, Loss=1.9347, lr=0.0000464 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 44099/88641, Loss=2.1152, lr=0.0000463 Time cost=4.1 Thoughput=12.12 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 44149/88641, Loss=2.1846, lr=0.0000463 Time cost=4.2 Thoughput=12.03 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 44199/88641, Loss=2.0650, lr=0.0000463 Time cost=4.1 Thoughput=12.09 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 44249/88641, Loss=1.8300, lr=0.0000463 Time cost=4.1 Thoughput=12.31 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 44299/88641, Loss=2.3841, lr=0.0000463 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 44349/88641, Loss=1.6713, lr=0.0000463 Time cost=4.1 Thoughput=12.22 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 44399/88641, Loss=1.4205, lr=0.0000463 Time cost=4.1 Thoughput=12.27 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 44449/88641, Loss=2.3265, lr=0.0000463 Time cost=4.1 Thoughput=12.15 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 44499/88641, Loss=1.9469, lr=0.0000463 Time cost=4.1 Thoughput=12.27 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 44549/88641, Loss=2.2374, lr=0.0000462 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 44599/88641, Loss=1.8445, lr=0.0000462 Time cost=4.1 Thoughput=12.21 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 44649/88641, Loss=2.1819, lr=0.0000462 Time cost=4.1 Thoughput=12.22 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 44699/88641, Loss=1.6388, lr=0.0000462 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 44749/88641, Loss=2.0264, lr=0.0000462 Time cost=4.1 Thoughput=12.20 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 44799/88641, Loss=1.9924, lr=0.0000462 Time cost=4.1 Thoughput=12.22 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 44849/88641, Loss=1.5002, lr=0.0000462 Time cost=4.1 Thoughput=12.27 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 44899/88641, Loss=1.9700, lr=0.0000462 Time cost=4.1 Thoughput=12.28 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 44949/88641, Loss=1.8849, lr=0.0000462 Time cost=4.1 Thoughput=12.22 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 44999/88641, Loss=2.3990, lr=0.0000462 Time cost=4.2 Thoughput=12.04 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 45049/88641, Loss=2.0280, lr=0.0000461 Time cost=4.2 Thoughput=11.89 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 45099/88641, Loss=1.9257, lr=0.0000461 Time cost=4.1 Thoughput=12.20 samples/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gluonnlp:Epoch: 0, Batch: 45149/88641, Loss=2.2712, lr=0.0000461 Time cost=4.1 Thoughput=12.11 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 45199/88641, Loss=1.6673, lr=0.0000461 Time cost=4.1 Thoughput=12.17 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 45249/88641, Loss=2.5072, lr=0.0000461 Time cost=4.1 Thoughput=12.21 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 45299/88641, Loss=2.1205, lr=0.0000461 Time cost=4.1 Thoughput=12.19 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 45349/88641, Loss=1.7288, lr=0.0000461 Time cost=4.1 Thoughput=12.20 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 45399/88641, Loss=1.6642, lr=0.0000461 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 45449/88641, Loss=2.2498, lr=0.0000461 Time cost=4.1 Thoughput=12.29 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 45499/88641, Loss=1.9381, lr=0.0000460 Time cost=4.1 Thoughput=12.10 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 45549/88641, Loss=2.1085, lr=0.0000460 Time cost=4.2 Thoughput=11.94 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 45599/88641, Loss=2.2625, lr=0.0000460 Time cost=4.1 Thoughput=12.12 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 45649/88641, Loss=2.1217, lr=0.0000460 Time cost=4.1 Thoughput=12.05 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 45699/88641, Loss=1.5774, lr=0.0000460 Time cost=4.1 Thoughput=12.16 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 45749/88641, Loss=2.0926, lr=0.0000460 Time cost=4.1 Thoughput=12.27 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 45799/88641, Loss=1.8015, lr=0.0000460 Time cost=4.1 Thoughput=12.27 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 45849/88641, Loss=2.0776, lr=0.0000460 Time cost=4.1 Thoughput=12.22 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 45899/88641, Loss=2.5001, lr=0.0000460 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 45949/88641, Loss=1.6882, lr=0.0000460 Time cost=4.1 Thoughput=12.20 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 45999/88641, Loss=2.2677, lr=0.0000459 Time cost=4.1 Thoughput=12.19 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 46049/88641, Loss=2.2166, lr=0.0000459 Time cost=4.1 Thoughput=12.17 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 46099/88641, Loss=2.2735, lr=0.0000459 Time cost=4.2 Thoughput=11.80 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 46149/88641, Loss=2.2991, lr=0.0000459 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 46199/88641, Loss=2.1511, lr=0.0000459 Time cost=4.1 Thoughput=12.27 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 46249/88641, Loss=1.9572, lr=0.0000459 Time cost=4.1 Thoughput=12.28 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 46299/88641, Loss=1.9485, lr=0.0000459 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 46349/88641, Loss=1.9822, lr=0.0000459 Time cost=4.1 Thoughput=12.22 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 46399/88641, Loss=2.2191, lr=0.0000459 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 46449/88641, Loss=2.1278, lr=0.0000459 Time cost=4.1 Thoughput=12.27 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 46499/88641, Loss=2.5802, lr=0.0000458 Time cost=4.2 Thoughput=12.02 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 46549/88641, Loss=1.9838, lr=0.0000458 Time cost=4.2 Thoughput=11.97 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 46599/88641, Loss=1.8194, lr=0.0000458 Time cost=4.6 Thoughput=10.76 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 46649/88641, Loss=2.4061, lr=0.0000458 Time cost=4.1 Thoughput=12.06 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 46699/88641, Loss=2.1419, lr=0.0000458 Time cost=4.2 Thoughput=12.01 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 46749/88641, Loss=2.4496, lr=0.0000458 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 46799/88641, Loss=2.1156, lr=0.0000458 Time cost=4.1 Thoughput=12.27 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 46849/88641, Loss=2.8306, lr=0.0000458 Time cost=4.1 Thoughput=12.22 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 46899/88641, Loss=2.2546, lr=0.0000458 Time cost=4.1 Thoughput=12.27 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 46949/88641, Loss=1.8897, lr=0.0000457 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 46999/88641, Loss=2.2666, lr=0.0000457 Time cost=4.1 Thoughput=12.21 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 47049/88641, Loss=2.2299, lr=0.0000457 Time cost=4.1 Thoughput=12.16 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 47099/88641, Loss=2.3264, lr=0.0000457 Time cost=4.1 Thoughput=12.20 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 47149/88641, Loss=1.9721, lr=0.0000457 Time cost=4.1 Thoughput=12.21 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 47199/88641, Loss=2.2325, lr=0.0000457 Time cost=4.1 Thoughput=12.15 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 47249/88641, Loss=2.3987, lr=0.0000457 Time cost=4.2 Thoughput=11.93 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 47299/88641, Loss=1.7228, lr=0.0000457 Time cost=4.1 Thoughput=12.15 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 47349/88641, Loss=2.3079, lr=0.0000457 Time cost=4.1 Thoughput=12.15 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 47399/88641, Loss=1.3828, lr=0.0000457 Time cost=4.1 Thoughput=12.13 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 47449/88641, Loss=2.4678, lr=0.0000456 Time cost=4.1 Thoughput=12.13 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 47499/88641, Loss=1.9648, lr=0.0000456 Time cost=4.1 Thoughput=12.16 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 47549/88641, Loss=1.8470, lr=0.0000456 Time cost=4.1 Thoughput=12.19 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 47599/88641, Loss=2.1138, lr=0.0000456 Time cost=4.1 Thoughput=12.20 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 47649/88641, Loss=1.4005, lr=0.0000456 Time cost=4.1 Thoughput=12.20 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 47699/88641, Loss=2.3061, lr=0.0000456 Time cost=4.1 Thoughput=12.19 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 47749/88641, Loss=1.9557, lr=0.0000456 Time cost=4.1 Thoughput=12.21 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 47799/88641, Loss=1.7128, lr=0.0000456 Time cost=4.1 Thoughput=12.21 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 47849/88641, Loss=2.0489, lr=0.0000456 Time cost=4.2 Thoughput=12.01 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 47899/88641, Loss=2.3964, lr=0.0000455 Time cost=4.2 Thoughput=11.97 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 47949/88641, Loss=2.3905, lr=0.0000455 Time cost=4.1 Thoughput=12.20 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 47999/88641, Loss=2.1863, lr=0.0000455 Time cost=4.2 Thoughput=11.99 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 48049/88641, Loss=2.4867, lr=0.0000455 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 48099/88641, Loss=2.0634, lr=0.0000455 Time cost=4.1 Thoughput=12.29 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 48149/88641, Loss=2.5392, lr=0.0000455 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 48199/88641, Loss=1.7851, lr=0.0000455 Time cost=4.1 Thoughput=12.09 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 48249/88641, Loss=1.7935, lr=0.0000455 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 48299/88641, Loss=2.0328, lr=0.0000455 Time cost=4.1 Thoughput=12.27 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 48349/88641, Loss=1.9872, lr=0.0000455 Time cost=4.1 Thoughput=12.27 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 48399/88641, Loss=2.1778, lr=0.0000454 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 48449/88641, Loss=2.0008, lr=0.0000454 Time cost=4.1 Thoughput=12.21 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 48499/88641, Loss=1.9901, lr=0.0000454 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 48549/88641, Loss=1.9905, lr=0.0000454 Time cost=4.1 Thoughput=12.28 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 48599/88641, Loss=1.9893, lr=0.0000454 Time cost=4.1 Thoughput=12.28 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 48649/88641, Loss=2.4033, lr=0.0000454 Time cost=4.1 Thoughput=12.27 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 48699/88641, Loss=1.5115, lr=0.0000454 Time cost=4.1 Thoughput=12.08 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 48749/88641, Loss=1.8589, lr=0.0000454 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 48799/88641, Loss=1.6877, lr=0.0000454 Time cost=4.1 Thoughput=12.30 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 48849/88641, Loss=2.3212, lr=0.0000453 Time cost=4.1 Thoughput=12.29 samples/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gluonnlp:Epoch: 0, Batch: 48899/88641, Loss=1.5594, lr=0.0000453 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 48949/88641, Loss=1.8686, lr=0.0000453 Time cost=4.1 Thoughput=12.28 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 48999/88641, Loss=2.7171, lr=0.0000453 Time cost=4.1 Thoughput=12.30 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 49049/88641, Loss=1.8645, lr=0.0000453 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 49099/88641, Loss=2.1759, lr=0.0000453 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 49149/88641, Loss=2.5194, lr=0.0000453 Time cost=4.1 Thoughput=12.29 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 49199/88641, Loss=1.8235, lr=0.0000453 Time cost=4.1 Thoughput=12.30 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 49249/88641, Loss=2.3215, lr=0.0000453 Time cost=4.1 Thoughput=12.27 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 49299/88641, Loss=1.8541, lr=0.0000453 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 49349/88641, Loss=1.8285, lr=0.0000452 Time cost=4.2 Thoughput=12.04 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 49399/88641, Loss=2.4403, lr=0.0000452 Time cost=4.2 Thoughput=11.95 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 49449/88641, Loss=2.0012, lr=0.0000452 Time cost=4.2 Thoughput=12.00 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 49499/88641, Loss=2.1690, lr=0.0000452 Time cost=4.3 Thoughput=11.52 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 49549/88641, Loss=1.8150, lr=0.0000452 Time cost=4.2 Thoughput=11.99 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 49599/88641, Loss=2.0674, lr=0.0000452 Time cost=4.2 Thoughput=11.98 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 49649/88641, Loss=2.0331, lr=0.0000452 Time cost=4.2 Thoughput=12.02 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 49699/88641, Loss=2.0223, lr=0.0000452 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 49749/88641, Loss=2.2179, lr=0.0000452 Time cost=4.3 Thoughput=11.75 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 49799/88641, Loss=2.0126, lr=0.0000452 Time cost=4.1 Thoughput=12.32 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 49849/88641, Loss=1.9019, lr=0.0000451 Time cost=4.1 Thoughput=12.20 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 49899/88641, Loss=2.4187, lr=0.0000451 Time cost=4.2 Thoughput=12.00 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 49949/88641, Loss=1.6160, lr=0.0000451 Time cost=4.2 Thoughput=11.97 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 49999/88641, Loss=2.1289, lr=0.0000451 Time cost=4.2 Thoughput=11.95 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 50049/88641, Loss=2.2054, lr=0.0000451 Time cost=4.2 Thoughput=11.99 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 50099/88641, Loss=1.9178, lr=0.0000451 Time cost=4.1 Thoughput=12.21 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 50149/88641, Loss=1.7768, lr=0.0000451 Time cost=4.1 Thoughput=12.07 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 50199/88641, Loss=2.2107, lr=0.0000451 Time cost=4.2 Thoughput=12.02 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 50249/88641, Loss=2.2430, lr=0.0000451 Time cost=4.1 Thoughput=12.14 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 50299/88641, Loss=1.8626, lr=0.0000450 Time cost=4.1 Thoughput=12.20 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 50349/88641, Loss=1.8316, lr=0.0000450 Time cost=4.1 Thoughput=12.22 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 50399/88641, Loss=2.1207, lr=0.0000450 Time cost=4.1 Thoughput=12.28 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 50449/88641, Loss=2.5551, lr=0.0000450 Time cost=4.6 Thoughput=10.93 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 50499/88641, Loss=2.2622, lr=0.0000450 Time cost=4.1 Thoughput=12.29 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 50549/88641, Loss=1.8782, lr=0.0000450 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 50599/88641, Loss=1.7219, lr=0.0000450 Time cost=4.1 Thoughput=12.19 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 50649/88641, Loss=2.0685, lr=0.0000450 Time cost=4.1 Thoughput=12.21 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 50699/88641, Loss=2.3645, lr=0.0000450 Time cost=4.1 Thoughput=12.20 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 50749/88641, Loss=2.6201, lr=0.0000450 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 50799/88641, Loss=1.8568, lr=0.0000449 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 50849/88641, Loss=2.3729, lr=0.0000449 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 50899/88641, Loss=2.0275, lr=0.0000449 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 50949/88641, Loss=2.4443, lr=0.0000449 Time cost=4.2 Thoughput=12.02 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 50999/88641, Loss=2.1931, lr=0.0000449 Time cost=4.2 Thoughput=12.03 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 51049/88641, Loss=1.5194, lr=0.0000449 Time cost=4.1 Thoughput=12.21 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 51099/88641, Loss=2.0908, lr=0.0000449 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 51149/88641, Loss=2.1009, lr=0.0000449 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 51199/88641, Loss=2.3336, lr=0.0000449 Time cost=4.1 Thoughput=12.07 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 51249/88641, Loss=2.3032, lr=0.0000448 Time cost=4.1 Thoughput=12.16 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 51299/88641, Loss=2.4676, lr=0.0000448 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 51349/88641, Loss=2.2636, lr=0.0000448 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 51399/88641, Loss=2.0085, lr=0.0000448 Time cost=4.1 Thoughput=12.22 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 51449/88641, Loss=2.1218, lr=0.0000448 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 51499/88641, Loss=1.8265, lr=0.0000448 Time cost=4.1 Thoughput=12.29 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 51549/88641, Loss=1.8627, lr=0.0000448 Time cost=4.1 Thoughput=12.28 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 51599/88641, Loss=1.7685, lr=0.0000448 Time cost=4.2 Thoughput=12.02 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 51649/88641, Loss=2.4700, lr=0.0000448 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 51699/88641, Loss=2.4021, lr=0.0000448 Time cost=4.1 Thoughput=12.20 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 51749/88641, Loss=2.5250, lr=0.0000447 Time cost=4.1 Thoughput=12.19 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 51799/88641, Loss=1.6791, lr=0.0000447 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 51849/88641, Loss=2.2909, lr=0.0000447 Time cost=4.1 Thoughput=12.16 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 51899/88641, Loss=2.0868, lr=0.0000447 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 51949/88641, Loss=2.2058, lr=0.0000447 Time cost=4.1 Thoughput=12.21 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 51999/88641, Loss=2.0360, lr=0.0000447 Time cost=4.1 Thoughput=12.19 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 52049/88641, Loss=1.5202, lr=0.0000447 Time cost=4.1 Thoughput=12.21 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 52099/88641, Loss=2.0291, lr=0.0000447 Time cost=4.1 Thoughput=12.08 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 52149/88641, Loss=2.6005, lr=0.0000447 Time cost=4.2 Thoughput=12.00 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 52199/88641, Loss=1.8786, lr=0.0000447 Time cost=4.2 Thoughput=11.97 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 52249/88641, Loss=2.0479, lr=0.0000446 Time cost=4.2 Thoughput=11.99 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 52299/88641, Loss=2.7759, lr=0.0000446 Time cost=4.1 Thoughput=12.17 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 52349/88641, Loss=2.1621, lr=0.0000446 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 52399/88641, Loss=2.1030, lr=0.0000446 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 52449/88641, Loss=2.4118, lr=0.0000446 Time cost=4.1 Thoughput=12.28 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 52499/88641, Loss=1.6078, lr=0.0000446 Time cost=4.1 Thoughput=12.20 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 52549/88641, Loss=2.0053, lr=0.0000446 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 52599/88641, Loss=2.0799, lr=0.0000446 Time cost=4.1 Thoughput=12.13 samples/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gluonnlp:Epoch: 0, Batch: 52649/88641, Loss=1.5604, lr=0.0000446 Time cost=4.1 Thoughput=12.18 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 52699/88641, Loss=1.1615, lr=0.0000445 Time cost=4.1 Thoughput=12.22 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 52749/88641, Loss=2.0803, lr=0.0000445 Time cost=4.1 Thoughput=12.21 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 52799/88641, Loss=2.1189, lr=0.0000445 Time cost=4.1 Thoughput=12.19 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 52849/88641, Loss=1.9833, lr=0.0000445 Time cost=4.1 Thoughput=12.13 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 52899/88641, Loss=2.1129, lr=0.0000445 Time cost=4.1 Thoughput=12.13 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 52949/88641, Loss=2.2757, lr=0.0000445 Time cost=4.1 Thoughput=12.27 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 52999/88641, Loss=2.0414, lr=0.0000445 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 53049/88641, Loss=2.1663, lr=0.0000445 Time cost=4.1 Thoughput=12.28 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 53099/88641, Loss=2.0721, lr=0.0000445 Time cost=4.1 Thoughput=12.28 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 53149/88641, Loss=1.8912, lr=0.0000445 Time cost=4.6 Thoughput=10.96 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 53199/88641, Loss=1.1913, lr=0.0000444 Time cost=4.1 Thoughput=12.28 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 53249/88641, Loss=2.1078, lr=0.0000444 Time cost=4.1 Thoughput=12.17 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 53299/88641, Loss=2.0129, lr=0.0000444 Time cost=4.1 Thoughput=12.27 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 53349/88641, Loss=2.7469, lr=0.0000444 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 53399/88641, Loss=1.8555, lr=0.0000444 Time cost=4.1 Thoughput=12.22 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 53449/88641, Loss=2.2182, lr=0.0000444 Time cost=4.1 Thoughput=12.22 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 53499/88641, Loss=1.6292, lr=0.0000444 Time cost=4.1 Thoughput=12.21 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 53549/88641, Loss=2.0048, lr=0.0000444 Time cost=4.1 Thoughput=12.21 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 53599/88641, Loss=1.8895, lr=0.0000444 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 53649/88641, Loss=2.2422, lr=0.0000443 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 53699/88641, Loss=1.2925, lr=0.0000443 Time cost=4.1 Thoughput=12.15 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 53749/88641, Loss=2.3634, lr=0.0000443 Time cost=4.2 Thoughput=11.98 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 53799/88641, Loss=1.9990, lr=0.0000443 Time cost=4.2 Thoughput=11.92 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 53849/88641, Loss=1.6026, lr=0.0000443 Time cost=4.1 Thoughput=12.21 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 53899/88641, Loss=1.7873, lr=0.0000443 Time cost=4.1 Thoughput=12.22 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 53949/88641, Loss=2.0320, lr=0.0000443 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 53999/88641, Loss=2.2183, lr=0.0000443 Time cost=4.1 Thoughput=12.28 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 54049/88641, Loss=1.9530, lr=0.0000443 Time cost=4.1 Thoughput=12.28 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 54099/88641, Loss=1.9237, lr=0.0000443 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 54149/88641, Loss=1.4804, lr=0.0000442 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 54199/88641, Loss=1.6468, lr=0.0000442 Time cost=4.1 Thoughput=12.27 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 54249/88641, Loss=2.1677, lr=0.0000442 Time cost=4.1 Thoughput=12.17 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 54299/88641, Loss=1.9271, lr=0.0000442 Time cost=4.3 Thoughput=11.69 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 54349/88641, Loss=1.8610, lr=0.0000442 Time cost=4.2 Thoughput=11.98 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 54399/88641, Loss=2.0913, lr=0.0000442 Time cost=4.2 Thoughput=12.00 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 54449/88641, Loss=2.2819, lr=0.0000442 Time cost=4.2 Thoughput=12.00 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 54499/88641, Loss=2.0260, lr=0.0000442 Time cost=4.2 Thoughput=12.02 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 54549/88641, Loss=2.4159, lr=0.0000442 Time cost=4.1 Thoughput=12.09 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 54599/88641, Loss=2.2448, lr=0.0000441 Time cost=4.1 Thoughput=12.20 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 54649/88641, Loss=1.8879, lr=0.0000441 Time cost=4.1 Thoughput=12.07 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 54699/88641, Loss=2.2712, lr=0.0000441 Time cost=4.1 Thoughput=12.19 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 54749/88641, Loss=1.9051, lr=0.0000441 Time cost=4.1 Thoughput=12.20 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 54799/88641, Loss=2.2718, lr=0.0000441 Time cost=4.1 Thoughput=12.22 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 54849/88641, Loss=1.8754, lr=0.0000441 Time cost=4.1 Thoughput=12.17 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 54899/88641, Loss=2.0295, lr=0.0000441 Time cost=4.1 Thoughput=12.21 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 54949/88641, Loss=1.7302, lr=0.0000441 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 54999/88641, Loss=2.6720, lr=0.0000441 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 55049/88641, Loss=2.0338, lr=0.0000441 Time cost=4.1 Thoughput=12.20 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 55099/88641, Loss=1.7939, lr=0.0000440 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 55149/88641, Loss=2.4361, lr=0.0000440 Time cost=4.1 Thoughput=12.27 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 55199/88641, Loss=1.8327, lr=0.0000440 Time cost=4.1 Thoughput=12.22 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 55249/88641, Loss=2.1633, lr=0.0000440 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 55299/88641, Loss=1.9195, lr=0.0000440 Time cost=4.1 Thoughput=12.22 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 55349/88641, Loss=2.5441, lr=0.0000440 Time cost=4.2 Thoughput=12.03 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 55399/88641, Loss=1.8802, lr=0.0000440 Time cost=4.1 Thoughput=12.20 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 55449/88641, Loss=2.1541, lr=0.0000440 Time cost=4.2 Thoughput=12.02 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 55499/88641, Loss=1.8818, lr=0.0000440 Time cost=4.1 Thoughput=12.27 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 55549/88641, Loss=2.2659, lr=0.0000440 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 55599/88641, Loss=1.8890, lr=0.0000439 Time cost=4.1 Thoughput=12.28 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 55649/88641, Loss=2.4657, lr=0.0000439 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 55699/88641, Loss=1.9387, lr=0.0000439 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 55749/88641, Loss=1.6014, lr=0.0000439 Time cost=4.1 Thoughput=12.31 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 55799/88641, Loss=2.5601, lr=0.0000439 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 55849/88641, Loss=2.0220, lr=0.0000439 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 55899/88641, Loss=1.9151, lr=0.0000439 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 55949/88641, Loss=1.9931, lr=0.0000439 Time cost=4.2 Thoughput=12.04 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 55999/88641, Loss=1.7748, lr=0.0000439 Time cost=4.2 Thoughput=11.97 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 56049/88641, Loss=1.8666, lr=0.0000438 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 56099/88641, Loss=2.1167, lr=0.0000438 Time cost=4.1 Thoughput=12.28 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 56149/88641, Loss=1.7843, lr=0.0000438 Time cost=4.1 Thoughput=12.20 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 56199/88641, Loss=2.0325, lr=0.0000438 Time cost=4.1 Thoughput=12.19 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 56249/88641, Loss=2.1187, lr=0.0000438 Time cost=4.1 Thoughput=12.20 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 56299/88641, Loss=2.1536, lr=0.0000438 Time cost=4.1 Thoughput=12.13 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 56349/88641, Loss=1.7983, lr=0.0000438 Time cost=4.1 Thoughput=12.23 samples/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gluonnlp:Epoch: 0, Batch: 56399/88641, Loss=2.1098, lr=0.0000438 Time cost=4.1 Thoughput=12.21 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 56449/88641, Loss=2.3146, lr=0.0000438 Time cost=4.1 Thoughput=12.18 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 56499/88641, Loss=1.8491, lr=0.0000438 Time cost=4.1 Thoughput=12.18 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 56549/88641, Loss=2.5193, lr=0.0000437 Time cost=4.1 Thoughput=12.21 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 56599/88641, Loss=2.2013, lr=0.0000437 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 56649/88641, Loss=2.4448, lr=0.0000437 Time cost=4.1 Thoughput=12.21 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 56699/88641, Loss=1.9879, lr=0.0000437 Time cost=4.1 Thoughput=12.21 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 56749/88641, Loss=2.1284, lr=0.0000437 Time cost=4.1 Thoughput=12.20 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 56799/88641, Loss=1.8980, lr=0.0000437 Time cost=4.1 Thoughput=12.20 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 56849/88641, Loss=1.9331, lr=0.0000437 Time cost=4.1 Thoughput=12.19 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 56899/88641, Loss=2.1289, lr=0.0000437 Time cost=4.1 Thoughput=12.15 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 56949/88641, Loss=1.7603, lr=0.0000437 Time cost=4.1 Thoughput=12.16 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 56999/88641, Loss=2.3988, lr=0.0000436 Time cost=4.6 Thoughput=10.82 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 57049/88641, Loss=1.7605, lr=0.0000436 Time cost=4.1 Thoughput=12.20 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 57099/88641, Loss=2.3583, lr=0.0000436 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 57149/88641, Loss=1.9140, lr=0.0000436 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 57199/88641, Loss=1.9568, lr=0.0000436 Time cost=4.1 Thoughput=12.17 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 57249/88641, Loss=2.4984, lr=0.0000436 Time cost=4.1 Thoughput=12.11 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 57299/88641, Loss=2.5000, lr=0.0000436 Time cost=4.2 Thoughput=11.94 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 57349/88641, Loss=1.9819, lr=0.0000436 Time cost=4.2 Thoughput=11.95 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 57399/88641, Loss=1.8764, lr=0.0000436 Time cost=4.1 Thoughput=12.21 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 57449/88641, Loss=1.9313, lr=0.0000436 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 57499/88641, Loss=1.7915, lr=0.0000435 Time cost=4.1 Thoughput=12.30 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 57549/88641, Loss=2.0697, lr=0.0000435 Time cost=4.1 Thoughput=12.31 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 57599/88641, Loss=1.7832, lr=0.0000435 Time cost=4.1 Thoughput=12.30 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 57649/88641, Loss=2.7174, lr=0.0000435 Time cost=4.1 Thoughput=12.31 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 57699/88641, Loss=2.3393, lr=0.0000435 Time cost=4.1 Thoughput=12.29 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 57749/88641, Loss=2.0227, lr=0.0000435 Time cost=4.1 Thoughput=12.30 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 57799/88641, Loss=2.3718, lr=0.0000435 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 57849/88641, Loss=2.4761, lr=0.0000435 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 57899/88641, Loss=1.9874, lr=0.0000435 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 57949/88641, Loss=2.5413, lr=0.0000434 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 57999/88641, Loss=1.9413, lr=0.0000434 Time cost=4.1 Thoughput=12.15 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 58049/88641, Loss=1.6101, lr=0.0000434 Time cost=4.1 Thoughput=12.28 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 58099/88641, Loss=2.2218, lr=0.0000434 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 58149/88641, Loss=1.9097, lr=0.0000434 Time cost=4.1 Thoughput=12.06 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 58199/88641, Loss=2.0987, lr=0.0000434 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 58249/88641, Loss=2.3607, lr=0.0000434 Time cost=4.1 Thoughput=12.28 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 58299/88641, Loss=1.7969, lr=0.0000434 Time cost=4.1 Thoughput=12.16 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 58349/88641, Loss=2.0827, lr=0.0000434 Time cost=4.1 Thoughput=12.15 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 58399/88641, Loss=1.9723, lr=0.0000434 Time cost=4.1 Thoughput=12.27 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 58449/88641, Loss=1.6944, lr=0.0000433 Time cost=4.1 Thoughput=12.07 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 58499/88641, Loss=1.9809, lr=0.0000433 Time cost=4.1 Thoughput=12.22 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 58549/88641, Loss=1.4964, lr=0.0000433 Time cost=4.1 Thoughput=12.13 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 58599/88641, Loss=2.0796, lr=0.0000433 Time cost=4.2 Thoughput=11.96 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 58649/88641, Loss=2.3856, lr=0.0000433 Time cost=4.1 Thoughput=12.16 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 58699/88641, Loss=1.8629, lr=0.0000433 Time cost=4.1 Thoughput=12.17 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 58749/88641, Loss=1.8513, lr=0.0000433 Time cost=4.1 Thoughput=12.16 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 58799/88641, Loss=2.3198, lr=0.0000433 Time cost=4.1 Thoughput=12.21 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 58849/88641, Loss=1.9536, lr=0.0000433 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 58899/88641, Loss=1.8457, lr=0.0000433 Time cost=4.2 Thoughput=12.01 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 58949/88641, Loss=2.1522, lr=0.0000432 Time cost=4.1 Thoughput=12.27 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 58999/88641, Loss=2.5690, lr=0.0000432 Time cost=4.1 Thoughput=12.28 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 59049/88641, Loss=2.1751, lr=0.0000432 Time cost=4.1 Thoughput=12.28 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 59099/88641, Loss=2.0847, lr=0.0000432 Time cost=4.1 Thoughput=12.21 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 59149/88641, Loss=1.7010, lr=0.0000432 Time cost=4.1 Thoughput=12.22 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 59199/88641, Loss=1.8437, lr=0.0000432 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 59249/88641, Loss=2.0473, lr=0.0000432 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 59299/88641, Loss=2.0909, lr=0.0000432 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 59349/88641, Loss=2.5620, lr=0.0000432 Time cost=4.1 Thoughput=12.20 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 59399/88641, Loss=2.3786, lr=0.0000431 Time cost=4.1 Thoughput=12.21 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 59449/88641, Loss=1.6834, lr=0.0000431 Time cost=4.1 Thoughput=12.18 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 59499/88641, Loss=1.8079, lr=0.0000431 Time cost=4.1 Thoughput=12.16 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 59549/88641, Loss=2.1670, lr=0.0000431 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 59599/88641, Loss=1.9372, lr=0.0000431 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 59649/88641, Loss=2.2912, lr=0.0000431 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 59699/88641, Loss=1.8380, lr=0.0000431 Time cost=4.1 Thoughput=12.19 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 59749/88641, Loss=1.9921, lr=0.0000431 Time cost=4.9 Thoughput=10.20 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 59799/88641, Loss=2.1730, lr=0.0000431 Time cost=4.1 Thoughput=12.20 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 59849/88641, Loss=2.3839, lr=0.0000431 Time cost=4.1 Thoughput=12.10 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 59899/88641, Loss=2.2350, lr=0.0000430 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 59949/88641, Loss=2.4436, lr=0.0000430 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 59999/88641, Loss=1.5279, lr=0.0000430 Time cost=4.1 Thoughput=12.27 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 60049/88641, Loss=1.6610, lr=0.0000430 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 60099/88641, Loss=2.0209, lr=0.0000430 Time cost=4.1 Thoughput=12.26 samples/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gluonnlp:Epoch: 0, Batch: 60149/88641, Loss=1.8385, lr=0.0000430 Time cost=4.1 Thoughput=12.29 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 60199/88641, Loss=1.9119, lr=0.0000430 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 60249/88641, Loss=2.3997, lr=0.0000430 Time cost=4.1 Thoughput=12.30 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 60299/88641, Loss=1.4336, lr=0.0000430 Time cost=4.1 Thoughput=12.33 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 60349/88641, Loss=1.8182, lr=0.0000429 Time cost=4.2 Thoughput=11.99 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 60399/88641, Loss=1.7104, lr=0.0000429 Time cost=4.2 Thoughput=12.00 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 60449/88641, Loss=1.6095, lr=0.0000429 Time cost=4.1 Thoughput=12.13 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 60499/88641, Loss=2.1098, lr=0.0000429 Time cost=4.1 Thoughput=12.27 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 60549/88641, Loss=1.8987, lr=0.0000429 Time cost=4.1 Thoughput=12.06 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 60599/88641, Loss=2.4980, lr=0.0000429 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 60649/88641, Loss=1.9198, lr=0.0000429 Time cost=4.1 Thoughput=12.27 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 60699/88641, Loss=2.1361, lr=0.0000429 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 60749/88641, Loss=1.6636, lr=0.0000429 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 60799/88641, Loss=1.6619, lr=0.0000429 Time cost=4.1 Thoughput=12.13 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 60849/88641, Loss=1.8797, lr=0.0000428 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 60899/88641, Loss=2.3485, lr=0.0000428 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 60949/88641, Loss=1.7366, lr=0.0000428 Time cost=4.1 Thoughput=12.22 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 60999/88641, Loss=2.1982, lr=0.0000428 Time cost=4.1 Thoughput=12.21 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 61049/88641, Loss=1.7393, lr=0.0000428 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 61099/88641, Loss=2.0951, lr=0.0000428 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 61149/88641, Loss=2.3792, lr=0.0000428 Time cost=4.1 Thoughput=12.27 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 61199/88641, Loss=2.3120, lr=0.0000428 Time cost=4.1 Thoughput=12.27 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 61249/88641, Loss=2.3604, lr=0.0000428 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 61299/88641, Loss=1.7870, lr=0.0000427 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 61349/88641, Loss=2.0728, lr=0.0000427 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 61399/88641, Loss=1.8306, lr=0.0000427 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 61449/88641, Loss=2.1329, lr=0.0000427 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 61499/88641, Loss=1.4828, lr=0.0000427 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 61549/88641, Loss=2.3957, lr=0.0000427 Time cost=4.1 Thoughput=12.29 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 61599/88641, Loss=2.2317, lr=0.0000427 Time cost=4.2 Thoughput=12.01 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 61649/88641, Loss=1.9365, lr=0.0000427 Time cost=4.1 Thoughput=12.18 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 61699/88641, Loss=2.1837, lr=0.0000427 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 61749/88641, Loss=1.8393, lr=0.0000427 Time cost=4.1 Thoughput=12.28 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 61799/88641, Loss=2.1754, lr=0.0000426 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 61849/88641, Loss=2.0215, lr=0.0000426 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 61899/88641, Loss=2.0045, lr=0.0000426 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 61949/88641, Loss=2.0445, lr=0.0000426 Time cost=4.3 Thoughput=11.65 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 61999/88641, Loss=1.9468, lr=0.0000426 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 62049/88641, Loss=2.3522, lr=0.0000426 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 62099/88641, Loss=2.1199, lr=0.0000426 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 62149/88641, Loss=1.9858, lr=0.0000426 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 62199/88641, Loss=1.3602, lr=0.0000426 Time cost=4.1 Thoughput=12.27 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 62249/88641, Loss=2.1018, lr=0.0000426 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 62299/88641, Loss=2.3428, lr=0.0000425 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 62349/88641, Loss=1.7400, lr=0.0000425 Time cost=4.1 Thoughput=12.21 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 62399/88641, Loss=2.6483, lr=0.0000425 Time cost=4.1 Thoughput=12.07 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 62449/88641, Loss=1.7421, lr=0.0000425 Time cost=4.1 Thoughput=12.30 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 62499/88641, Loss=2.5209, lr=0.0000425 Time cost=4.1 Thoughput=12.28 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 62549/88641, Loss=2.2893, lr=0.0000425 Time cost=4.2 Thoughput=11.97 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 62599/88641, Loss=1.9971, lr=0.0000425 Time cost=4.1 Thoughput=12.18 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 62649/88641, Loss=2.1300, lr=0.0000425 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 62699/88641, Loss=2.5139, lr=0.0000425 Time cost=4.1 Thoughput=12.22 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 62749/88641, Loss=2.0632, lr=0.0000424 Time cost=4.2 Thoughput=12.02 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 62799/88641, Loss=2.0581, lr=0.0000424 Time cost=4.1 Thoughput=12.07 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 62849/88641, Loss=1.7156, lr=0.0000424 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 62899/88641, Loss=1.6493, lr=0.0000424 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 62949/88641, Loss=2.6658, lr=0.0000424 Time cost=4.1 Thoughput=12.21 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 62999/88641, Loss=2.4440, lr=0.0000424 Time cost=4.2 Thoughput=11.98 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 63049/88641, Loss=1.6973, lr=0.0000424 Time cost=4.1 Thoughput=12.20 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 63099/88641, Loss=1.9000, lr=0.0000424 Time cost=4.1 Thoughput=12.27 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 63149/88641, Loss=1.4206, lr=0.0000424 Time cost=4.1 Thoughput=12.27 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 63199/88641, Loss=2.1459, lr=0.0000424 Time cost=4.1 Thoughput=12.30 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 63249/88641, Loss=2.2285, lr=0.0000423 Time cost=4.1 Thoughput=12.27 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 63299/88641, Loss=1.9123, lr=0.0000423 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 63349/88641, Loss=2.2609, lr=0.0000423 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 63399/88641, Loss=2.2193, lr=0.0000423 Time cost=4.1 Thoughput=12.17 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 63449/88641, Loss=2.6376, lr=0.0000423 Time cost=4.1 Thoughput=12.20 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 63499/88641, Loss=1.5881, lr=0.0000423 Time cost=4.1 Thoughput=12.20 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 63549/88641, Loss=1.7466, lr=0.0000423 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 63599/88641, Loss=2.7152, lr=0.0000423 Time cost=4.6 Thoughput=10.87 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 63649/88641, Loss=2.4747, lr=0.0000423 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 63699/88641, Loss=2.1967, lr=0.0000422 Time cost=4.2 Thoughput=12.02 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 63749/88641, Loss=1.5504, lr=0.0000422 Time cost=4.2 Thoughput=12.01 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 63799/88641, Loss=1.9803, lr=0.0000422 Time cost=4.2 Thoughput=11.98 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 63849/88641, Loss=2.2532, lr=0.0000422 Time cost=4.2 Thoughput=12.04 samples/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gluonnlp:Epoch: 0, Batch: 63899/88641, Loss=2.3191, lr=0.0000422 Time cost=4.1 Thoughput=12.21 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 63949/88641, Loss=2.4351, lr=0.0000422 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 63999/88641, Loss=2.0314, lr=0.0000422 Time cost=4.1 Thoughput=12.27 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 64049/88641, Loss=1.1592, lr=0.0000422 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 64099/88641, Loss=2.5617, lr=0.0000422 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 64149/88641, Loss=1.5760, lr=0.0000422 Time cost=4.1 Thoughput=12.22 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 64199/88641, Loss=1.9523, lr=0.0000421 Time cost=4.1 Thoughput=12.22 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 64249/88641, Loss=2.0378, lr=0.0000421 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 64299/88641, Loss=2.8015, lr=0.0000421 Time cost=4.1 Thoughput=12.28 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 64349/88641, Loss=1.9246, lr=0.0000421 Time cost=4.1 Thoughput=12.27 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 64399/88641, Loss=1.9514, lr=0.0000421 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 64449/88641, Loss=1.8590, lr=0.0000421 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 64499/88641, Loss=1.7549, lr=0.0000421 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 64549/88641, Loss=1.9775, lr=0.0000421 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 64599/88641, Loss=1.7104, lr=0.0000421 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 64649/88641, Loss=1.8585, lr=0.0000420 Time cost=4.2 Thoughput=12.02 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 64699/88641, Loss=1.7061, lr=0.0000420 Time cost=4.2 Thoughput=11.99 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 64749/88641, Loss=2.2125, lr=0.0000420 Time cost=4.3 Thoughput=11.74 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 64799/88641, Loss=2.1207, lr=0.0000420 Time cost=4.1 Thoughput=12.17 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 64849/88641, Loss=2.1641, lr=0.0000420 Time cost=4.1 Thoughput=12.22 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 64899/88641, Loss=2.0446, lr=0.0000420 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 64949/88641, Loss=2.0270, lr=0.0000420 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 64999/88641, Loss=1.9144, lr=0.0000420 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 65049/88641, Loss=1.8102, lr=0.0000420 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 65099/88641, Loss=1.8894, lr=0.0000420 Time cost=4.1 Thoughput=12.28 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 65149/88641, Loss=1.8731, lr=0.0000419 Time cost=4.1 Thoughput=12.28 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 65199/88641, Loss=1.8154, lr=0.0000419 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 65249/88641, Loss=1.8958, lr=0.0000419 Time cost=4.1 Thoughput=12.21 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 65299/88641, Loss=1.9964, lr=0.0000419 Time cost=4.1 Thoughput=12.17 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 65349/88641, Loss=2.0490, lr=0.0000419 Time cost=4.1 Thoughput=12.22 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 65399/88641, Loss=1.7881, lr=0.0000419 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 65449/88641, Loss=1.9083, lr=0.0000419 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 65499/88641, Loss=2.0989, lr=0.0000419 Time cost=4.1 Thoughput=12.22 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 65549/88641, Loss=2.1975, lr=0.0000419 Time cost=4.1 Thoughput=12.20 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 65599/88641, Loss=1.6644, lr=0.0000419 Time cost=4.1 Thoughput=12.12 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 65649/88641, Loss=2.0705, lr=0.0000418 Time cost=4.1 Thoughput=12.15 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 65699/88641, Loss=2.5236, lr=0.0000418 Time cost=4.1 Thoughput=12.18 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 65749/88641, Loss=1.8731, lr=0.0000418 Time cost=4.2 Thoughput=12.04 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 65799/88641, Loss=2.2173, lr=0.0000418 Time cost=4.2 Thoughput=12.00 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 65849/88641, Loss=1.4827, lr=0.0000418 Time cost=4.2 Thoughput=12.00 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 65899/88641, Loss=1.5531, lr=0.0000418 Time cost=4.2 Thoughput=12.00 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 65949/88641, Loss=1.9596, lr=0.0000418 Time cost=4.1 Thoughput=12.09 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 65999/88641, Loss=2.1483, lr=0.0000418 Time cost=4.1 Thoughput=12.18 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 66049/88641, Loss=1.7992, lr=0.0000418 Time cost=4.1 Thoughput=12.22 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 66099/88641, Loss=2.3864, lr=0.0000417 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 66149/88641, Loss=1.8949, lr=0.0000417 Time cost=4.1 Thoughput=12.27 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 66199/88641, Loss=1.7533, lr=0.0000417 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 66249/88641, Loss=2.2867, lr=0.0000417 Time cost=4.1 Thoughput=12.18 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 66299/88641, Loss=1.9734, lr=0.0000417 Time cost=4.6 Thoughput=10.91 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 66349/88641, Loss=2.2572, lr=0.0000417 Time cost=4.1 Thoughput=12.19 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 66399/88641, Loss=2.2251, lr=0.0000417 Time cost=4.1 Thoughput=12.18 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 66449/88641, Loss=2.2635, lr=0.0000417 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 66499/88641, Loss=1.6478, lr=0.0000417 Time cost=4.1 Thoughput=12.20 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 66549/88641, Loss=1.7219, lr=0.0000417 Time cost=4.1 Thoughput=12.18 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 66599/88641, Loss=1.7362, lr=0.0000416 Time cost=4.1 Thoughput=12.18 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 66649/88641, Loss=1.9333, lr=0.0000416 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 66699/88641, Loss=1.9497, lr=0.0000416 Time cost=4.1 Thoughput=12.27 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 66749/88641, Loss=2.5379, lr=0.0000416 Time cost=4.1 Thoughput=12.27 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 66799/88641, Loss=1.7873, lr=0.0000416 Time cost=4.1 Thoughput=12.28 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 66849/88641, Loss=2.7123, lr=0.0000416 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 66899/88641, Loss=1.8890, lr=0.0000416 Time cost=4.1 Thoughput=12.18 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 66949/88641, Loss=1.7252, lr=0.0000416 Time cost=4.2 Thoughput=11.93 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 66999/88641, Loss=2.2493, lr=0.0000416 Time cost=4.1 Thoughput=12.20 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 67049/88641, Loss=2.2889, lr=0.0000415 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 67099/88641, Loss=1.7561, lr=0.0000415 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 67149/88641, Loss=2.1767, lr=0.0000415 Time cost=4.2 Thoughput=12.01 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 67199/88641, Loss=2.3176, lr=0.0000415 Time cost=4.1 Thoughput=12.30 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 67249/88641, Loss=2.2062, lr=0.0000415 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 67299/88641, Loss=1.6163, lr=0.0000415 Time cost=4.1 Thoughput=12.11 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 67349/88641, Loss=1.5187, lr=0.0000415 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 67399/88641, Loss=1.4233, lr=0.0000415 Time cost=4.1 Thoughput=12.18 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 67449/88641, Loss=1.5611, lr=0.0000415 Time cost=4.1 Thoughput=12.20 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 67499/88641, Loss=1.8789, lr=0.0000415 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 67549/88641, Loss=2.2768, lr=0.0000414 Time cost=4.1 Thoughput=12.18 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 67599/88641, Loss=2.1604, lr=0.0000414 Time cost=4.1 Thoughput=12.22 samples/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gluonnlp:Epoch: 0, Batch: 67649/88641, Loss=1.4990, lr=0.0000414 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 67699/88641, Loss=2.5816, lr=0.0000414 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 67749/88641, Loss=1.8354, lr=0.0000414 Time cost=4.1 Thoughput=12.28 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 67799/88641, Loss=1.8789, lr=0.0000414 Time cost=4.1 Thoughput=12.27 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 67849/88641, Loss=2.1095, lr=0.0000414 Time cost=4.1 Thoughput=12.28 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 67899/88641, Loss=2.4119, lr=0.0000414 Time cost=4.1 Thoughput=12.27 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 67949/88641, Loss=2.0322, lr=0.0000414 Time cost=4.1 Thoughput=12.30 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 67999/88641, Loss=2.3928, lr=0.0000413 Time cost=4.1 Thoughput=12.30 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 68049/88641, Loss=1.3924, lr=0.0000413 Time cost=4.1 Thoughput=12.30 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 68099/88641, Loss=2.0274, lr=0.0000413 Time cost=4.1 Thoughput=12.28 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 68149/88641, Loss=2.4902, lr=0.0000413 Time cost=4.1 Thoughput=12.27 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 68199/88641, Loss=1.7301, lr=0.0000413 Time cost=4.1 Thoughput=12.14 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 68249/88641, Loss=1.7168, lr=0.0000413 Time cost=4.1 Thoughput=12.13 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 68299/88641, Loss=1.8167, lr=0.0000413 Time cost=4.1 Thoughput=12.06 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 68349/88641, Loss=2.4313, lr=0.0000413 Time cost=4.1 Thoughput=12.07 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 68399/88641, Loss=1.7953, lr=0.0000413 Time cost=4.1 Thoughput=12.22 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 68449/88641, Loss=2.0512, lr=0.0000413 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 68499/88641, Loss=1.6213, lr=0.0000412 Time cost=4.1 Thoughput=12.27 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 68549/88641, Loss=2.2444, lr=0.0000412 Time cost=4.1 Thoughput=12.28 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 68599/88641, Loss=1.8416, lr=0.0000412 Time cost=4.1 Thoughput=12.27 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 68649/88641, Loss=2.3419, lr=0.0000412 Time cost=4.1 Thoughput=12.28 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 68699/88641, Loss=1.9004, lr=0.0000412 Time cost=4.1 Thoughput=12.27 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 68749/88641, Loss=1.5558, lr=0.0000412 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 68799/88641, Loss=2.5320, lr=0.0000412 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 68849/88641, Loss=2.0786, lr=0.0000412 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 68899/88641, Loss=2.0227, lr=0.0000412 Time cost=4.1 Thoughput=12.21 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 68949/88641, Loss=1.8411, lr=0.0000412 Time cost=4.1 Thoughput=12.17 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 68999/88641, Loss=2.4983, lr=0.0000411 Time cost=4.1 Thoughput=12.19 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 69049/88641, Loss=1.7393, lr=0.0000411 Time cost=4.1 Thoughput=12.21 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 69099/88641, Loss=2.4172, lr=0.0000411 Time cost=4.1 Thoughput=12.16 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 69149/88641, Loss=1.9159, lr=0.0000411 Time cost=4.2 Thoughput=12.04 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 69199/88641, Loss=2.0179, lr=0.0000411 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 69249/88641, Loss=2.2831, lr=0.0000411 Time cost=4.1 Thoughput=12.28 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 69299/88641, Loss=2.0736, lr=0.0000411 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 69349/88641, Loss=1.9284, lr=0.0000411 Time cost=4.1 Thoughput=12.21 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 69399/88641, Loss=2.0032, lr=0.0000411 Time cost=4.1 Thoughput=12.21 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 69449/88641, Loss=1.9271, lr=0.0000410 Time cost=4.1 Thoughput=12.27 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 69499/88641, Loss=1.7051, lr=0.0000410 Time cost=4.1 Thoughput=12.21 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 69549/88641, Loss=1.5652, lr=0.0000410 Time cost=4.1 Thoughput=12.28 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 69599/88641, Loss=1.7737, lr=0.0000410 Time cost=4.1 Thoughput=12.28 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 69649/88641, Loss=2.3309, lr=0.0000410 Time cost=4.1 Thoughput=12.27 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 69699/88641, Loss=1.9624, lr=0.0000410 Time cost=4.1 Thoughput=12.06 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 69749/88641, Loss=2.4948, lr=0.0000410 Time cost=4.1 Thoughput=12.30 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 69799/88641, Loss=2.1636, lr=0.0000410 Time cost=4.1 Thoughput=12.27 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 69849/88641, Loss=1.8370, lr=0.0000410 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 69899/88641, Loss=2.0292, lr=0.0000410 Time cost=4.1 Thoughput=12.20 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 69949/88641, Loss=1.9828, lr=0.0000409 Time cost=4.1 Thoughput=12.20 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 69999/88641, Loss=2.0461, lr=0.0000409 Time cost=4.1 Thoughput=12.22 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 70049/88641, Loss=1.6213, lr=0.0000409 Time cost=4.1 Thoughput=12.15 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 70099/88641, Loss=1.9621, lr=0.0000409 Time cost=4.1 Thoughput=12.21 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 70149/88641, Loss=1.8434, lr=0.0000409 Time cost=4.6 Thoughput=10.85 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 70199/88641, Loss=2.4019, lr=0.0000409 Time cost=4.1 Thoughput=12.27 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 70249/88641, Loss=1.9621, lr=0.0000409 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 70299/88641, Loss=2.3099, lr=0.0000409 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 70349/88641, Loss=1.9494, lr=0.0000409 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 70399/88641, Loss=2.1036, lr=0.0000408 Time cost=4.1 Thoughput=12.20 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 70449/88641, Loss=2.3827, lr=0.0000408 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 70499/88641, Loss=2.4183, lr=0.0000408 Time cost=4.1 Thoughput=12.19 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 70549/88641, Loss=1.5790, lr=0.0000408 Time cost=4.1 Thoughput=12.19 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 70599/88641, Loss=1.9613, lr=0.0000408 Time cost=4.1 Thoughput=12.18 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 70649/88641, Loss=1.7302, lr=0.0000408 Time cost=4.1 Thoughput=12.20 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 70699/88641, Loss=2.5922, lr=0.0000408 Time cost=4.1 Thoughput=12.16 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 70749/88641, Loss=2.2470, lr=0.0000408 Time cost=4.1 Thoughput=12.19 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 70799/88641, Loss=2.1291, lr=0.0000408 Time cost=4.1 Thoughput=12.17 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 70849/88641, Loss=1.8565, lr=0.0000408 Time cost=4.1 Thoughput=12.21 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 70899/88641, Loss=2.4375, lr=0.0000407 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 70949/88641, Loss=1.8434, lr=0.0000407 Time cost=4.1 Thoughput=12.22 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 70999/88641, Loss=1.7190, lr=0.0000407 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 71049/88641, Loss=1.9936, lr=0.0000407 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 71099/88641, Loss=1.7185, lr=0.0000407 Time cost=4.2 Thoughput=12.03 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 71149/88641, Loss=1.7848, lr=0.0000407 Time cost=4.1 Thoughput=12.05 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 71199/88641, Loss=1.4502, lr=0.0000407 Time cost=4.1 Thoughput=12.16 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 71249/88641, Loss=1.7641, lr=0.0000407 Time cost=4.1 Thoughput=12.28 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 71299/88641, Loss=1.5093, lr=0.0000407 Time cost=4.1 Thoughput=12.05 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 71349/88641, Loss=1.9626, lr=0.0000406 Time cost=4.1 Thoughput=12.22 samples/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gluonnlp:Epoch: 0, Batch: 71399/88641, Loss=2.3167, lr=0.0000406 Time cost=4.1 Thoughput=12.13 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 71449/88641, Loss=1.8355, lr=0.0000406 Time cost=4.1 Thoughput=12.17 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 71499/88641, Loss=1.9428, lr=0.0000406 Time cost=4.1 Thoughput=12.18 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 71549/88641, Loss=2.0944, lr=0.0000406 Time cost=4.1 Thoughput=12.22 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 71599/88641, Loss=1.8491, lr=0.0000406 Time cost=4.1 Thoughput=12.27 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 71649/88641, Loss=1.7407, lr=0.0000406 Time cost=4.2 Thoughput=12.04 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 71699/88641, Loss=1.8197, lr=0.0000406 Time cost=4.2 Thoughput=12.03 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 71749/88641, Loss=1.5723, lr=0.0000406 Time cost=4.2 Thoughput=12.02 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 71799/88641, Loss=2.0590, lr=0.0000406 Time cost=4.2 Thoughput=12.00 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 71849/88641, Loss=1.8503, lr=0.0000405 Time cost=4.2 Thoughput=12.01 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 71899/88641, Loss=2.4701, lr=0.0000405 Time cost=4.2 Thoughput=12.00 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 71949/88641, Loss=1.0405, lr=0.0000405 Time cost=4.2 Thoughput=12.03 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 71999/88641, Loss=2.5953, lr=0.0000405 Time cost=4.2 Thoughput=11.99 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 72049/88641, Loss=1.9691, lr=0.0000405 Time cost=4.2 Thoughput=11.85 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 72099/88641, Loss=2.0142, lr=0.0000405 Time cost=4.1 Thoughput=12.22 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 72149/88641, Loss=1.2767, lr=0.0000405 Time cost=4.1 Thoughput=12.22 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 72199/88641, Loss=1.7054, lr=0.0000405 Time cost=4.1 Thoughput=12.20 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 72249/88641, Loss=2.1030, lr=0.0000405 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 72299/88641, Loss=2.6722, lr=0.0000405 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 72349/88641, Loss=1.8298, lr=0.0000404 Time cost=4.1 Thoughput=12.09 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 72399/88641, Loss=2.2599, lr=0.0000404 Time cost=4.2 Thoughput=12.03 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 72449/88641, Loss=2.2146, lr=0.0000404 Time cost=4.1 Thoughput=12.30 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 72499/88641, Loss=1.9519, lr=0.0000404 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 72549/88641, Loss=2.2400, lr=0.0000404 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 72599/88641, Loss=1.6785, lr=0.0000404 Time cost=4.1 Thoughput=12.08 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 72649/88641, Loss=1.6257, lr=0.0000404 Time cost=4.2 Thoughput=11.96 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 72699/88641, Loss=1.6123, lr=0.0000404 Time cost=4.2 Thoughput=11.98 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 72749/88641, Loss=1.9827, lr=0.0000404 Time cost=4.2 Thoughput=11.99 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 72799/88641, Loss=2.2840, lr=0.0000403 Time cost=4.2 Thoughput=11.98 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 72849/88641, Loss=2.1298, lr=0.0000403 Time cost=4.6 Thoughput=10.88 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 72899/88641, Loss=2.1112, lr=0.0000403 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 72949/88641, Loss=1.8356, lr=0.0000403 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 72999/88641, Loss=2.5813, lr=0.0000403 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 73049/88641, Loss=1.4475, lr=0.0000403 Time cost=4.1 Thoughput=12.27 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 73099/88641, Loss=2.1678, lr=0.0000403 Time cost=4.1 Thoughput=12.17 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 73149/88641, Loss=2.3612, lr=0.0000403 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 73199/88641, Loss=1.3436, lr=0.0000403 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 73249/88641, Loss=1.8191, lr=0.0000403 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 73299/88641, Loss=2.3324, lr=0.0000402 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 73349/88641, Loss=1.7292, lr=0.0000402 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 73399/88641, Loss=1.8418, lr=0.0000402 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 73449/88641, Loss=2.0078, lr=0.0000402 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 73499/88641, Loss=2.2214, lr=0.0000402 Time cost=4.2 Thoughput=11.92 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 73549/88641, Loss=1.8817, lr=0.0000402 Time cost=4.1 Thoughput=12.20 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 73599/88641, Loss=2.0294, lr=0.0000402 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 73649/88641, Loss=1.8388, lr=0.0000402 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 73699/88641, Loss=1.8678, lr=0.0000402 Time cost=4.1 Thoughput=12.27 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 73749/88641, Loss=1.5843, lr=0.0000401 Time cost=4.1 Thoughput=12.18 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 73799/88641, Loss=2.1487, lr=0.0000401 Time cost=4.2 Thoughput=12.00 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 73849/88641, Loss=1.7100, lr=0.0000401 Time cost=4.1 Thoughput=12.22 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 73899/88641, Loss=2.0313, lr=0.0000401 Time cost=4.1 Thoughput=12.22 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 73949/88641, Loss=2.1650, lr=0.0000401 Time cost=4.2 Thoughput=12.02 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 73999/88641, Loss=1.7034, lr=0.0000401 Time cost=4.1 Thoughput=12.07 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 74049/88641, Loss=1.7400, lr=0.0000401 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 74099/88641, Loss=2.3789, lr=0.0000401 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 74149/88641, Loss=2.4684, lr=0.0000401 Time cost=4.1 Thoughput=12.27 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 74199/88641, Loss=1.6235, lr=0.0000401 Time cost=4.1 Thoughput=12.21 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 74249/88641, Loss=2.3764, lr=0.0000400 Time cost=4.1 Thoughput=12.22 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 74299/88641, Loss=1.8079, lr=0.0000400 Time cost=4.1 Thoughput=12.28 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 74349/88641, Loss=2.3565, lr=0.0000400 Time cost=4.1 Thoughput=12.27 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 74399/88641, Loss=1.8370, lr=0.0000400 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 74449/88641, Loss=1.3836, lr=0.0000400 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 74499/88641, Loss=1.7041, lr=0.0000400 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 74549/88641, Loss=1.3641, lr=0.0000400 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 74599/88641, Loss=1.4449, lr=0.0000400 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 74649/88641, Loss=1.9548, lr=0.0000400 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 74699/88641, Loss=1.9822, lr=0.0000399 Time cost=4.1 Thoughput=12.22 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 74749/88641, Loss=2.2412, lr=0.0000399 Time cost=4.1 Thoughput=12.16 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 74799/88641, Loss=1.9077, lr=0.0000399 Time cost=4.1 Thoughput=12.21 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 74849/88641, Loss=1.7166, lr=0.0000399 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 74899/88641, Loss=1.9330, lr=0.0000399 Time cost=4.1 Thoughput=12.22 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 74949/88641, Loss=1.7715, lr=0.0000399 Time cost=4.1 Thoughput=12.28 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 74999/88641, Loss=2.1955, lr=0.0000399 Time cost=4.1 Thoughput=12.28 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 75049/88641, Loss=2.2469, lr=0.0000399 Time cost=4.1 Thoughput=12.19 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 75099/88641, Loss=1.5828, lr=0.0000399 Time cost=4.2 Thoughput=12.02 samples/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gluonnlp:Epoch: 0, Batch: 75149/88641, Loss=1.5743, lr=0.0000399 Time cost=4.1 Thoughput=12.15 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 75199/88641, Loss=1.7381, lr=0.0000398 Time cost=4.1 Thoughput=12.21 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 75249/88641, Loss=1.4470, lr=0.0000398 Time cost=4.1 Thoughput=12.18 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 75299/88641, Loss=1.8967, lr=0.0000398 Time cost=4.1 Thoughput=12.20 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 75349/88641, Loss=2.2144, lr=0.0000398 Time cost=4.1 Thoughput=12.19 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 75399/88641, Loss=1.9514, lr=0.0000398 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 75449/88641, Loss=2.0400, lr=0.0000398 Time cost=4.1 Thoughput=12.27 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 75499/88641, Loss=2.3377, lr=0.0000398 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 75549/88641, Loss=1.9035, lr=0.0000398 Time cost=4.1 Thoughput=12.28 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 75599/88641, Loss=2.1758, lr=0.0000398 Time cost=4.1 Thoughput=12.28 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 75649/88641, Loss=2.0977, lr=0.0000398 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 75699/88641, Loss=1.8682, lr=0.0000397 Time cost=4.2 Thoughput=12.05 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 75749/88641, Loss=1.2973, lr=0.0000397 Time cost=4.1 Thoughput=12.27 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 75799/88641, Loss=1.9695, lr=0.0000397 Time cost=4.1 Thoughput=12.21 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 75849/88641, Loss=2.1568, lr=0.0000397 Time cost=4.1 Thoughput=12.14 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 75899/88641, Loss=1.9216, lr=0.0000397 Time cost=4.1 Thoughput=12.27 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 75949/88641, Loss=1.8458, lr=0.0000397 Time cost=4.2 Thoughput=12.03 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 75999/88641, Loss=1.7939, lr=0.0000397 Time cost=4.2 Thoughput=12.01 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 76049/88641, Loss=2.5110, lr=0.0000397 Time cost=4.1 Thoughput=12.27 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 76099/88641, Loss=1.7916, lr=0.0000397 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 76149/88641, Loss=2.4610, lr=0.0000396 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 76199/88641, Loss=2.2873, lr=0.0000396 Time cost=4.1 Thoughput=12.17 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 76249/88641, Loss=1.6756, lr=0.0000396 Time cost=4.1 Thoughput=12.17 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 76299/88641, Loss=1.7273, lr=0.0000396 Time cost=4.1 Thoughput=12.20 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 76349/88641, Loss=1.7359, lr=0.0000396 Time cost=4.1 Thoughput=12.21 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 76399/88641, Loss=2.2257, lr=0.0000396 Time cost=4.1 Thoughput=12.20 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 76449/88641, Loss=1.6030, lr=0.0000396 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 76499/88641, Loss=2.4538, lr=0.0000396 Time cost=4.1 Thoughput=12.30 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 76549/88641, Loss=2.3455, lr=0.0000396 Time cost=4.1 Thoughput=12.31 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 76599/88641, Loss=2.3567, lr=0.0000396 Time cost=4.1 Thoughput=12.31 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 76649/88641, Loss=2.0434, lr=0.0000395 Time cost=4.1 Thoughput=12.21 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 76699/88641, Loss=1.9413, lr=0.0000395 Time cost=4.7 Thoughput=10.66 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 76749/88641, Loss=1.9721, lr=0.0000395 Time cost=4.2 Thoughput=11.98 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 76799/88641, Loss=2.1487, lr=0.0000395 Time cost=4.1 Thoughput=12.21 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 76849/88641, Loss=2.0811, lr=0.0000395 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 76899/88641, Loss=2.1757, lr=0.0000395 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 76949/88641, Loss=2.0766, lr=0.0000395 Time cost=4.1 Thoughput=12.22 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 76999/88641, Loss=2.2082, lr=0.0000395 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 77049/88641, Loss=2.0722, lr=0.0000395 Time cost=4.1 Thoughput=12.21 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 77099/88641, Loss=2.5187, lr=0.0000394 Time cost=4.1 Thoughput=12.22 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 77149/88641, Loss=1.9162, lr=0.0000394 Time cost=4.2 Thoughput=12.00 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 77199/88641, Loss=2.2494, lr=0.0000394 Time cost=4.1 Thoughput=12.18 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 77249/88641, Loss=2.3001, lr=0.0000394 Time cost=4.1 Thoughput=12.21 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 77299/88641, Loss=1.5904, lr=0.0000394 Time cost=4.1 Thoughput=12.20 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 77349/88641, Loss=1.9176, lr=0.0000394 Time cost=4.1 Thoughput=12.19 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 77399/88641, Loss=2.0093, lr=0.0000394 Time cost=4.1 Thoughput=12.17 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 77449/88641, Loss=2.1662, lr=0.0000394 Time cost=4.1 Thoughput=12.18 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 77499/88641, Loss=1.9130, lr=0.0000394 Time cost=4.1 Thoughput=12.19 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 77549/88641, Loss=2.0022, lr=0.0000394 Time cost=4.1 Thoughput=12.17 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 77599/88641, Loss=1.8644, lr=0.0000393 Time cost=4.1 Thoughput=12.20 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 77649/88641, Loss=1.8791, lr=0.0000393 Time cost=4.1 Thoughput=12.20 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 77699/88641, Loss=1.6607, lr=0.0000393 Time cost=4.1 Thoughput=12.20 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 77749/88641, Loss=1.7910, lr=0.0000393 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 77799/88641, Loss=2.0339, lr=0.0000393 Time cost=4.2 Thoughput=11.91 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 77849/88641, Loss=1.8414, lr=0.0000393 Time cost=4.2 Thoughput=12.04 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 77899/88641, Loss=2.0624, lr=0.0000393 Time cost=4.3 Thoughput=11.69 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 77949/88641, Loss=1.6806, lr=0.0000393 Time cost=4.1 Thoughput=12.17 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 77999/88641, Loss=1.6264, lr=0.0000393 Time cost=4.1 Thoughput=12.18 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 78049/88641, Loss=2.1886, lr=0.0000392 Time cost=4.1 Thoughput=12.17 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 78099/88641, Loss=2.2006, lr=0.0000392 Time cost=4.1 Thoughput=12.14 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 78149/88641, Loss=1.8518, lr=0.0000392 Time cost=4.1 Thoughput=12.16 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 78199/88641, Loss=2.2061, lr=0.0000392 Time cost=4.1 Thoughput=12.11 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 78249/88641, Loss=1.9649, lr=0.0000392 Time cost=4.1 Thoughput=12.22 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 78299/88641, Loss=1.4761, lr=0.0000392 Time cost=4.1 Thoughput=12.21 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 78349/88641, Loss=1.8777, lr=0.0000392 Time cost=4.1 Thoughput=12.19 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 78399/88641, Loss=2.3574, lr=0.0000392 Time cost=4.1 Thoughput=12.22 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 78449/88641, Loss=2.3443, lr=0.0000392 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 78499/88641, Loss=1.8358, lr=0.0000392 Time cost=4.1 Thoughput=12.16 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 78549/88641, Loss=2.3456, lr=0.0000391 Time cost=4.1 Thoughput=12.15 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 78599/88641, Loss=1.7429, lr=0.0000391 Time cost=4.2 Thoughput=12.01 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 78649/88641, Loss=1.7160, lr=0.0000391 Time cost=4.2 Thoughput=12.02 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 78699/88641, Loss=1.5380, lr=0.0000391 Time cost=4.2 Thoughput=12.03 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 78749/88641, Loss=2.0882, lr=0.0000391 Time cost=4.1 Thoughput=12.14 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 78799/88641, Loss=2.3133, lr=0.0000391 Time cost=4.1 Thoughput=12.22 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 78849/88641, Loss=1.3138, lr=0.0000391 Time cost=4.1 Thoughput=12.20 samples/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gluonnlp:Epoch: 0, Batch: 78899/88641, Loss=1.7973, lr=0.0000391 Time cost=4.1 Thoughput=12.21 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 78949/88641, Loss=2.3347, lr=0.0000391 Time cost=4.1 Thoughput=12.09 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 78999/88641, Loss=1.5988, lr=0.0000391 Time cost=4.2 Thoughput=11.98 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 79049/88641, Loss=1.2543, lr=0.0000390 Time cost=4.1 Thoughput=12.18 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 79099/88641, Loss=1.6230, lr=0.0000390 Time cost=4.1 Thoughput=12.21 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 79149/88641, Loss=1.9872, lr=0.0000390 Time cost=4.1 Thoughput=12.19 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 79199/88641, Loss=2.4216, lr=0.0000390 Time cost=4.1 Thoughput=12.20 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 79249/88641, Loss=2.4642, lr=0.0000390 Time cost=4.1 Thoughput=12.21 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 79299/88641, Loss=2.2782, lr=0.0000390 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 79349/88641, Loss=2.0564, lr=0.0000390 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 79399/88641, Loss=1.9265, lr=0.0000390 Time cost=4.6 Thoughput=10.94 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 79449/88641, Loss=2.1769, lr=0.0000390 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 79499/88641, Loss=2.6339, lr=0.0000389 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 79549/88641, Loss=1.4558, lr=0.0000389 Time cost=4.1 Thoughput=12.27 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 79599/88641, Loss=2.4978, lr=0.0000389 Time cost=4.1 Thoughput=12.28 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 79649/88641, Loss=2.3164, lr=0.0000389 Time cost=4.1 Thoughput=12.21 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 79699/88641, Loss=1.7149, lr=0.0000389 Time cost=4.1 Thoughput=12.22 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 79749/88641, Loss=1.8481, lr=0.0000389 Time cost=4.1 Thoughput=12.17 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 79799/88641, Loss=1.7193, lr=0.0000389 Time cost=4.1 Thoughput=12.10 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 79849/88641, Loss=1.8535, lr=0.0000389 Time cost=4.1 Thoughput=12.29 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 79899/88641, Loss=2.3555, lr=0.0000389 Time cost=4.1 Thoughput=12.28 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 79949/88641, Loss=2.2402, lr=0.0000389 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 79999/88641, Loss=1.3392, lr=0.0000388 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 80049/88641, Loss=1.7832, lr=0.0000388 Time cost=4.2 Thoughput=11.97 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 80099/88641, Loss=2.7694, lr=0.0000388 Time cost=4.1 Thoughput=12.18 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 80149/88641, Loss=1.5922, lr=0.0000388 Time cost=4.1 Thoughput=12.19 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 80199/88641, Loss=2.0680, lr=0.0000388 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 80249/88641, Loss=1.7893, lr=0.0000388 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 80299/88641, Loss=1.3919, lr=0.0000388 Time cost=4.1 Thoughput=12.13 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 80349/88641, Loss=2.0371, lr=0.0000388 Time cost=4.2 Thoughput=12.02 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 80399/88641, Loss=2.1860, lr=0.0000388 Time cost=4.1 Thoughput=12.29 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 80449/88641, Loss=1.3228, lr=0.0000387 Time cost=4.1 Thoughput=12.22 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 80499/88641, Loss=2.5120, lr=0.0000387 Time cost=4.2 Thoughput=11.99 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 80549/88641, Loss=1.7675, lr=0.0000387 Time cost=4.1 Thoughput=12.22 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 80599/88641, Loss=2.2343, lr=0.0000387 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 80649/88641, Loss=2.0464, lr=0.0000387 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 80699/88641, Loss=2.3240, lr=0.0000387 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 80749/88641, Loss=2.1265, lr=0.0000387 Time cost=4.1 Thoughput=12.21 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 80799/88641, Loss=2.1948, lr=0.0000387 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 80849/88641, Loss=2.1907, lr=0.0000387 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 80899/88641, Loss=2.0979, lr=0.0000387 Time cost=4.1 Thoughput=12.05 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 80949/88641, Loss=1.9750, lr=0.0000386 Time cost=4.2 Thoughput=11.99 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 80999/88641, Loss=1.8270, lr=0.0000386 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 81049/88641, Loss=2.0545, lr=0.0000386 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 81099/88641, Loss=2.5039, lr=0.0000386 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 81149/88641, Loss=1.8869, lr=0.0000386 Time cost=4.1 Thoughput=12.27 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 81199/88641, Loss=2.4763, lr=0.0000386 Time cost=4.8 Thoughput=10.46 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 81249/88641, Loss=1.4821, lr=0.0000386 Time cost=4.2 Thoughput=12.02 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 81299/88641, Loss=2.4683, lr=0.0000386 Time cost=4.1 Thoughput=12.14 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 81349/88641, Loss=2.1504, lr=0.0000386 Time cost=4.1 Thoughput=12.16 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 81399/88641, Loss=2.5258, lr=0.0000385 Time cost=4.1 Thoughput=12.20 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 81449/88641, Loss=1.8814, lr=0.0000385 Time cost=4.1 Thoughput=12.18 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 81499/88641, Loss=1.6978, lr=0.0000385 Time cost=4.1 Thoughput=12.29 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 81549/88641, Loss=2.0599, lr=0.0000385 Time cost=4.1 Thoughput=12.28 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 81599/88641, Loss=1.8104, lr=0.0000385 Time cost=4.1 Thoughput=12.29 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 81649/88641, Loss=1.5118, lr=0.0000385 Time cost=4.1 Thoughput=12.30 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 81699/88641, Loss=1.9898, lr=0.0000385 Time cost=4.1 Thoughput=12.17 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 81749/88641, Loss=1.9572, lr=0.0000385 Time cost=4.1 Thoughput=12.29 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 81799/88641, Loss=2.1673, lr=0.0000385 Time cost=4.8 Thoughput=10.51 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 81849/88641, Loss=2.3311, lr=0.0000385 Time cost=4.1 Thoughput=12.29 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 81899/88641, Loss=2.3234, lr=0.0000384 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 81949/88641, Loss=1.5468, lr=0.0000384 Time cost=4.1 Thoughput=12.27 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 81999/88641, Loss=1.7706, lr=0.0000384 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 82049/88641, Loss=2.3799, lr=0.0000384 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 82099/88641, Loss=2.4002, lr=0.0000384 Time cost=4.8 Thoughput=10.51 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 82149/88641, Loss=2.0746, lr=0.0000384 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 82199/88641, Loss=1.8754, lr=0.0000384 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 82249/88641, Loss=1.5674, lr=0.0000384 Time cost=4.2 Thoughput=12.02 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 82299/88641, Loss=2.0816, lr=0.0000384 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 82349/88641, Loss=1.9017, lr=0.0000384 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 82399/88641, Loss=1.4505, lr=0.0000383 Time cost=4.1 Thoughput=12.29 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 82449/88641, Loss=2.5149, lr=0.0000383 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 82499/88641, Loss=1.6361, lr=0.0000383 Time cost=4.1 Thoughput=12.17 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 82549/88641, Loss=1.9979, lr=0.0000383 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 82599/88641, Loss=2.0611, lr=0.0000383 Time cost=4.1 Thoughput=12.26 samples/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gluonnlp:Epoch: 0, Batch: 82649/88641, Loss=2.2721, lr=0.0000383 Time cost=4.7 Thoughput=10.53 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 82699/88641, Loss=1.6509, lr=0.0000383 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 82749/88641, Loss=2.2947, lr=0.0000383 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 82799/88641, Loss=1.8063, lr=0.0000383 Time cost=4.1 Thoughput=12.18 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 82849/88641, Loss=1.2470, lr=0.0000382 Time cost=4.1 Thoughput=12.21 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 82899/88641, Loss=2.0231, lr=0.0000382 Time cost=4.1 Thoughput=12.21 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 82949/88641, Loss=1.9765, lr=0.0000382 Time cost=4.1 Thoughput=12.28 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 82999/88641, Loss=1.9351, lr=0.0000382 Time cost=4.1 Thoughput=12.05 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 83049/88641, Loss=2.2368, lr=0.0000382 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 83099/88641, Loss=2.1656, lr=0.0000382 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 83149/88641, Loss=1.9510, lr=0.0000382 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 83199/88641, Loss=2.1728, lr=0.0000382 Time cost=4.1 Thoughput=12.20 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 83249/88641, Loss=2.2628, lr=0.0000382 Time cost=4.6 Thoughput=10.85 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 83299/88641, Loss=2.0809, lr=0.0000382 Time cost=4.2 Thoughput=11.97 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 83349/88641, Loss=2.2204, lr=0.0000381 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 83399/88641, Loss=2.0763, lr=0.0000381 Time cost=4.1 Thoughput=12.22 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 83449/88641, Loss=2.0023, lr=0.0000381 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 83499/88641, Loss=1.7147, lr=0.0000381 Time cost=4.1 Thoughput=12.22 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 83549/88641, Loss=2.0662, lr=0.0000381 Time cost=4.2 Thoughput=12.01 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 83599/88641, Loss=1.7324, lr=0.0000381 Time cost=4.1 Thoughput=12.11 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 83649/88641, Loss=2.4072, lr=0.0000381 Time cost=4.1 Thoughput=12.21 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 83699/88641, Loss=2.1137, lr=0.0000381 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 83749/88641, Loss=1.7848, lr=0.0000381 Time cost=4.1 Thoughput=12.27 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 83799/88641, Loss=2.2676, lr=0.0000380 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 83849/88641, Loss=1.8681, lr=0.0000380 Time cost=4.1 Thoughput=12.22 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 83899/88641, Loss=2.0970, lr=0.0000380 Time cost=4.1 Thoughput=12.21 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 83949/88641, Loss=1.7750, lr=0.0000380 Time cost=4.1 Thoughput=12.15 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 83999/88641, Loss=1.8888, lr=0.0000380 Time cost=4.1 Thoughput=12.22 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 84049/88641, Loss=1.8979, lr=0.0000380 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 84099/88641, Loss=1.6706, lr=0.0000380 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 84149/88641, Loss=2.3633, lr=0.0000380 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 84199/88641, Loss=1.8059, lr=0.0000380 Time cost=4.1 Thoughput=12.22 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 84249/88641, Loss=2.3572, lr=0.0000380 Time cost=4.1 Thoughput=12.20 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 84299/88641, Loss=1.8113, lr=0.0000379 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 84349/88641, Loss=1.9519, lr=0.0000379 Time cost=4.1 Thoughput=12.22 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 84399/88641, Loss=1.7428, lr=0.0000379 Time cost=4.2 Thoughput=11.92 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 84449/88641, Loss=2.2838, lr=0.0000379 Time cost=4.1 Thoughput=12.21 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 84499/88641, Loss=2.3355, lr=0.0000379 Time cost=4.2 Thoughput=12.01 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 84549/88641, Loss=2.3559, lr=0.0000379 Time cost=4.2 Thoughput=11.98 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 84599/88641, Loss=1.9285, lr=0.0000379 Time cost=4.2 Thoughput=12.00 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 84649/88641, Loss=1.3392, lr=0.0000379 Time cost=4.1 Thoughput=12.08 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 84699/88641, Loss=2.2126, lr=0.0000379 Time cost=4.1 Thoughput=12.28 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 84749/88641, Loss=1.5176, lr=0.0000378 Time cost=4.1 Thoughput=12.18 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 84799/88641, Loss=2.1686, lr=0.0000378 Time cost=4.1 Thoughput=12.21 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 84849/88641, Loss=2.0922, lr=0.0000378 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 84899/88641, Loss=2.1262, lr=0.0000378 Time cost=4.1 Thoughput=12.20 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 84949/88641, Loss=1.4566, lr=0.0000378 Time cost=4.2 Thoughput=11.99 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 84999/88641, Loss=2.0465, lr=0.0000378 Time cost=4.2 Thoughput=12.01 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 85049/88641, Loss=1.9583, lr=0.0000378 Time cost=4.2 Thoughput=11.96 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 85099/88641, Loss=1.8656, lr=0.0000378 Time cost=4.2 Thoughput=11.92 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 85149/88641, Loss=1.8004, lr=0.0000378 Time cost=4.3 Thoughput=11.75 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 85199/88641, Loss=2.0568, lr=0.0000378 Time cost=4.3 Thoughput=11.72 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 85249/88641, Loss=2.0903, lr=0.0000377 Time cost=4.1 Thoughput=12.10 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 85299/88641, Loss=2.2934, lr=0.0000377 Time cost=4.1 Thoughput=12.30 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 85349/88641, Loss=2.0168, lr=0.0000377 Time cost=4.1 Thoughput=12.31 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 85399/88641, Loss=1.4950, lr=0.0000377 Time cost=4.2 Thoughput=12.02 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 85449/88641, Loss=1.4874, lr=0.0000377 Time cost=4.1 Thoughput=12.17 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 85499/88641, Loss=2.1537, lr=0.0000377 Time cost=4.1 Thoughput=12.21 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 85549/88641, Loss=1.3408, lr=0.0000377 Time cost=4.1 Thoughput=12.06 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 85599/88641, Loss=2.2337, lr=0.0000377 Time cost=4.1 Thoughput=12.08 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 85649/88641, Loss=1.6991, lr=0.0000377 Time cost=4.1 Thoughput=12.13 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 85699/88641, Loss=1.8962, lr=0.0000377 Time cost=4.1 Thoughput=12.11 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 85749/88641, Loss=2.4348, lr=0.0000376 Time cost=4.1 Thoughput=12.19 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 85799/88641, Loss=1.6939, lr=0.0000376 Time cost=4.1 Thoughput=12.18 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 85849/88641, Loss=2.2553, lr=0.0000376 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 85899/88641, Loss=1.9496, lr=0.0000376 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 85949/88641, Loss=1.8379, lr=0.0000376 Time cost=4.6 Thoughput=10.77 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 85999/88641, Loss=1.7807, lr=0.0000376 Time cost=4.1 Thoughput=12.29 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 86049/88641, Loss=2.0521, lr=0.0000376 Time cost=4.1 Thoughput=12.28 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 86099/88641, Loss=1.5192, lr=0.0000376 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 86149/88641, Loss=2.8383, lr=0.0000376 Time cost=4.2 Thoughput=12.00 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 86199/88641, Loss=1.7213, lr=0.0000375 Time cost=4.1 Thoughput=12.15 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 86249/88641, Loss=2.3415, lr=0.0000375 Time cost=4.1 Thoughput=12.14 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 86299/88641, Loss=1.4108, lr=0.0000375 Time cost=4.1 Thoughput=12.21 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 86349/88641, Loss=1.2348, lr=0.0000375 Time cost=4.1 Thoughput=12.26 samples/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gluonnlp:Epoch: 0, Batch: 86399/88641, Loss=1.0634, lr=0.0000375 Time cost=4.1 Thoughput=12.22 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 86449/88641, Loss=2.5137, lr=0.0000375 Time cost=4.1 Thoughput=12.27 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 86499/88641, Loss=1.9312, lr=0.0000375 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 86549/88641, Loss=2.1348, lr=0.0000375 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 86599/88641, Loss=1.9851, lr=0.0000375 Time cost=4.2 Thoughput=12.01 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 86649/88641, Loss=1.4952, lr=0.0000375 Time cost=4.1 Thoughput=12.13 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 86699/88641, Loss=2.3255, lr=0.0000374 Time cost=4.1 Thoughput=12.21 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 86749/88641, Loss=2.3959, lr=0.0000374 Time cost=4.1 Thoughput=12.27 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 86799/88641, Loss=1.7481, lr=0.0000374 Time cost=4.1 Thoughput=12.21 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 86849/88641, Loss=2.0359, lr=0.0000374 Time cost=4.1 Thoughput=12.14 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 86899/88641, Loss=1.9536, lr=0.0000374 Time cost=4.1 Thoughput=12.16 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 86949/88641, Loss=2.7267, lr=0.0000374 Time cost=4.2 Thoughput=11.93 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 86999/88641, Loss=1.5667, lr=0.0000374 Time cost=4.2 Thoughput=11.88 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 87049/88641, Loss=1.7911, lr=0.0000374 Time cost=4.1 Thoughput=12.20 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 87099/88641, Loss=2.0627, lr=0.0000374 Time cost=4.1 Thoughput=12.19 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 87149/88641, Loss=1.6435, lr=0.0000373 Time cost=4.1 Thoughput=12.11 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 87199/88641, Loss=2.3834, lr=0.0000373 Time cost=4.1 Thoughput=12.16 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 87249/88641, Loss=1.8258, lr=0.0000373 Time cost=4.1 Thoughput=12.16 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 87299/88641, Loss=1.9666, lr=0.0000373 Time cost=4.1 Thoughput=12.19 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 87349/88641, Loss=1.9491, lr=0.0000373 Time cost=4.2 Thoughput=12.04 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 87399/88641, Loss=1.9234, lr=0.0000373 Time cost=4.1 Thoughput=12.08 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 87449/88641, Loss=1.9947, lr=0.0000373 Time cost=4.1 Thoughput=12.16 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 87499/88641, Loss=1.9793, lr=0.0000373 Time cost=4.1 Thoughput=12.19 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 87549/88641, Loss=1.8243, lr=0.0000373 Time cost=4.1 Thoughput=12.21 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 87599/88641, Loss=2.3704, lr=0.0000373 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 87649/88641, Loss=1.4255, lr=0.0000372 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 87699/88641, Loss=1.9002, lr=0.0000372 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 87749/88641, Loss=2.3083, lr=0.0000372 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 87799/88641, Loss=1.8786, lr=0.0000372 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 87849/88641, Loss=1.8217, lr=0.0000372 Time cost=4.1 Thoughput=12.22 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 87899/88641, Loss=2.1704, lr=0.0000372 Time cost=4.1 Thoughput=12.12 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 87949/88641, Loss=1.6502, lr=0.0000372 Time cost=4.2 Thoughput=12.02 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 87999/88641, Loss=1.4970, lr=0.0000372 Time cost=4.2 Thoughput=11.99 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 88049/88641, Loss=2.0133, lr=0.0000372 Time cost=4.2 Thoughput=11.98 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 88099/88641, Loss=2.0434, lr=0.0000372 Time cost=4.2 Thoughput=11.98 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 88149/88641, Loss=1.7103, lr=0.0000371 Time cost=4.1 Thoughput=12.07 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 88199/88641, Loss=1.7212, lr=0.0000371 Time cost=4.1 Thoughput=12.15 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 88249/88641, Loss=1.5113, lr=0.0000371 Time cost=4.1 Thoughput=12.15 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 88299/88641, Loss=2.7142, lr=0.0000371 Time cost=4.1 Thoughput=12.10 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 88349/88641, Loss=1.7233, lr=0.0000371 Time cost=4.2 Thoughput=12.00 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 88399/88641, Loss=1.7981, lr=0.0000371 Time cost=4.1 Thoughput=12.10 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 88449/88641, Loss=2.1686, lr=0.0000371 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 88499/88641, Loss=1.5747, lr=0.0000371 Time cost=4.1 Thoughput=12.29 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 88549/88641, Loss=1.9505, lr=0.0000371 Time cost=4.1 Thoughput=12.27 samples/s\n",
      "INFO:gluonnlp:Epoch: 0, Batch: 88599/88641, Loss=2.0742, lr=0.0000370 Time cost=4.2 Thoughput=12.04 samples/s\n",
      "INFO:gluonnlp:Time cost=7305.53 s, Thoughput=12.13 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 49/88641, Loss=1.3287, lr=0.0000370 Time cost=4.2 Thoughput=21.87 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 99/88641, Loss=2.1834, lr=0.0000370 Time cost=4.2 Thoughput=11.97 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 149/88641, Loss=1.9483, lr=0.0000370 Time cost=4.3 Thoughput=11.73 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 199/88641, Loss=2.2095, lr=0.0000370 Time cost=4.1 Thoughput=12.22 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 249/88641, Loss=1.5611, lr=0.0000370 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 299/88641, Loss=2.4294, lr=0.0000370 Time cost=4.1 Thoughput=12.29 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 349/88641, Loss=1.8766, lr=0.0000370 Time cost=4.1 Thoughput=12.27 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 399/88641, Loss=1.9690, lr=0.0000370 Time cost=4.1 Thoughput=12.27 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 449/88641, Loss=1.2915, lr=0.0000369 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 499/88641, Loss=1.5856, lr=0.0000369 Time cost=4.1 Thoughput=12.09 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 549/88641, Loss=1.2671, lr=0.0000369 Time cost=4.2 Thoughput=12.04 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 599/88641, Loss=1.9091, lr=0.0000369 Time cost=4.2 Thoughput=12.03 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 649/88641, Loss=1.9366, lr=0.0000369 Time cost=4.2 Thoughput=12.02 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 699/88641, Loss=1.7360, lr=0.0000369 Time cost=4.1 Thoughput=12.15 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 749/88641, Loss=2.6123, lr=0.0000369 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 799/88641, Loss=1.8505, lr=0.0000369 Time cost=4.1 Thoughput=12.21 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 849/88641, Loss=1.4141, lr=0.0000369 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 899/88641, Loss=2.2162, lr=0.0000368 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 949/88641, Loss=1.7925, lr=0.0000368 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 999/88641, Loss=1.8551, lr=0.0000368 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 1049/88641, Loss=1.8083, lr=0.0000368 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 1099/88641, Loss=1.2587, lr=0.0000368 Time cost=4.1 Thoughput=12.29 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 1149/88641, Loss=1.7420, lr=0.0000368 Time cost=4.6 Thoughput=10.93 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 1199/88641, Loss=1.6131, lr=0.0000368 Time cost=4.1 Thoughput=12.28 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 1249/88641, Loss=1.5941, lr=0.0000368 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 1299/88641, Loss=2.1387, lr=0.0000368 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 1349/88641, Loss=1.8003, lr=0.0000368 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 1399/88641, Loss=2.3429, lr=0.0000367 Time cost=4.1 Thoughput=12.16 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 1449/88641, Loss=1.8402, lr=0.0000367 Time cost=4.1 Thoughput=12.18 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 1499/88641, Loss=1.2158, lr=0.0000367 Time cost=4.1 Thoughput=12.20 samples/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gluonnlp:Epoch: 1, Batch: 1549/88641, Loss=1.6124, lr=0.0000367 Time cost=4.1 Thoughput=12.12 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 1599/88641, Loss=1.4201, lr=0.0000367 Time cost=4.2 Thoughput=11.98 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 1649/88641, Loss=2.0306, lr=0.0000367 Time cost=4.1 Thoughput=12.20 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 1699/88641, Loss=1.5982, lr=0.0000367 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 1749/88641, Loss=1.9433, lr=0.0000367 Time cost=4.1 Thoughput=12.27 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 1799/88641, Loss=2.1873, lr=0.0000367 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 1849/88641, Loss=1.1639, lr=0.0000367 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 1899/88641, Loss=2.3087, lr=0.0000366 Time cost=4.1 Thoughput=12.06 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 1949/88641, Loss=1.7556, lr=0.0000366 Time cost=4.1 Thoughput=12.05 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 1999/88641, Loss=1.9335, lr=0.0000366 Time cost=4.1 Thoughput=12.19 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 2049/88641, Loss=1.6872, lr=0.0000366 Time cost=4.1 Thoughput=12.16 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 2099/88641, Loss=1.9270, lr=0.0000366 Time cost=4.1 Thoughput=12.20 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 2149/88641, Loss=1.9246, lr=0.0000366 Time cost=4.1 Thoughput=12.20 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 2199/88641, Loss=1.2803, lr=0.0000366 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 2249/88641, Loss=1.3336, lr=0.0000366 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 2299/88641, Loss=1.7068, lr=0.0000366 Time cost=4.2 Thoughput=11.95 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 2349/88641, Loss=1.4656, lr=0.0000365 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 2399/88641, Loss=1.7279, lr=0.0000365 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 2449/88641, Loss=1.6864, lr=0.0000365 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 2499/88641, Loss=1.2563, lr=0.0000365 Time cost=4.1 Thoughput=12.21 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 2549/88641, Loss=1.3301, lr=0.0000365 Time cost=4.1 Thoughput=12.17 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 2599/88641, Loss=1.8093, lr=0.0000365 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 2649/88641, Loss=1.5214, lr=0.0000365 Time cost=4.1 Thoughput=12.22 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 2699/88641, Loss=1.9196, lr=0.0000365 Time cost=4.1 Thoughput=12.21 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 2749/88641, Loss=1.4022, lr=0.0000365 Time cost=4.1 Thoughput=12.20 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 2799/88641, Loss=1.9341, lr=0.0000365 Time cost=4.1 Thoughput=12.18 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 2849/88641, Loss=1.6202, lr=0.0000364 Time cost=4.1 Thoughput=12.17 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 2899/88641, Loss=1.7877, lr=0.0000364 Time cost=4.1 Thoughput=12.18 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 2949/88641, Loss=1.3414, lr=0.0000364 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 2999/88641, Loss=1.4037, lr=0.0000364 Time cost=4.2 Thoughput=11.78 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 3049/88641, Loss=1.7088, lr=0.0000364 Time cost=4.2 Thoughput=11.97 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 3099/88641, Loss=1.4236, lr=0.0000364 Time cost=4.1 Thoughput=12.15 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 3149/88641, Loss=1.5120, lr=0.0000364 Time cost=4.1 Thoughput=12.27 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 3199/88641, Loss=1.9081, lr=0.0000364 Time cost=4.1 Thoughput=12.28 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 3249/88641, Loss=2.2879, lr=0.0000364 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 3299/88641, Loss=1.4045, lr=0.0000363 Time cost=4.2 Thoughput=11.89 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 3349/88641, Loss=2.5097, lr=0.0000363 Time cost=4.1 Thoughput=12.22 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 3399/88641, Loss=1.4850, lr=0.0000363 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 3449/88641, Loss=1.5482, lr=0.0000363 Time cost=4.2 Thoughput=12.04 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 3499/88641, Loss=1.5384, lr=0.0000363 Time cost=4.2 Thoughput=12.01 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 3549/88641, Loss=2.0908, lr=0.0000363 Time cost=4.1 Thoughput=12.13 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 3599/88641, Loss=1.0828, lr=0.0000363 Time cost=4.1 Thoughput=12.22 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 3649/88641, Loss=2.3530, lr=0.0000363 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 3699/88641, Loss=2.0624, lr=0.0000363 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 3749/88641, Loss=1.6604, lr=0.0000363 Time cost=4.1 Thoughput=12.22 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 3799/88641, Loss=1.3982, lr=0.0000362 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 3849/88641, Loss=1.3035, lr=0.0000362 Time cost=4.6 Thoughput=10.93 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 3899/88641, Loss=2.0470, lr=0.0000362 Time cost=4.1 Thoughput=12.19 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 3949/88641, Loss=1.9046, lr=0.0000362 Time cost=4.1 Thoughput=12.21 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 3999/88641, Loss=1.2530, lr=0.0000362 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 4049/88641, Loss=1.2569, lr=0.0000362 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 4099/88641, Loss=2.0118, lr=0.0000362 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 4149/88641, Loss=2.0702, lr=0.0000362 Time cost=4.1 Thoughput=12.15 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 4199/88641, Loss=1.6895, lr=0.0000362 Time cost=4.1 Thoughput=12.16 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 4249/88641, Loss=1.6011, lr=0.0000361 Time cost=4.1 Thoughput=12.21 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 4299/88641, Loss=2.2058, lr=0.0000361 Time cost=4.1 Thoughput=12.12 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 4349/88641, Loss=2.3143, lr=0.0000361 Time cost=4.1 Thoughput=12.15 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 4399/88641, Loss=1.7452, lr=0.0000361 Time cost=4.1 Thoughput=12.17 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 4449/88641, Loss=1.6204, lr=0.0000361 Time cost=4.1 Thoughput=12.19 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 4499/88641, Loss=1.5299, lr=0.0000361 Time cost=4.2 Thoughput=11.96 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 4549/88641, Loss=1.6516, lr=0.0000361 Time cost=4.1 Thoughput=12.17 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 4599/88641, Loss=1.9689, lr=0.0000361 Time cost=4.1 Thoughput=12.19 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 4649/88641, Loss=1.2629, lr=0.0000361 Time cost=4.1 Thoughput=12.19 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 4699/88641, Loss=2.0651, lr=0.0000361 Time cost=4.2 Thoughput=12.00 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 4749/88641, Loss=1.8634, lr=0.0000360 Time cost=4.1 Thoughput=12.16 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 4799/88641, Loss=2.1169, lr=0.0000360 Time cost=4.1 Thoughput=12.16 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 4849/88641, Loss=1.7184, lr=0.0000360 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 4899/88641, Loss=2.0788, lr=0.0000360 Time cost=4.1 Thoughput=12.22 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 4949/88641, Loss=1.5426, lr=0.0000360 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 4999/88641, Loss=1.8231, lr=0.0000360 Time cost=4.1 Thoughput=12.19 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 5049/88641, Loss=1.7264, lr=0.0000360 Time cost=4.1 Thoughput=12.18 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 5099/88641, Loss=1.3491, lr=0.0000360 Time cost=4.1 Thoughput=12.20 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 5149/88641, Loss=1.5144, lr=0.0000360 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 5199/88641, Loss=1.5861, lr=0.0000360 Time cost=4.1 Thoughput=12.20 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 5249/88641, Loss=1.4182, lr=0.0000359 Time cost=4.1 Thoughput=12.18 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 5299/88641, Loss=2.1901, lr=0.0000359 Time cost=4.1 Thoughput=12.20 samples/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gluonnlp:Epoch: 1, Batch: 5349/88641, Loss=1.6326, lr=0.0000359 Time cost=4.1 Thoughput=12.27 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 5399/88641, Loss=1.1341, lr=0.0000359 Time cost=4.1 Thoughput=12.31 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 5449/88641, Loss=1.9105, lr=0.0000359 Time cost=4.1 Thoughput=12.12 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 5499/88641, Loss=1.6433, lr=0.0000359 Time cost=4.2 Thoughput=11.99 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 5549/88641, Loss=1.7207, lr=0.0000359 Time cost=4.2 Thoughput=12.02 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 5599/88641, Loss=1.8039, lr=0.0000359 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 5649/88641, Loss=1.6858, lr=0.0000359 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 5699/88641, Loss=1.7810, lr=0.0000358 Time cost=4.1 Thoughput=12.21 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 5749/88641, Loss=1.8577, lr=0.0000358 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 5799/88641, Loss=1.6704, lr=0.0000358 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 5849/88641, Loss=2.3189, lr=0.0000358 Time cost=4.1 Thoughput=12.27 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 5899/88641, Loss=1.6403, lr=0.0000358 Time cost=4.1 Thoughput=12.27 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 5949/88641, Loss=2.3310, lr=0.0000358 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 5999/88641, Loss=1.9315, lr=0.0000358 Time cost=4.1 Thoughput=12.22 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 6049/88641, Loss=1.8177, lr=0.0000358 Time cost=4.1 Thoughput=12.21 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 6099/88641, Loss=1.7774, lr=0.0000358 Time cost=4.1 Thoughput=12.12 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 6149/88641, Loss=1.5886, lr=0.0000358 Time cost=4.2 Thoughput=11.94 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 6199/88641, Loss=1.7291, lr=0.0000357 Time cost=4.1 Thoughput=12.16 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 6249/88641, Loss=2.6771, lr=0.0000357 Time cost=4.1 Thoughput=12.19 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 6299/88641, Loss=1.8914, lr=0.0000357 Time cost=4.1 Thoughput=12.19 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 6349/88641, Loss=1.3786, lr=0.0000357 Time cost=4.2 Thoughput=11.82 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 6399/88641, Loss=1.8942, lr=0.0000357 Time cost=4.2 Thoughput=12.01 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 6449/88641, Loss=1.8721, lr=0.0000357 Time cost=4.1 Thoughput=12.22 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 6499/88641, Loss=1.2231, lr=0.0000357 Time cost=4.1 Thoughput=12.22 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 6549/88641, Loss=2.1136, lr=0.0000357 Time cost=4.1 Thoughput=12.22 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 6599/88641, Loss=1.7302, lr=0.0000357 Time cost=4.1 Thoughput=12.14 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 6649/88641, Loss=1.5148, lr=0.0000356 Time cost=4.1 Thoughput=12.21 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 6699/88641, Loss=1.8451, lr=0.0000356 Time cost=4.2 Thoughput=12.01 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 6749/88641, Loss=2.2445, lr=0.0000356 Time cost=4.1 Thoughput=12.22 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 6799/88641, Loss=1.3431, lr=0.0000356 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 6849/88641, Loss=1.6485, lr=0.0000356 Time cost=4.2 Thoughput=11.82 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 6899/88641, Loss=2.0140, lr=0.0000356 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 6949/88641, Loss=2.0447, lr=0.0000356 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 6999/88641, Loss=1.8715, lr=0.0000356 Time cost=4.1 Thoughput=12.21 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 7049/88641, Loss=1.6536, lr=0.0000356 Time cost=4.1 Thoughput=12.19 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 7099/88641, Loss=1.1206, lr=0.0000356 Time cost=4.1 Thoughput=12.19 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 7149/88641, Loss=1.9166, lr=0.0000355 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 7199/88641, Loss=1.7315, lr=0.0000355 Time cost=4.1 Thoughput=12.21 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 7249/88641, Loss=1.4173, lr=0.0000355 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 7299/88641, Loss=2.2444, lr=0.0000355 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 7349/88641, Loss=1.9687, lr=0.0000355 Time cost=4.2 Thoughput=12.03 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 7399/88641, Loss=1.3759, lr=0.0000355 Time cost=4.1 Thoughput=12.05 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 7449/88641, Loss=1.9958, lr=0.0000355 Time cost=4.1 Thoughput=12.20 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 7499/88641, Loss=1.5182, lr=0.0000355 Time cost=4.1 Thoughput=12.21 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 7549/88641, Loss=1.3515, lr=0.0000355 Time cost=4.1 Thoughput=12.19 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 7599/88641, Loss=1.1432, lr=0.0000354 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 7649/88641, Loss=1.6412, lr=0.0000354 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 7699/88641, Loss=1.8568, lr=0.0000354 Time cost=4.6 Thoughput=10.91 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 7749/88641, Loss=1.5898, lr=0.0000354 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 7799/88641, Loss=2.0765, lr=0.0000354 Time cost=4.1 Thoughput=12.22 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 7849/88641, Loss=1.7545, lr=0.0000354 Time cost=4.1 Thoughput=12.22 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 7899/88641, Loss=2.0669, lr=0.0000354 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 7949/88641, Loss=2.1156, lr=0.0000354 Time cost=4.1 Thoughput=12.21 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 7999/88641, Loss=1.3400, lr=0.0000354 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 8049/88641, Loss=1.7874, lr=0.0000354 Time cost=4.1 Thoughput=12.28 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 8099/88641, Loss=2.2361, lr=0.0000353 Time cost=4.1 Thoughput=12.28 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 8149/88641, Loss=1.2133, lr=0.0000353 Time cost=4.1 Thoughput=12.32 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 8199/88641, Loss=2.4009, lr=0.0000353 Time cost=4.1 Thoughput=12.28 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 8249/88641, Loss=2.0219, lr=0.0000353 Time cost=4.1 Thoughput=12.17 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 8299/88641, Loss=1.3842, lr=0.0000353 Time cost=4.2 Thoughput=11.97 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 8349/88641, Loss=0.9714, lr=0.0000353 Time cost=4.1 Thoughput=12.22 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 8399/88641, Loss=1.9468, lr=0.0000353 Time cost=4.1 Thoughput=12.22 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 8449/88641, Loss=1.9192, lr=0.0000353 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 8499/88641, Loss=2.4271, lr=0.0000353 Time cost=4.1 Thoughput=12.22 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 8549/88641, Loss=1.7234, lr=0.0000353 Time cost=4.1 Thoughput=12.21 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 8599/88641, Loss=1.3764, lr=0.0000352 Time cost=4.1 Thoughput=12.22 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 8649/88641, Loss=2.0209, lr=0.0000352 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 8699/88641, Loss=1.6726, lr=0.0000352 Time cost=4.1 Thoughput=12.22 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 8749/88641, Loss=2.0737, lr=0.0000352 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 8799/88641, Loss=2.1866, lr=0.0000352 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 8849/88641, Loss=1.5720, lr=0.0000352 Time cost=4.1 Thoughput=12.20 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 8899/88641, Loss=1.7667, lr=0.0000352 Time cost=4.2 Thoughput=11.83 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 8949/88641, Loss=1.6234, lr=0.0000352 Time cost=4.2 Thoughput=11.96 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 8999/88641, Loss=1.7594, lr=0.0000352 Time cost=4.2 Thoughput=11.94 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 9049/88641, Loss=1.8012, lr=0.0000351 Time cost=4.2 Thoughput=12.04 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 9099/88641, Loss=1.8293, lr=0.0000351 Time cost=4.1 Thoughput=12.16 samples/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gluonnlp:Epoch: 1, Batch: 9149/88641, Loss=1.8170, lr=0.0000351 Time cost=4.1 Thoughput=12.12 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 9199/88641, Loss=1.5920, lr=0.0000351 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 9249/88641, Loss=1.9912, lr=0.0000351 Time cost=4.2 Thoughput=12.02 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 9299/88641, Loss=1.8384, lr=0.0000351 Time cost=4.2 Thoughput=11.99 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 9349/88641, Loss=1.7075, lr=0.0000351 Time cost=4.1 Thoughput=12.15 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 9399/88641, Loss=2.0798, lr=0.0000351 Time cost=4.1 Thoughput=12.28 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 9449/88641, Loss=1.9728, lr=0.0000351 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 9499/88641, Loss=1.5132, lr=0.0000351 Time cost=4.1 Thoughput=12.15 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 9549/88641, Loss=2.0049, lr=0.0000350 Time cost=4.1 Thoughput=12.29 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 9599/88641, Loss=1.6420, lr=0.0000350 Time cost=4.1 Thoughput=12.28 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 9649/88641, Loss=1.8764, lr=0.0000350 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 9699/88641, Loss=1.9865, lr=0.0000350 Time cost=4.1 Thoughput=12.19 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 9749/88641, Loss=1.4834, lr=0.0000350 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 9799/88641, Loss=1.5762, lr=0.0000350 Time cost=4.1 Thoughput=12.20 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 9849/88641, Loss=1.6670, lr=0.0000350 Time cost=4.1 Thoughput=12.20 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 9899/88641, Loss=1.5187, lr=0.0000350 Time cost=4.2 Thoughput=11.95 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 9949/88641, Loss=1.8051, lr=0.0000350 Time cost=4.2 Thoughput=11.93 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 9999/88641, Loss=2.0187, lr=0.0000349 Time cost=4.2 Thoughput=12.05 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 10049/88641, Loss=1.7121, lr=0.0000349 Time cost=4.1 Thoughput=12.21 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 10099/88641, Loss=1.6924, lr=0.0000349 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 10149/88641, Loss=1.8445, lr=0.0000349 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 10199/88641, Loss=1.4996, lr=0.0000349 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 10249/88641, Loss=2.2676, lr=0.0000349 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 10299/88641, Loss=2.4280, lr=0.0000349 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 10349/88641, Loss=1.2752, lr=0.0000349 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 10399/88641, Loss=2.3059, lr=0.0000349 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 10449/88641, Loss=1.9621, lr=0.0000349 Time cost=4.6 Thoughput=10.98 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 10499/88641, Loss=1.6072, lr=0.0000348 Time cost=4.1 Thoughput=12.16 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 10549/88641, Loss=2.2979, lr=0.0000348 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 10599/88641, Loss=2.0331, lr=0.0000348 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 10649/88641, Loss=1.2235, lr=0.0000348 Time cost=4.1 Thoughput=12.29 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 10699/88641, Loss=2.2237, lr=0.0000348 Time cost=4.1 Thoughput=12.28 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 10749/88641, Loss=1.8234, lr=0.0000348 Time cost=4.1 Thoughput=12.29 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 10799/88641, Loss=1.4756, lr=0.0000348 Time cost=4.1 Thoughput=12.28 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 10849/88641, Loss=1.4264, lr=0.0000348 Time cost=4.1 Thoughput=12.27 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 10899/88641, Loss=1.2814, lr=0.0000348 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 10949/88641, Loss=1.9334, lr=0.0000347 Time cost=4.1 Thoughput=12.22 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 10999/88641, Loss=1.7702, lr=0.0000347 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 11049/88641, Loss=1.6638, lr=0.0000347 Time cost=4.2 Thoughput=11.94 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 11099/88641, Loss=1.5599, lr=0.0000347 Time cost=4.1 Thoughput=12.18 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 11149/88641, Loss=1.6642, lr=0.0000347 Time cost=4.2 Thoughput=11.87 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 11199/88641, Loss=2.1012, lr=0.0000347 Time cost=4.2 Thoughput=12.04 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 11249/88641, Loss=1.8078, lr=0.0000347 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 11299/88641, Loss=1.2830, lr=0.0000347 Time cost=4.1 Thoughput=12.20 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 11349/88641, Loss=1.8305, lr=0.0000347 Time cost=4.1 Thoughput=12.16 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 11399/88641, Loss=1.2372, lr=0.0000347 Time cost=4.1 Thoughput=12.16 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 11449/88641, Loss=1.5520, lr=0.0000346 Time cost=4.1 Thoughput=12.16 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 11499/88641, Loss=2.3506, lr=0.0000346 Time cost=4.1 Thoughput=12.19 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 11549/88641, Loss=1.7220, lr=0.0000346 Time cost=4.5 Thoughput=11.07 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 11599/88641, Loss=2.2300, lr=0.0000346 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 11649/88641, Loss=2.0020, lr=0.0000346 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 11699/88641, Loss=1.7013, lr=0.0000346 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 11749/88641, Loss=1.6757, lr=0.0000346 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 11799/88641, Loss=1.8385, lr=0.0000346 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 11849/88641, Loss=2.2185, lr=0.0000346 Time cost=4.1 Thoughput=12.27 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 11899/88641, Loss=1.4606, lr=0.0000346 Time cost=4.1 Thoughput=12.28 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 11949/88641, Loss=2.3566, lr=0.0000345 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 11999/88641, Loss=1.7023, lr=0.0000345 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 12049/88641, Loss=1.2643, lr=0.0000345 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 12099/88641, Loss=1.8999, lr=0.0000345 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 12149/88641, Loss=1.2569, lr=0.0000345 Time cost=4.1 Thoughput=12.28 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 12199/88641, Loss=1.6150, lr=0.0000345 Time cost=4.1 Thoughput=12.27 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 12249/88641, Loss=1.7290, lr=0.0000345 Time cost=4.1 Thoughput=12.28 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 12299/88641, Loss=1.9206, lr=0.0000345 Time cost=4.1 Thoughput=12.29 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 12349/88641, Loss=1.0474, lr=0.0000345 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 12399/88641, Loss=1.9371, lr=0.0000344 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 12449/88641, Loss=2.0824, lr=0.0000344 Time cost=4.1 Thoughput=12.20 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 12499/88641, Loss=1.3156, lr=0.0000344 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 12549/88641, Loss=1.8037, lr=0.0000344 Time cost=4.1 Thoughput=12.10 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 12599/88641, Loss=1.4573, lr=0.0000344 Time cost=4.1 Thoughput=12.05 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 12649/88641, Loss=1.7665, lr=0.0000344 Time cost=4.1 Thoughput=12.08 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 12699/88641, Loss=1.8030, lr=0.0000344 Time cost=4.1 Thoughput=12.05 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 12749/88641, Loss=1.6338, lr=0.0000344 Time cost=4.1 Thoughput=12.17 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 12799/88641, Loss=1.0389, lr=0.0000344 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 12849/88641, Loss=2.1301, lr=0.0000344 Time cost=4.1 Thoughput=12.15 samples/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gluonnlp:Epoch: 1, Batch: 12899/88641, Loss=1.7406, lr=0.0000343 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 12949/88641, Loss=1.4065, lr=0.0000343 Time cost=4.1 Thoughput=12.21 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 12999/88641, Loss=1.9523, lr=0.0000343 Time cost=4.1 Thoughput=12.21 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 13049/88641, Loss=2.1559, lr=0.0000343 Time cost=4.1 Thoughput=12.21 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 13099/88641, Loss=1.4147, lr=0.0000343 Time cost=4.1 Thoughput=12.08 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 13149/88641, Loss=2.2314, lr=0.0000343 Time cost=4.2 Thoughput=12.04 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 13199/88641, Loss=1.5547, lr=0.0000343 Time cost=4.1 Thoughput=12.16 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 13249/88641, Loss=1.4226, lr=0.0000343 Time cost=4.2 Thoughput=11.81 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 13299/88641, Loss=1.8570, lr=0.0000343 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 13349/88641, Loss=1.7294, lr=0.0000342 Time cost=4.1 Thoughput=12.27 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 13399/88641, Loss=2.3588, lr=0.0000342 Time cost=4.1 Thoughput=12.31 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 13449/88641, Loss=1.2302, lr=0.0000342 Time cost=4.1 Thoughput=12.29 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 13499/88641, Loss=1.2039, lr=0.0000342 Time cost=4.1 Thoughput=12.28 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 13549/88641, Loss=1.4805, lr=0.0000342 Time cost=4.1 Thoughput=12.11 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 13599/88641, Loss=1.9483, lr=0.0000342 Time cost=4.2 Thoughput=12.00 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 13649/88641, Loss=1.4568, lr=0.0000342 Time cost=4.1 Thoughput=12.15 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 13699/88641, Loss=2.7211, lr=0.0000342 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 13749/88641, Loss=0.9243, lr=0.0000342 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 13799/88641, Loss=2.0812, lr=0.0000342 Time cost=4.1 Thoughput=12.18 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 13849/88641, Loss=1.7672, lr=0.0000341 Time cost=4.1 Thoughput=12.22 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 13899/88641, Loss=2.4962, lr=0.0000341 Time cost=4.1 Thoughput=12.27 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 13949/88641, Loss=1.4295, lr=0.0000341 Time cost=4.1 Thoughput=12.27 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 13999/88641, Loss=1.7968, lr=0.0000341 Time cost=4.1 Thoughput=12.14 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 14049/88641, Loss=1.5680, lr=0.0000341 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 14099/88641, Loss=1.5717, lr=0.0000341 Time cost=4.2 Thoughput=12.04 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 14149/88641, Loss=1.8179, lr=0.0000341 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 14199/88641, Loss=1.1818, lr=0.0000341 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 14249/88641, Loss=2.5063, lr=0.0000341 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 14299/88641, Loss=1.9075, lr=0.0000340 Time cost=4.6 Thoughput=10.88 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 14349/88641, Loss=1.6054, lr=0.0000340 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 14399/88641, Loss=1.6939, lr=0.0000340 Time cost=4.1 Thoughput=12.21 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 14449/88641, Loss=2.0323, lr=0.0000340 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 14499/88641, Loss=1.9335, lr=0.0000340 Time cost=4.1 Thoughput=12.21 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 14549/88641, Loss=1.4773, lr=0.0000340 Time cost=4.2 Thoughput=11.94 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 14599/88641, Loss=1.7362, lr=0.0000340 Time cost=4.2 Thoughput=12.00 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 14649/88641, Loss=1.3983, lr=0.0000340 Time cost=4.5 Thoughput=11.14 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 14699/88641, Loss=1.5890, lr=0.0000340 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 14749/88641, Loss=1.6029, lr=0.0000340 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 14799/88641, Loss=2.1750, lr=0.0000339 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 14849/88641, Loss=1.7926, lr=0.0000339 Time cost=4.1 Thoughput=12.19 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 14899/88641, Loss=1.5201, lr=0.0000339 Time cost=4.1 Thoughput=12.21 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 14949/88641, Loss=1.5094, lr=0.0000339 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 14999/88641, Loss=1.7379, lr=0.0000339 Time cost=4.1 Thoughput=12.13 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 15049/88641, Loss=1.5903, lr=0.0000339 Time cost=4.1 Thoughput=12.12 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 15099/88641, Loss=1.1685, lr=0.0000339 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 15149/88641, Loss=1.5710, lr=0.0000339 Time cost=4.1 Thoughput=12.28 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 15199/88641, Loss=1.6741, lr=0.0000339 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 15249/88641, Loss=1.6115, lr=0.0000339 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 15299/88641, Loss=1.6513, lr=0.0000338 Time cost=4.1 Thoughput=12.21 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 15349/88641, Loss=1.9783, lr=0.0000338 Time cost=4.1 Thoughput=12.18 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 15399/88641, Loss=1.3586, lr=0.0000338 Time cost=4.1 Thoughput=12.22 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 15449/88641, Loss=1.6814, lr=0.0000338 Time cost=4.2 Thoughput=11.96 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 15499/88641, Loss=1.8778, lr=0.0000338 Time cost=4.1 Thoughput=12.28 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 15549/88641, Loss=1.9477, lr=0.0000338 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 15599/88641, Loss=1.7456, lr=0.0000338 Time cost=4.1 Thoughput=12.28 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 15649/88641, Loss=1.4638, lr=0.0000338 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 15699/88641, Loss=1.6570, lr=0.0000338 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 15749/88641, Loss=1.9873, lr=0.0000337 Time cost=4.1 Thoughput=12.28 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 15799/88641, Loss=1.2450, lr=0.0000337 Time cost=4.1 Thoughput=12.22 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 15849/88641, Loss=2.0441, lr=0.0000337 Time cost=4.1 Thoughput=12.21 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 15899/88641, Loss=1.9277, lr=0.0000337 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 15949/88641, Loss=1.4019, lr=0.0000337 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 15999/88641, Loss=2.1290, lr=0.0000337 Time cost=4.1 Thoughput=12.22 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 16049/88641, Loss=1.7433, lr=0.0000337 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 16099/88641, Loss=1.8927, lr=0.0000337 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 16149/88641, Loss=1.6718, lr=0.0000337 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 16199/88641, Loss=1.4730, lr=0.0000337 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 16249/88641, Loss=1.6708, lr=0.0000336 Time cost=4.1 Thoughput=12.27 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 16299/88641, Loss=1.4017, lr=0.0000336 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 16349/88641, Loss=2.4471, lr=0.0000336 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 16399/88641, Loss=1.1068, lr=0.0000336 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 16449/88641, Loss=1.4866, lr=0.0000336 Time cost=4.3 Thoughput=11.53 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 16499/88641, Loss=2.0677, lr=0.0000336 Time cost=4.2 Thoughput=11.95 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 16549/88641, Loss=1.5883, lr=0.0000336 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 16599/88641, Loss=2.1746, lr=0.0000336 Time cost=4.1 Thoughput=12.25 samples/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gluonnlp:Epoch: 1, Batch: 16649/88641, Loss=1.8064, lr=0.0000336 Time cost=4.1 Thoughput=12.10 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 16699/88641, Loss=1.8855, lr=0.0000335 Time cost=4.2 Thoughput=11.86 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 16749/88641, Loss=1.4715, lr=0.0000335 Time cost=4.2 Thoughput=11.87 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 16799/88641, Loss=1.6430, lr=0.0000335 Time cost=4.2 Thoughput=11.87 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 16849/88641, Loss=2.2912, lr=0.0000335 Time cost=4.1 Thoughput=12.15 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 16899/88641, Loss=1.7829, lr=0.0000335 Time cost=4.1 Thoughput=12.27 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 16949/88641, Loss=1.6851, lr=0.0000335 Time cost=4.1 Thoughput=12.28 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 16999/88641, Loss=1.9656, lr=0.0000335 Time cost=4.6 Thoughput=10.97 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 17049/88641, Loss=2.4471, lr=0.0000335 Time cost=4.1 Thoughput=12.30 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 17099/88641, Loss=1.7761, lr=0.0000335 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 17149/88641, Loss=2.2000, lr=0.0000335 Time cost=4.1 Thoughput=12.11 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 17199/88641, Loss=1.6180, lr=0.0000334 Time cost=4.1 Thoughput=12.22 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 17249/88641, Loss=1.7894, lr=0.0000334 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 17299/88641, Loss=1.3339, lr=0.0000334 Time cost=4.1 Thoughput=12.27 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 17349/88641, Loss=1.7347, lr=0.0000334 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 17399/88641, Loss=1.4717, lr=0.0000334 Time cost=4.1 Thoughput=12.19 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 17449/88641, Loss=1.3223, lr=0.0000334 Time cost=4.1 Thoughput=12.17 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 17499/88641, Loss=2.0911, lr=0.0000334 Time cost=4.2 Thoughput=12.04 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 17549/88641, Loss=1.6160, lr=0.0000334 Time cost=4.1 Thoughput=12.20 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 17599/88641, Loss=1.6929, lr=0.0000334 Time cost=4.1 Thoughput=12.17 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 17649/88641, Loss=1.4756, lr=0.0000333 Time cost=4.2 Thoughput=11.82 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 17699/88641, Loss=1.6017, lr=0.0000333 Time cost=4.1 Thoughput=12.14 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 17749/88641, Loss=1.6197, lr=0.0000333 Time cost=4.1 Thoughput=12.28 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 17799/88641, Loss=2.6256, lr=0.0000333 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 17849/88641, Loss=1.9958, lr=0.0000333 Time cost=4.1 Thoughput=12.21 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 17899/88641, Loss=1.4607, lr=0.0000333 Time cost=4.1 Thoughput=12.21 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 17949/88641, Loss=1.8315, lr=0.0000333 Time cost=4.1 Thoughput=12.22 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 17999/88641, Loss=2.3806, lr=0.0000333 Time cost=4.1 Thoughput=12.17 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 18049/88641, Loss=1.8791, lr=0.0000333 Time cost=4.1 Thoughput=12.20 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 18099/88641, Loss=1.5163, lr=0.0000333 Time cost=4.1 Thoughput=12.22 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 18149/88641, Loss=1.6236, lr=0.0000332 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 18199/88641, Loss=1.5299, lr=0.0000332 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 18249/88641, Loss=1.4383, lr=0.0000332 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 18299/88641, Loss=1.5471, lr=0.0000332 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 18349/88641, Loss=2.2062, lr=0.0000332 Time cost=4.1 Thoughput=12.28 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 18399/88641, Loss=1.5147, lr=0.0000332 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 18449/88641, Loss=1.6583, lr=0.0000332 Time cost=4.1 Thoughput=12.28 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 18499/88641, Loss=1.7887, lr=0.0000332 Time cost=4.1 Thoughput=12.27 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 18549/88641, Loss=1.7808, lr=0.0000332 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 18599/88641, Loss=2.0144, lr=0.0000332 Time cost=4.1 Thoughput=12.30 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 18649/88641, Loss=1.4633, lr=0.0000331 Time cost=4.1 Thoughput=12.31 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 18699/88641, Loss=1.5191, lr=0.0000331 Time cost=4.1 Thoughput=12.28 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 18749/88641, Loss=1.8288, lr=0.0000331 Time cost=4.1 Thoughput=12.30 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 18799/88641, Loss=1.3281, lr=0.0000331 Time cost=4.1 Thoughput=12.27 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 18849/88641, Loss=1.3494, lr=0.0000331 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 18899/88641, Loss=1.8004, lr=0.0000331 Time cost=4.1 Thoughput=12.21 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 18949/88641, Loss=1.7655, lr=0.0000331 Time cost=4.1 Thoughput=12.21 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 18999/88641, Loss=2.0207, lr=0.0000331 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 19049/88641, Loss=2.0513, lr=0.0000331 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 19099/88641, Loss=1.3187, lr=0.0000330 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 19149/88641, Loss=1.7969, lr=0.0000330 Time cost=4.1 Thoughput=12.17 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 19199/88641, Loss=1.9036, lr=0.0000330 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 19249/88641, Loss=1.7840, lr=0.0000330 Time cost=4.1 Thoughput=12.21 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 19299/88641, Loss=1.6148, lr=0.0000330 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 19349/88641, Loss=1.6492, lr=0.0000330 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 19399/88641, Loss=1.9174, lr=0.0000330 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 19449/88641, Loss=1.5854, lr=0.0000330 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 19499/88641, Loss=1.9796, lr=0.0000330 Time cost=4.1 Thoughput=12.30 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 19549/88641, Loss=1.0837, lr=0.0000330 Time cost=4.1 Thoughput=12.21 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 19599/88641, Loss=2.1476, lr=0.0000329 Time cost=4.2 Thoughput=11.80 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 19649/88641, Loss=2.0981, lr=0.0000329 Time cost=4.2 Thoughput=11.92 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 19699/88641, Loss=1.1921, lr=0.0000329 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 19749/88641, Loss=1.8104, lr=0.0000329 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 19799/88641, Loss=1.6721, lr=0.0000329 Time cost=4.1 Thoughput=12.21 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 19849/88641, Loss=1.2661, lr=0.0000329 Time cost=4.1 Thoughput=12.08 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 19899/88641, Loss=2.3108, lr=0.0000329 Time cost=4.1 Thoughput=12.22 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 19949/88641, Loss=2.1226, lr=0.0000329 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 19999/88641, Loss=1.1934, lr=0.0000329 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 20049/88641, Loss=1.5447, lr=0.0000328 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 20099/88641, Loss=1.2764, lr=0.0000328 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 20149/88641, Loss=2.1880, lr=0.0000328 Time cost=4.1 Thoughput=12.27 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 20199/88641, Loss=1.7900, lr=0.0000328 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 20249/88641, Loss=1.6949, lr=0.0000328 Time cost=4.2 Thoughput=12.03 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 20299/88641, Loss=1.4521, lr=0.0000328 Time cost=4.1 Thoughput=12.27 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 20349/88641, Loss=1.4227, lr=0.0000328 Time cost=4.1 Thoughput=12.26 samples/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gluonnlp:Epoch: 1, Batch: 20399/88641, Loss=1.7502, lr=0.0000328 Time cost=4.1 Thoughput=12.27 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 20449/88641, Loss=1.5152, lr=0.0000328 Time cost=4.1 Thoughput=12.29 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 20499/88641, Loss=1.5260, lr=0.0000328 Time cost=4.1 Thoughput=12.27 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 20549/88641, Loss=2.3974, lr=0.0000327 Time cost=4.1 Thoughput=12.28 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 20599/88641, Loss=2.2021, lr=0.0000327 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 20649/88641, Loss=2.8181, lr=0.0000327 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 20699/88641, Loss=1.8726, lr=0.0000327 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 20749/88641, Loss=1.7084, lr=0.0000327 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 20799/88641, Loss=1.4892, lr=0.0000327 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 20849/88641, Loss=1.6285, lr=0.0000327 Time cost=4.6 Thoughput=10.92 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 20899/88641, Loss=1.8125, lr=0.0000327 Time cost=4.1 Thoughput=12.30 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 20949/88641, Loss=1.9378, lr=0.0000327 Time cost=4.1 Thoughput=12.28 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 20999/88641, Loss=1.5925, lr=0.0000326 Time cost=4.1 Thoughput=12.28 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 21049/88641, Loss=1.6850, lr=0.0000326 Time cost=4.2 Thoughput=11.93 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 21099/88641, Loss=1.7198, lr=0.0000326 Time cost=4.2 Thoughput=11.83 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 21149/88641, Loss=1.8143, lr=0.0000326 Time cost=4.1 Thoughput=12.20 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 21199/88641, Loss=1.5589, lr=0.0000326 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 21249/88641, Loss=2.3638, lr=0.0000326 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 21299/88641, Loss=2.0868, lr=0.0000326 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 21349/88641, Loss=1.4054, lr=0.0000326 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 21399/88641, Loss=1.5500, lr=0.0000326 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 21449/88641, Loss=1.6985, lr=0.0000326 Time cost=4.1 Thoughput=12.17 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 21499/88641, Loss=1.3758, lr=0.0000325 Time cost=4.1 Thoughput=12.06 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 21549/88641, Loss=1.2821, lr=0.0000325 Time cost=4.1 Thoughput=12.09 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 21599/88641, Loss=1.0680, lr=0.0000325 Time cost=4.1 Thoughput=12.22 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 21649/88641, Loss=1.9508, lr=0.0000325 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 21699/88641, Loss=1.7822, lr=0.0000325 Time cost=4.1 Thoughput=12.29 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 21749/88641, Loss=1.7506, lr=0.0000325 Time cost=4.1 Thoughput=12.28 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 21799/88641, Loss=2.0850, lr=0.0000325 Time cost=4.1 Thoughput=12.08 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 21849/88641, Loss=1.2370, lr=0.0000325 Time cost=4.1 Thoughput=12.13 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 21899/88641, Loss=1.7486, lr=0.0000325 Time cost=4.1 Thoughput=12.18 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 21949/88641, Loss=1.5150, lr=0.0000325 Time cost=4.2 Thoughput=11.98 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 21999/88641, Loss=2.0999, lr=0.0000324 Time cost=4.2 Thoughput=11.79 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 22049/88641, Loss=1.6137, lr=0.0000324 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 22099/88641, Loss=1.6857, lr=0.0000324 Time cost=4.1 Thoughput=12.27 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 22149/88641, Loss=2.0381, lr=0.0000324 Time cost=4.1 Thoughput=12.27 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 22199/88641, Loss=2.2073, lr=0.0000324 Time cost=4.1 Thoughput=12.20 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 22249/88641, Loss=2.0627, lr=0.0000324 Time cost=4.2 Thoughput=11.97 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 22299/88641, Loss=1.6135, lr=0.0000324 Time cost=4.2 Thoughput=11.99 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 22349/88641, Loss=1.9661, lr=0.0000324 Time cost=4.1 Thoughput=12.20 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 22399/88641, Loss=1.6732, lr=0.0000324 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 22449/88641, Loss=1.8241, lr=0.0000323 Time cost=4.1 Thoughput=12.07 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 22499/88641, Loss=1.4195, lr=0.0000323 Time cost=4.1 Thoughput=12.20 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 22549/88641, Loss=2.0035, lr=0.0000323 Time cost=4.1 Thoughput=12.22 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 22599/88641, Loss=1.9806, lr=0.0000323 Time cost=4.1 Thoughput=12.22 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 22649/88641, Loss=1.8441, lr=0.0000323 Time cost=4.1 Thoughput=12.19 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 22699/88641, Loss=1.5092, lr=0.0000323 Time cost=4.2 Thoughput=11.83 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 22749/88641, Loss=1.8058, lr=0.0000323 Time cost=4.2 Thoughput=12.01 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 22799/88641, Loss=1.7761, lr=0.0000323 Time cost=4.1 Thoughput=12.27 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 22849/88641, Loss=2.2732, lr=0.0000323 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 22899/88641, Loss=1.9444, lr=0.0000323 Time cost=4.1 Thoughput=12.22 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 22949/88641, Loss=1.3054, lr=0.0000322 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 22999/88641, Loss=1.8013, lr=0.0000322 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 23049/88641, Loss=1.6461, lr=0.0000322 Time cost=4.1 Thoughput=12.27 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 23099/88641, Loss=2.2077, lr=0.0000322 Time cost=4.1 Thoughput=12.14 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 23149/88641, Loss=1.1505, lr=0.0000322 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 23199/88641, Loss=1.8273, lr=0.0000322 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 23249/88641, Loss=1.7985, lr=0.0000322 Time cost=4.1 Thoughput=12.21 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 23299/88641, Loss=1.7466, lr=0.0000322 Time cost=4.1 Thoughput=12.16 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 23349/88641, Loss=1.4586, lr=0.0000322 Time cost=4.1 Thoughput=12.22 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 23399/88641, Loss=1.9112, lr=0.0000321 Time cost=4.1 Thoughput=12.27 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 23449/88641, Loss=1.7265, lr=0.0000321 Time cost=4.1 Thoughput=12.27 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 23499/88641, Loss=2.0549, lr=0.0000321 Time cost=4.1 Thoughput=12.07 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 23549/88641, Loss=1.7241, lr=0.0000321 Time cost=4.7 Thoughput=10.66 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 23599/88641, Loss=1.0447, lr=0.0000321 Time cost=4.1 Thoughput=12.29 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 23649/88641, Loss=2.1012, lr=0.0000321 Time cost=4.1 Thoughput=12.28 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 23699/88641, Loss=1.5580, lr=0.0000321 Time cost=4.1 Thoughput=12.28 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 23749/88641, Loss=1.5804, lr=0.0000321 Time cost=4.1 Thoughput=12.28 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 23799/88641, Loss=2.1873, lr=0.0000321 Time cost=4.1 Thoughput=12.29 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 23849/88641, Loss=2.0486, lr=0.0000321 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 23899/88641, Loss=1.4043, lr=0.0000320 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 23949/88641, Loss=2.0061, lr=0.0000320 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 23999/88641, Loss=1.1770, lr=0.0000320 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 24049/88641, Loss=1.8401, lr=0.0000320 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 24099/88641, Loss=1.5050, lr=0.0000320 Time cost=4.1 Thoughput=12.27 samples/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gluonnlp:Epoch: 1, Batch: 24149/88641, Loss=2.2064, lr=0.0000320 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 24199/88641, Loss=1.7776, lr=0.0000320 Time cost=4.2 Thoughput=11.99 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 24249/88641, Loss=1.8201, lr=0.0000320 Time cost=4.1 Thoughput=12.05 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 24299/88641, Loss=1.3753, lr=0.0000320 Time cost=4.2 Thoughput=12.04 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 24349/88641, Loss=1.8014, lr=0.0000319 Time cost=4.1 Thoughput=12.19 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 24399/88641, Loss=1.7468, lr=0.0000319 Time cost=4.1 Thoughput=12.19 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 24449/88641, Loss=1.7242, lr=0.0000319 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 24499/88641, Loss=1.5061, lr=0.0000319 Time cost=4.1 Thoughput=12.28 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 24549/88641, Loss=1.5261, lr=0.0000319 Time cost=4.1 Thoughput=12.28 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 24599/88641, Loss=1.2509, lr=0.0000319 Time cost=4.1 Thoughput=12.27 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 24649/88641, Loss=1.8922, lr=0.0000319 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 24699/88641, Loss=2.2581, lr=0.0000319 Time cost=4.1 Thoughput=12.12 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 24749/88641, Loss=1.5872, lr=0.0000319 Time cost=4.1 Thoughput=12.09 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 24799/88641, Loss=1.8000, lr=0.0000319 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 24849/88641, Loss=1.4739, lr=0.0000318 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 24899/88641, Loss=1.9458, lr=0.0000318 Time cost=4.1 Thoughput=12.22 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 24949/88641, Loss=1.7252, lr=0.0000318 Time cost=4.1 Thoughput=12.21 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 24999/88641, Loss=1.4241, lr=0.0000318 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 25049/88641, Loss=0.9179, lr=0.0000318 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 25099/88641, Loss=2.2470, lr=0.0000318 Time cost=4.1 Thoughput=12.29 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 25149/88641, Loss=1.4975, lr=0.0000318 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 25199/88641, Loss=1.8875, lr=0.0000318 Time cost=4.1 Thoughput=12.12 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 25249/88641, Loss=1.5159, lr=0.0000318 Time cost=4.1 Thoughput=12.09 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 25299/88641, Loss=2.2894, lr=0.0000318 Time cost=4.1 Thoughput=12.20 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 25349/88641, Loss=1.4374, lr=0.0000317 Time cost=4.1 Thoughput=12.07 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 25399/88641, Loss=2.3738, lr=0.0000317 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 25449/88641, Loss=1.3851, lr=0.0000317 Time cost=4.1 Thoughput=12.27 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 25499/88641, Loss=1.9868, lr=0.0000317 Time cost=4.1 Thoughput=12.27 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 25549/88641, Loss=1.7400, lr=0.0000317 Time cost=4.1 Thoughput=12.20 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 25599/88641, Loss=1.8384, lr=0.0000317 Time cost=4.2 Thoughput=11.96 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 25649/88641, Loss=1.2602, lr=0.0000317 Time cost=4.2 Thoughput=12.01 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 25699/88641, Loss=1.4869, lr=0.0000317 Time cost=4.1 Thoughput=12.08 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 25749/88641, Loss=1.6620, lr=0.0000317 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 25799/88641, Loss=1.3243, lr=0.0000316 Time cost=4.1 Thoughput=12.27 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 25849/88641, Loss=2.1793, lr=0.0000316 Time cost=4.1 Thoughput=12.29 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 25899/88641, Loss=2.0532, lr=0.0000316 Time cost=4.1 Thoughput=12.29 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 25949/88641, Loss=1.7218, lr=0.0000316 Time cost=4.1 Thoughput=12.21 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 25999/88641, Loss=1.6351, lr=0.0000316 Time cost=4.2 Thoughput=12.03 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 26049/88641, Loss=1.5125, lr=0.0000316 Time cost=4.2 Thoughput=12.02 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 26099/88641, Loss=1.5856, lr=0.0000316 Time cost=4.2 Thoughput=12.05 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 26149/88641, Loss=1.3751, lr=0.0000316 Time cost=4.2 Thoughput=12.03 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 26199/88641, Loss=1.6542, lr=0.0000316 Time cost=4.1 Thoughput=12.10 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 26249/88641, Loss=2.1320, lr=0.0000316 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 26299/88641, Loss=1.2299, lr=0.0000315 Time cost=4.1 Thoughput=12.07 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 26349/88641, Loss=1.7797, lr=0.0000315 Time cost=4.1 Thoughput=12.27 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 26399/88641, Loss=1.1635, lr=0.0000315 Time cost=4.2 Thoughput=11.98 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 26449/88641, Loss=2.0095, lr=0.0000315 Time cost=4.1 Thoughput=12.21 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 26499/88641, Loss=1.4276, lr=0.0000315 Time cost=4.2 Thoughput=12.00 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 26549/88641, Loss=1.5427, lr=0.0000315 Time cost=4.2 Thoughput=12.01 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 26599/88641, Loss=1.5778, lr=0.0000315 Time cost=4.2 Thoughput=12.00 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 26649/88641, Loss=1.9380, lr=0.0000315 Time cost=4.1 Thoughput=12.18 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 26699/88641, Loss=1.2278, lr=0.0000315 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 26749/88641, Loss=1.8496, lr=0.0000314 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 26799/88641, Loss=2.0697, lr=0.0000314 Time cost=4.1 Thoughput=12.22 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 26849/88641, Loss=1.6250, lr=0.0000314 Time cost=4.1 Thoughput=12.19 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 26899/88641, Loss=1.7703, lr=0.0000314 Time cost=4.1 Thoughput=12.27 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 26949/88641, Loss=1.8093, lr=0.0000314 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 26999/88641, Loss=2.1515, lr=0.0000314 Time cost=4.2 Thoughput=11.97 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 27049/88641, Loss=1.2679, lr=0.0000314 Time cost=4.4 Thoughput=11.45 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 27099/88641, Loss=1.4090, lr=0.0000314 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 27149/88641, Loss=0.9072, lr=0.0000314 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 27199/88641, Loss=2.1353, lr=0.0000314 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 27249/88641, Loss=1.9776, lr=0.0000313 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 27299/88641, Loss=1.4216, lr=0.0000313 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 27349/88641, Loss=1.4044, lr=0.0000313 Time cost=4.2 Thoughput=12.02 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 27399/88641, Loss=2.0619, lr=0.0000313 Time cost=4.6 Thoughput=10.78 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 27449/88641, Loss=1.8066, lr=0.0000313 Time cost=4.1 Thoughput=12.15 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 27499/88641, Loss=1.9969, lr=0.0000313 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 27549/88641, Loss=1.7620, lr=0.0000313 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 27599/88641, Loss=2.1311, lr=0.0000313 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 27649/88641, Loss=1.6700, lr=0.0000313 Time cost=4.1 Thoughput=12.21 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 27699/88641, Loss=1.5809, lr=0.0000313 Time cost=4.1 Thoughput=12.27 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 27749/88641, Loss=1.8156, lr=0.0000312 Time cost=4.1 Thoughput=12.29 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 27799/88641, Loss=1.6026, lr=0.0000312 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 27849/88641, Loss=1.5227, lr=0.0000312 Time cost=4.1 Thoughput=12.28 samples/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gluonnlp:Epoch: 1, Batch: 27899/88641, Loss=1.9201, lr=0.0000312 Time cost=4.1 Thoughput=12.11 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 27949/88641, Loss=1.3815, lr=0.0000312 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 27999/88641, Loss=2.3085, lr=0.0000312 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 28049/88641, Loss=1.3472, lr=0.0000312 Time cost=4.1 Thoughput=12.27 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 28099/88641, Loss=1.5617, lr=0.0000312 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 28149/88641, Loss=1.0740, lr=0.0000312 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 28199/88641, Loss=1.7873, lr=0.0000311 Time cost=4.1 Thoughput=12.21 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 28249/88641, Loss=1.6035, lr=0.0000311 Time cost=4.1 Thoughput=12.20 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 28299/88641, Loss=1.6008, lr=0.0000311 Time cost=4.1 Thoughput=12.28 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 28349/88641, Loss=1.4564, lr=0.0000311 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 28399/88641, Loss=1.2681, lr=0.0000311 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 28449/88641, Loss=1.7912, lr=0.0000311 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 28499/88641, Loss=1.4479, lr=0.0000311 Time cost=4.1 Thoughput=12.27 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 28549/88641, Loss=1.3576, lr=0.0000311 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 28599/88641, Loss=1.2204, lr=0.0000311 Time cost=4.2 Thoughput=12.00 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 28649/88641, Loss=2.0707, lr=0.0000311 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 28699/88641, Loss=1.9006, lr=0.0000310 Time cost=4.1 Thoughput=12.21 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 28749/88641, Loss=1.9499, lr=0.0000310 Time cost=4.1 Thoughput=12.21 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 28799/88641, Loss=2.0088, lr=0.0000310 Time cost=4.1 Thoughput=12.15 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 28849/88641, Loss=1.6559, lr=0.0000310 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 28899/88641, Loss=1.9364, lr=0.0000310 Time cost=4.1 Thoughput=12.27 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 28949/88641, Loss=1.4728, lr=0.0000310 Time cost=4.2 Thoughput=11.91 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 28999/88641, Loss=1.5489, lr=0.0000310 Time cost=4.1 Thoughput=12.07 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 29049/88641, Loss=1.7764, lr=0.0000310 Time cost=4.1 Thoughput=12.22 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 29099/88641, Loss=1.6689, lr=0.0000310 Time cost=4.2 Thoughput=11.96 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 29149/88641, Loss=2.1024, lr=0.0000309 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 29199/88641, Loss=1.7851, lr=0.0000309 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 29249/88641, Loss=2.0564, lr=0.0000309 Time cost=4.1 Thoughput=12.19 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 29299/88641, Loss=1.6366, lr=0.0000309 Time cost=4.1 Thoughput=12.22 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 29349/88641, Loss=1.0388, lr=0.0000309 Time cost=4.1 Thoughput=12.22 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 29399/88641, Loss=1.7004, lr=0.0000309 Time cost=4.1 Thoughput=12.27 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 29449/88641, Loss=1.9060, lr=0.0000309 Time cost=4.1 Thoughput=12.32 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 29499/88641, Loss=2.0702, lr=0.0000309 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 29549/88641, Loss=2.0061, lr=0.0000309 Time cost=4.2 Thoughput=11.89 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 29599/88641, Loss=2.3274, lr=0.0000309 Time cost=4.2 Thoughput=12.03 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 29649/88641, Loss=1.4880, lr=0.0000308 Time cost=4.2 Thoughput=12.03 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 29699/88641, Loss=1.5481, lr=0.0000308 Time cost=4.2 Thoughput=12.04 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 29749/88641, Loss=1.8819, lr=0.0000308 Time cost=4.2 Thoughput=12.01 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 29799/88641, Loss=1.3239, lr=0.0000308 Time cost=4.2 Thoughput=12.02 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 29849/88641, Loss=1.5927, lr=0.0000308 Time cost=4.2 Thoughput=11.95 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 29899/88641, Loss=1.3981, lr=0.0000308 Time cost=4.1 Thoughput=12.12 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 29949/88641, Loss=1.6276, lr=0.0000308 Time cost=4.1 Thoughput=12.22 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 29999/88641, Loss=2.0319, lr=0.0000308 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 30049/88641, Loss=1.7619, lr=0.0000308 Time cost=4.1 Thoughput=12.19 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 30099/88641, Loss=1.8635, lr=0.0000307 Time cost=4.6 Thoughput=10.83 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 30149/88641, Loss=1.6545, lr=0.0000307 Time cost=4.4 Thoughput=11.44 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 30199/88641, Loss=2.0631, lr=0.0000307 Time cost=4.1 Thoughput=12.22 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 30249/88641, Loss=1.9139, lr=0.0000307 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 30299/88641, Loss=2.0764, lr=0.0000307 Time cost=4.1 Thoughput=12.21 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 30349/88641, Loss=1.8242, lr=0.0000307 Time cost=4.1 Thoughput=12.20 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 30399/88641, Loss=1.6930, lr=0.0000307 Time cost=4.1 Thoughput=12.20 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 30449/88641, Loss=1.5901, lr=0.0000307 Time cost=4.1 Thoughput=12.12 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 30499/88641, Loss=1.5927, lr=0.0000307 Time cost=4.2 Thoughput=11.82 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 30549/88641, Loss=2.0242, lr=0.0000307 Time cost=4.2 Thoughput=11.96 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 30599/88641, Loss=1.8693, lr=0.0000306 Time cost=4.1 Thoughput=12.17 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 30649/88641, Loss=1.4075, lr=0.0000306 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 30699/88641, Loss=1.8512, lr=0.0000306 Time cost=4.1 Thoughput=12.27 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 30749/88641, Loss=1.9078, lr=0.0000306 Time cost=4.2 Thoughput=11.96 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 30799/88641, Loss=1.8384, lr=0.0000306 Time cost=4.1 Thoughput=12.17 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 30849/88641, Loss=1.2207, lr=0.0000306 Time cost=4.1 Thoughput=12.20 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 30899/88641, Loss=1.9989, lr=0.0000306 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 30949/88641, Loss=1.6154, lr=0.0000306 Time cost=4.1 Thoughput=12.30 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 30999/88641, Loss=1.3473, lr=0.0000306 Time cost=4.1 Thoughput=12.32 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 31049/88641, Loss=0.9443, lr=0.0000306 Time cost=4.1 Thoughput=12.29 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 31099/88641, Loss=1.6509, lr=0.0000305 Time cost=4.1 Thoughput=12.27 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 31149/88641, Loss=1.7793, lr=0.0000305 Time cost=4.1 Thoughput=12.20 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 31199/88641, Loss=2.1643, lr=0.0000305 Time cost=4.1 Thoughput=12.17 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 31249/88641, Loss=1.5036, lr=0.0000305 Time cost=4.1 Thoughput=12.22 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 31299/88641, Loss=1.4137, lr=0.0000305 Time cost=4.1 Thoughput=12.19 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 31349/88641, Loss=1.4724, lr=0.0000305 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 31399/88641, Loss=2.3057, lr=0.0000305 Time cost=4.1 Thoughput=12.27 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 31449/88641, Loss=1.5110, lr=0.0000305 Time cost=4.1 Thoughput=12.27 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 31499/88641, Loss=1.6948, lr=0.0000305 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 31549/88641, Loss=1.2348, lr=0.0000304 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 31599/88641, Loss=1.7222, lr=0.0000304 Time cost=4.1 Thoughput=12.22 samples/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gluonnlp:Epoch: 1, Batch: 31649/88641, Loss=1.6721, lr=0.0000304 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 31699/88641, Loss=1.6107, lr=0.0000304 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 31749/88641, Loss=1.9971, lr=0.0000304 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 31799/88641, Loss=1.7955, lr=0.0000304 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 31849/88641, Loss=2.2350, lr=0.0000304 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 31899/88641, Loss=1.5034, lr=0.0000304 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 31949/88641, Loss=2.1068, lr=0.0000304 Time cost=4.1 Thoughput=12.29 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 31999/88641, Loss=1.9314, lr=0.0000304 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 32049/88641, Loss=1.9600, lr=0.0000303 Time cost=4.1 Thoughput=12.17 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 32099/88641, Loss=1.5084, lr=0.0000303 Time cost=4.1 Thoughput=12.32 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 32149/88641, Loss=1.6025, lr=0.0000303 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 32199/88641, Loss=1.7446, lr=0.0000303 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 32249/88641, Loss=1.5410, lr=0.0000303 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 32299/88641, Loss=1.5632, lr=0.0000303 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 32349/88641, Loss=1.0955, lr=0.0000303 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 32399/88641, Loss=1.8136, lr=0.0000303 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 32449/88641, Loss=1.9668, lr=0.0000303 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 32499/88641, Loss=1.2471, lr=0.0000302 Time cost=4.1 Thoughput=12.29 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 32549/88641, Loss=1.7505, lr=0.0000302 Time cost=4.1 Thoughput=12.27 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 32599/88641, Loss=1.7637, lr=0.0000302 Time cost=4.1 Thoughput=12.28 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 32649/88641, Loss=2.2573, lr=0.0000302 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 32699/88641, Loss=1.8136, lr=0.0000302 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 32749/88641, Loss=1.5499, lr=0.0000302 Time cost=4.1 Thoughput=12.27 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 32799/88641, Loss=1.8249, lr=0.0000302 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 32849/88641, Loss=1.8740, lr=0.0000302 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 32899/88641, Loss=1.9836, lr=0.0000302 Time cost=4.1 Thoughput=12.10 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 32949/88641, Loss=1.9104, lr=0.0000302 Time cost=4.2 Thoughput=11.80 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 32999/88641, Loss=1.5119, lr=0.0000301 Time cost=4.1 Thoughput=12.21 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 33049/88641, Loss=1.3917, lr=0.0000301 Time cost=4.1 Thoughput=12.22 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 33099/88641, Loss=1.2591, lr=0.0000301 Time cost=4.1 Thoughput=12.19 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 33149/88641, Loss=1.6370, lr=0.0000301 Time cost=4.1 Thoughput=12.22 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 33199/88641, Loss=2.0047, lr=0.0000301 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 33249/88641, Loss=1.8017, lr=0.0000301 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 33299/88641, Loss=1.7954, lr=0.0000301 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 33349/88641, Loss=1.6894, lr=0.0000301 Time cost=4.1 Thoughput=12.30 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 33399/88641, Loss=1.3052, lr=0.0000301 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 33449/88641, Loss=1.5612, lr=0.0000300 Time cost=4.1 Thoughput=12.08 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 33499/88641, Loss=1.6163, lr=0.0000300 Time cost=4.1 Thoughput=12.22 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 33549/88641, Loss=1.3205, lr=0.0000300 Time cost=4.1 Thoughput=12.14 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 33599/88641, Loss=1.4249, lr=0.0000300 Time cost=4.1 Thoughput=12.13 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 33649/88641, Loss=1.6397, lr=0.0000300 Time cost=4.1 Thoughput=12.15 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 33699/88641, Loss=1.6062, lr=0.0000300 Time cost=4.1 Thoughput=12.15 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 33749/88641, Loss=1.9275, lr=0.0000300 Time cost=4.1 Thoughput=12.17 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 33799/88641, Loss=1.4870, lr=0.0000300 Time cost=4.1 Thoughput=12.20 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 33849/88641, Loss=1.0341, lr=0.0000300 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 33899/88641, Loss=1.8063, lr=0.0000300 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 33949/88641, Loss=1.5105, lr=0.0000299 Time cost=4.6 Thoughput=10.89 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 33999/88641, Loss=1.2681, lr=0.0000299 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 34049/88641, Loss=1.9697, lr=0.0000299 Time cost=4.1 Thoughput=12.22 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 34099/88641, Loss=1.5662, lr=0.0000299 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 34149/88641, Loss=1.5775, lr=0.0000299 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 34199/88641, Loss=1.7774, lr=0.0000299 Time cost=4.1 Thoughput=12.11 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 34249/88641, Loss=1.3696, lr=0.0000299 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 34299/88641, Loss=1.7238, lr=0.0000299 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 34349/88641, Loss=2.0822, lr=0.0000299 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 34399/88641, Loss=1.3685, lr=0.0000299 Time cost=4.1 Thoughput=12.21 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 34449/88641, Loss=1.9709, lr=0.0000298 Time cost=4.1 Thoughput=12.20 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 34499/88641, Loss=1.9490, lr=0.0000298 Time cost=4.1 Thoughput=12.22 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 34549/88641, Loss=1.9145, lr=0.0000298 Time cost=4.1 Thoughput=12.27 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 34599/88641, Loss=1.8059, lr=0.0000298 Time cost=4.1 Thoughput=12.28 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 34649/88641, Loss=1.1688, lr=0.0000298 Time cost=4.1 Thoughput=12.30 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 34699/88641, Loss=2.0384, lr=0.0000298 Time cost=4.1 Thoughput=12.30 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 34749/88641, Loss=1.8133, lr=0.0000298 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 34799/88641, Loss=1.8905, lr=0.0000298 Time cost=4.1 Thoughput=12.21 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 34849/88641, Loss=1.2847, lr=0.0000298 Time cost=4.2 Thoughput=12.00 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 34899/88641, Loss=1.5088, lr=0.0000297 Time cost=4.2 Thoughput=11.99 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 34949/88641, Loss=1.8770, lr=0.0000297 Time cost=4.2 Thoughput=11.97 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 34999/88641, Loss=1.7719, lr=0.0000297 Time cost=4.1 Thoughput=12.18 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 35049/88641, Loss=1.6971, lr=0.0000297 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 35099/88641, Loss=1.0533, lr=0.0000297 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 35149/88641, Loss=1.6245, lr=0.0000297 Time cost=4.2 Thoughput=12.02 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 35199/88641, Loss=2.2668, lr=0.0000297 Time cost=4.1 Thoughput=12.22 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 35249/88641, Loss=1.9016, lr=0.0000297 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 35299/88641, Loss=1.5347, lr=0.0000297 Time cost=4.1 Thoughput=12.21 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 35349/88641, Loss=1.8978, lr=0.0000297 Time cost=4.1 Thoughput=12.22 samples/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gluonnlp:Epoch: 1, Batch: 35399/88641, Loss=2.2046, lr=0.0000296 Time cost=4.1 Thoughput=12.20 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 35449/88641, Loss=1.3273, lr=0.0000296 Time cost=4.1 Thoughput=12.22 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 35499/88641, Loss=1.8215, lr=0.0000296 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 35549/88641, Loss=1.5036, lr=0.0000296 Time cost=4.1 Thoughput=12.20 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 35599/88641, Loss=1.8759, lr=0.0000296 Time cost=4.1 Thoughput=12.20 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 35649/88641, Loss=1.7733, lr=0.0000296 Time cost=4.1 Thoughput=12.17 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 35699/88641, Loss=1.5864, lr=0.0000296 Time cost=4.1 Thoughput=12.10 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 35749/88641, Loss=1.7584, lr=0.0000296 Time cost=4.2 Thoughput=12.03 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 35799/88641, Loss=2.4436, lr=0.0000296 Time cost=4.2 Thoughput=12.01 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 35849/88641, Loss=1.8247, lr=0.0000295 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 35899/88641, Loss=1.1104, lr=0.0000295 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 35949/88641, Loss=2.0495, lr=0.0000295 Time cost=4.1 Thoughput=12.27 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 35999/88641, Loss=1.6108, lr=0.0000295 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 36049/88641, Loss=1.4559, lr=0.0000295 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 36099/88641, Loss=1.2492, lr=0.0000295 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 36149/88641, Loss=1.9273, lr=0.0000295 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 36199/88641, Loss=1.0773, lr=0.0000295 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 36249/88641, Loss=1.4549, lr=0.0000295 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 36299/88641, Loss=1.5973, lr=0.0000295 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 36349/88641, Loss=2.1184, lr=0.0000294 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 36399/88641, Loss=1.6926, lr=0.0000294 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 36449/88641, Loss=2.2087, lr=0.0000294 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 36499/88641, Loss=1.5438, lr=0.0000294 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 36549/88641, Loss=1.6606, lr=0.0000294 Time cost=4.1 Thoughput=12.27 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 36599/88641, Loss=1.7387, lr=0.0000294 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 36649/88641, Loss=1.5279, lr=0.0000294 Time cost=4.6 Thoughput=10.95 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 36699/88641, Loss=2.0822, lr=0.0000294 Time cost=4.1 Thoughput=12.18 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 36749/88641, Loss=1.6257, lr=0.0000294 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 36799/88641, Loss=1.5344, lr=0.0000293 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 36849/88641, Loss=1.2746, lr=0.0000293 Time cost=4.1 Thoughput=12.21 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 36899/88641, Loss=1.6553, lr=0.0000293 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 36949/88641, Loss=2.0245, lr=0.0000293 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 36999/88641, Loss=1.6209, lr=0.0000293 Time cost=4.1 Thoughput=12.27 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 37049/88641, Loss=2.5883, lr=0.0000293 Time cost=4.1 Thoughput=12.29 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 37099/88641, Loss=1.4128, lr=0.0000293 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 37149/88641, Loss=1.3666, lr=0.0000293 Time cost=4.1 Thoughput=12.17 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 37199/88641, Loss=1.2957, lr=0.0000293 Time cost=4.2 Thoughput=12.03 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 37249/88641, Loss=1.3497, lr=0.0000293 Time cost=4.2 Thoughput=11.99 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 37299/88641, Loss=1.9426, lr=0.0000292 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 37349/88641, Loss=1.6110, lr=0.0000292 Time cost=4.2 Thoughput=11.95 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 37399/88641, Loss=1.4620, lr=0.0000292 Time cost=4.1 Thoughput=12.21 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 37449/88641, Loss=1.6156, lr=0.0000292 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 37499/88641, Loss=1.3942, lr=0.0000292 Time cost=4.1 Thoughput=12.18 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 37549/88641, Loss=2.0206, lr=0.0000292 Time cost=4.2 Thoughput=11.95 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 37599/88641, Loss=1.3556, lr=0.0000292 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 37649/88641, Loss=2.0335, lr=0.0000292 Time cost=4.1 Thoughput=12.22 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 37699/88641, Loss=1.7272, lr=0.0000292 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 37749/88641, Loss=1.9701, lr=0.0000292 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 37799/88641, Loss=1.4580, lr=0.0000291 Time cost=4.1 Thoughput=12.17 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 37849/88641, Loss=1.7479, lr=0.0000291 Time cost=4.1 Thoughput=12.10 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 37899/88641, Loss=2.1117, lr=0.0000291 Time cost=4.1 Thoughput=12.13 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 37949/88641, Loss=1.8437, lr=0.0000291 Time cost=4.1 Thoughput=12.17 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 37999/88641, Loss=1.3789, lr=0.0000291 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 38049/88641, Loss=1.6381, lr=0.0000291 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 38099/88641, Loss=0.9760, lr=0.0000291 Time cost=4.1 Thoughput=12.19 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 38149/88641, Loss=1.1976, lr=0.0000291 Time cost=4.1 Thoughput=12.22 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 38199/88641, Loss=1.8583, lr=0.0000291 Time cost=4.1 Thoughput=12.08 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 38249/88641, Loss=1.7273, lr=0.0000290 Time cost=4.1 Thoughput=12.18 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 38299/88641, Loss=1.7514, lr=0.0000290 Time cost=4.1 Thoughput=12.28 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 38349/88641, Loss=1.9002, lr=0.0000290 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 38399/88641, Loss=2.2873, lr=0.0000290 Time cost=4.1 Thoughput=12.22 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 38449/88641, Loss=1.3487, lr=0.0000290 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 38499/88641, Loss=1.9102, lr=0.0000290 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 38549/88641, Loss=0.8441, lr=0.0000290 Time cost=4.3 Thoughput=11.60 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 38599/88641, Loss=1.2063, lr=0.0000290 Time cost=4.1 Thoughput=12.16 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 38649/88641, Loss=1.8319, lr=0.0000290 Time cost=4.1 Thoughput=12.14 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 38699/88641, Loss=2.1357, lr=0.0000290 Time cost=4.1 Thoughput=12.13 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 38749/88641, Loss=1.7501, lr=0.0000289 Time cost=4.1 Thoughput=12.15 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 38799/88641, Loss=1.6529, lr=0.0000289 Time cost=4.1 Thoughput=12.20 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 38849/88641, Loss=1.4401, lr=0.0000289 Time cost=4.1 Thoughput=12.19 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 38899/88641, Loss=2.3455, lr=0.0000289 Time cost=4.1 Thoughput=12.14 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 38949/88641, Loss=2.1059, lr=0.0000289 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 38999/88641, Loss=1.9672, lr=0.0000289 Time cost=4.1 Thoughput=12.21 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 39049/88641, Loss=1.6256, lr=0.0000289 Time cost=4.1 Thoughput=12.17 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 39099/88641, Loss=1.0584, lr=0.0000289 Time cost=4.4 Thoughput=11.44 samples/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gluonnlp:Epoch: 1, Batch: 39149/88641, Loss=1.4587, lr=0.0000289 Time cost=4.1 Thoughput=12.22 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 39199/88641, Loss=2.1625, lr=0.0000288 Time cost=4.1 Thoughput=12.22 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 39249/88641, Loss=2.1335, lr=0.0000288 Time cost=4.1 Thoughput=12.21 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 39299/88641, Loss=1.9244, lr=0.0000288 Time cost=4.1 Thoughput=12.21 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 39349/88641, Loss=1.3417, lr=0.0000288 Time cost=4.1 Thoughput=12.19 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 39399/88641, Loss=1.7993, lr=0.0000288 Time cost=4.1 Thoughput=12.20 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 39449/88641, Loss=1.8923, lr=0.0000288 Time cost=4.1 Thoughput=12.20 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 39499/88641, Loss=1.8757, lr=0.0000288 Time cost=4.1 Thoughput=12.15 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 39549/88641, Loss=1.7658, lr=0.0000288 Time cost=4.2 Thoughput=12.04 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 39599/88641, Loss=1.5916, lr=0.0000288 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 39649/88641, Loss=1.7145, lr=0.0000288 Time cost=4.1 Thoughput=12.28 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 39699/88641, Loss=1.9524, lr=0.0000287 Time cost=4.1 Thoughput=12.30 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 39749/88641, Loss=1.5028, lr=0.0000287 Time cost=4.1 Thoughput=12.16 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 39799/88641, Loss=1.7737, lr=0.0000287 Time cost=4.2 Thoughput=12.00 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 39849/88641, Loss=1.9071, lr=0.0000287 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 39899/88641, Loss=1.5782, lr=0.0000287 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 39949/88641, Loss=2.1830, lr=0.0000287 Time cost=4.1 Thoughput=12.28 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 39999/88641, Loss=1.9735, lr=0.0000287 Time cost=4.1 Thoughput=12.28 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 40049/88641, Loss=2.0239, lr=0.0000287 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 40099/88641, Loss=1.6768, lr=0.0000287 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 40149/88641, Loss=1.6068, lr=0.0000286 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 40199/88641, Loss=1.3414, lr=0.0000286 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 40249/88641, Loss=1.6808, lr=0.0000286 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 40299/88641, Loss=1.5732, lr=0.0000286 Time cost=4.1 Thoughput=12.22 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 40349/88641, Loss=1.2471, lr=0.0000286 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 40399/88641, Loss=1.7282, lr=0.0000286 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 40449/88641, Loss=1.5445, lr=0.0000286 Time cost=4.1 Thoughput=12.27 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 40499/88641, Loss=1.9116, lr=0.0000286 Time cost=4.6 Thoughput=10.90 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 40549/88641, Loss=2.0026, lr=0.0000286 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 40599/88641, Loss=1.8136, lr=0.0000286 Time cost=4.1 Thoughput=12.22 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 40649/88641, Loss=1.7291, lr=0.0000285 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 40699/88641, Loss=1.9849, lr=0.0000285 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 40749/88641, Loss=1.1986, lr=0.0000285 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 40799/88641, Loss=1.9918, lr=0.0000285 Time cost=4.1 Thoughput=12.10 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 40849/88641, Loss=1.7678, lr=0.0000285 Time cost=4.2 Thoughput=11.98 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 40899/88641, Loss=1.6282, lr=0.0000285 Time cost=4.2 Thoughput=11.89 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 40949/88641, Loss=2.0378, lr=0.0000285 Time cost=4.2 Thoughput=11.99 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 40999/88641, Loss=2.1599, lr=0.0000285 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 41049/88641, Loss=1.5373, lr=0.0000285 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 41099/88641, Loss=2.1079, lr=0.0000285 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 41149/88641, Loss=1.4686, lr=0.0000284 Time cost=4.1 Thoughput=12.20 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 41199/88641, Loss=1.6981, lr=0.0000284 Time cost=4.1 Thoughput=12.18 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 41249/88641, Loss=1.6293, lr=0.0000284 Time cost=4.2 Thoughput=12.01 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 41299/88641, Loss=2.1303, lr=0.0000284 Time cost=4.2 Thoughput=11.95 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 41349/88641, Loss=2.4791, lr=0.0000284 Time cost=4.2 Thoughput=12.02 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 41399/88641, Loss=1.9528, lr=0.0000284 Time cost=4.1 Thoughput=12.11 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 41449/88641, Loss=1.2612, lr=0.0000284 Time cost=4.1 Thoughput=12.08 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 41499/88641, Loss=1.6915, lr=0.0000284 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 41549/88641, Loss=1.4668, lr=0.0000284 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 41599/88641, Loss=1.8721, lr=0.0000283 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 41649/88641, Loss=1.9315, lr=0.0000283 Time cost=4.2 Thoughput=11.90 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 41699/88641, Loss=1.7273, lr=0.0000283 Time cost=4.2 Thoughput=11.92 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 41749/88641, Loss=0.9361, lr=0.0000283 Time cost=4.1 Thoughput=12.19 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 41799/88641, Loss=1.8132, lr=0.0000283 Time cost=4.1 Thoughput=12.19 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 41849/88641, Loss=1.1925, lr=0.0000283 Time cost=4.1 Thoughput=12.17 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 41899/88641, Loss=1.8172, lr=0.0000283 Time cost=4.1 Thoughput=12.16 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 41949/88641, Loss=2.2483, lr=0.0000283 Time cost=4.1 Thoughput=12.17 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 41999/88641, Loss=1.4043, lr=0.0000283 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 42049/88641, Loss=2.0525, lr=0.0000283 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 42099/88641, Loss=1.8517, lr=0.0000282 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 42149/88641, Loss=1.4538, lr=0.0000282 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 42199/88641, Loss=1.0637, lr=0.0000282 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 42249/88641, Loss=1.4706, lr=0.0000282 Time cost=4.1 Thoughput=12.09 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 42299/88641, Loss=1.7435, lr=0.0000282 Time cost=4.1 Thoughput=12.21 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 42349/88641, Loss=1.7492, lr=0.0000282 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 42399/88641, Loss=2.2339, lr=0.0000282 Time cost=4.1 Thoughput=12.18 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 42449/88641, Loss=1.1368, lr=0.0000282 Time cost=4.1 Thoughput=12.18 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 42499/88641, Loss=1.4400, lr=0.0000282 Time cost=4.1 Thoughput=12.19 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 42549/88641, Loss=1.6654, lr=0.0000281 Time cost=4.1 Thoughput=12.20 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 42599/88641, Loss=1.9721, lr=0.0000281 Time cost=4.1 Thoughput=12.22 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 42649/88641, Loss=1.6498, lr=0.0000281 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 42699/88641, Loss=1.8171, lr=0.0000281 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 42749/88641, Loss=1.4918, lr=0.0000281 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 42799/88641, Loss=1.8480, lr=0.0000281 Time cost=4.1 Thoughput=12.29 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 42849/88641, Loss=1.5463, lr=0.0000281 Time cost=4.1 Thoughput=12.24 samples/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gluonnlp:Epoch: 1, Batch: 42899/88641, Loss=1.3324, lr=0.0000281 Time cost=4.1 Thoughput=12.14 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 42949/88641, Loss=1.8475, lr=0.0000281 Time cost=4.1 Thoughput=12.18 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 42999/88641, Loss=1.4718, lr=0.0000281 Time cost=4.1 Thoughput=12.18 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 43049/88641, Loss=1.7915, lr=0.0000280 Time cost=4.1 Thoughput=12.22 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 43099/88641, Loss=2.0647, lr=0.0000280 Time cost=4.1 Thoughput=12.22 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 43149/88641, Loss=1.4715, lr=0.0000280 Time cost=4.1 Thoughput=12.22 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 43199/88641, Loss=1.4985, lr=0.0000280 Time cost=4.6 Thoughput=10.88 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 43249/88641, Loss=2.0297, lr=0.0000280 Time cost=4.1 Thoughput=12.19 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 43299/88641, Loss=1.5787, lr=0.0000280 Time cost=4.1 Thoughput=12.18 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 43349/88641, Loss=2.0170, lr=0.0000280 Time cost=4.1 Thoughput=12.19 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 43399/88641, Loss=1.5843, lr=0.0000280 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 43449/88641, Loss=2.0865, lr=0.0000280 Time cost=4.1 Thoughput=12.30 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 43499/88641, Loss=2.0820, lr=0.0000279 Time cost=4.1 Thoughput=12.30 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 43549/88641, Loss=1.3777, lr=0.0000279 Time cost=4.1 Thoughput=12.28 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 43599/88641, Loss=2.1481, lr=0.0000279 Time cost=4.1 Thoughput=12.27 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 43649/88641, Loss=1.5993, lr=0.0000279 Time cost=4.1 Thoughput=12.28 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 43699/88641, Loss=1.4492, lr=0.0000279 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 43749/88641, Loss=1.8958, lr=0.0000279 Time cost=4.1 Thoughput=12.22 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 43799/88641, Loss=1.5245, lr=0.0000279 Time cost=4.1 Thoughput=12.20 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 43849/88641, Loss=1.7658, lr=0.0000279 Time cost=4.1 Thoughput=12.19 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 43899/88641, Loss=1.7858, lr=0.0000279 Time cost=4.2 Thoughput=11.94 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 43949/88641, Loss=1.8455, lr=0.0000279 Time cost=4.1 Thoughput=12.15 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 43999/88641, Loss=1.6903, lr=0.0000278 Time cost=4.1 Thoughput=12.20 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 44049/88641, Loss=1.1403, lr=0.0000278 Time cost=4.1 Thoughput=12.17 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 44099/88641, Loss=2.2193, lr=0.0000278 Time cost=4.1 Thoughput=12.21 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 44149/88641, Loss=2.0386, lr=0.0000278 Time cost=4.1 Thoughput=12.09 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 44199/88641, Loss=1.4266, lr=0.0000278 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 44249/88641, Loss=1.3612, lr=0.0000278 Time cost=4.1 Thoughput=12.30 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 44299/88641, Loss=1.0923, lr=0.0000278 Time cost=4.1 Thoughput=12.08 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 44349/88641, Loss=1.9556, lr=0.0000278 Time cost=4.2 Thoughput=12.01 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 44399/88641, Loss=2.4314, lr=0.0000278 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 44449/88641, Loss=1.8194, lr=0.0000278 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 44499/88641, Loss=1.8712, lr=0.0000277 Time cost=4.1 Thoughput=12.29 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 44549/88641, Loss=1.7996, lr=0.0000277 Time cost=4.1 Thoughput=12.28 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 44599/88641, Loss=1.8730, lr=0.0000277 Time cost=4.1 Thoughput=12.27 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 44649/88641, Loss=1.2712, lr=0.0000277 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 44699/88641, Loss=1.4690, lr=0.0000277 Time cost=4.1 Thoughput=12.22 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 44749/88641, Loss=2.0788, lr=0.0000277 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 44799/88641, Loss=1.7400, lr=0.0000277 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 44849/88641, Loss=1.7418, lr=0.0000277 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 44899/88641, Loss=1.2383, lr=0.0000277 Time cost=4.1 Thoughput=12.27 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 44949/88641, Loss=1.8010, lr=0.0000276 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 44999/88641, Loss=1.5760, lr=0.0000276 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 45049/88641, Loss=1.3711, lr=0.0000276 Time cost=4.1 Thoughput=12.27 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 45099/88641, Loss=1.8576, lr=0.0000276 Time cost=4.1 Thoughput=12.27 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 45149/88641, Loss=1.2379, lr=0.0000276 Time cost=4.1 Thoughput=12.27 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 45199/88641, Loss=1.6896, lr=0.0000276 Time cost=4.1 Thoughput=12.22 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 45249/88641, Loss=1.5812, lr=0.0000276 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 45299/88641, Loss=1.3589, lr=0.0000276 Time cost=4.1 Thoughput=12.28 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 45349/88641, Loss=2.2672, lr=0.0000276 Time cost=4.1 Thoughput=12.28 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 45399/88641, Loss=1.6536, lr=0.0000276 Time cost=4.1 Thoughput=12.29 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 45449/88641, Loss=1.9794, lr=0.0000275 Time cost=4.1 Thoughput=12.30 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 45499/88641, Loss=1.7628, lr=0.0000275 Time cost=4.1 Thoughput=12.28 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 45549/88641, Loss=1.7580, lr=0.0000275 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 45599/88641, Loss=1.5028, lr=0.0000275 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 45649/88641, Loss=0.9668, lr=0.0000275 Time cost=4.1 Thoughput=12.21 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 45699/88641, Loss=2.0755, lr=0.0000275 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 45749/88641, Loss=1.3884, lr=0.0000275 Time cost=4.1 Thoughput=12.22 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 45799/88641, Loss=1.8046, lr=0.0000275 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 45849/88641, Loss=1.3952, lr=0.0000275 Time cost=4.1 Thoughput=12.20 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 45899/88641, Loss=1.5166, lr=0.0000274 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 45949/88641, Loss=1.4155, lr=0.0000274 Time cost=4.1 Thoughput=12.27 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 45999/88641, Loss=1.9100, lr=0.0000274 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 46049/88641, Loss=2.0796, lr=0.0000274 Time cost=4.1 Thoughput=12.19 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 46099/88641, Loss=1.5797, lr=0.0000274 Time cost=4.2 Thoughput=11.85 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 46149/88641, Loss=1.7094, lr=0.0000274 Time cost=4.2 Thoughput=11.95 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 46199/88641, Loss=1.6866, lr=0.0000274 Time cost=4.3 Thoughput=11.65 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 46249/88641, Loss=0.8425, lr=0.0000274 Time cost=4.1 Thoughput=12.19 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 46299/88641, Loss=1.7961, lr=0.0000274 Time cost=4.2 Thoughput=12.01 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 46349/88641, Loss=1.5578, lr=0.0000274 Time cost=4.1 Thoughput=12.28 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 46399/88641, Loss=2.0997, lr=0.0000273 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 46449/88641, Loss=1.7992, lr=0.0000273 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 46499/88641, Loss=1.6576, lr=0.0000273 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 46549/88641, Loss=1.1017, lr=0.0000273 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 46599/88641, Loss=1.5280, lr=0.0000273 Time cost=4.1 Thoughput=12.24 samples/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gluonnlp:Epoch: 1, Batch: 46649/88641, Loss=1.4870, lr=0.0000273 Time cost=4.2 Thoughput=11.89 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 46699/88641, Loss=1.3658, lr=0.0000273 Time cost=4.2 Thoughput=11.93 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 46749/88641, Loss=1.5041, lr=0.0000273 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 46799/88641, Loss=2.1536, lr=0.0000273 Time cost=4.1 Thoughput=12.14 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 46849/88641, Loss=1.3602, lr=0.0000272 Time cost=4.2 Thoughput=11.98 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 46899/88641, Loss=1.5989, lr=0.0000272 Time cost=4.2 Thoughput=11.81 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 46949/88641, Loss=1.4885, lr=0.0000272 Time cost=4.1 Thoughput=12.16 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 46999/88641, Loss=1.0135, lr=0.0000272 Time cost=4.1 Thoughput=12.17 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 47049/88641, Loss=2.1725, lr=0.0000272 Time cost=4.6 Thoughput=10.82 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 47099/88641, Loss=1.8329, lr=0.0000272 Time cost=4.1 Thoughput=12.19 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 47149/88641, Loss=1.8468, lr=0.0000272 Time cost=4.2 Thoughput=11.85 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 47199/88641, Loss=1.0863, lr=0.0000272 Time cost=4.1 Thoughput=12.28 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 47249/88641, Loss=1.9617, lr=0.0000272 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 47299/88641, Loss=2.0515, lr=0.0000272 Time cost=4.1 Thoughput=12.27 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 47349/88641, Loss=1.5399, lr=0.0000271 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 47399/88641, Loss=1.7951, lr=0.0000271 Time cost=4.1 Thoughput=12.27 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 47449/88641, Loss=1.8367, lr=0.0000271 Time cost=4.1 Thoughput=12.27 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 47499/88641, Loss=2.3673, lr=0.0000271 Time cost=4.1 Thoughput=12.29 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 47549/88641, Loss=1.5595, lr=0.0000271 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 47599/88641, Loss=1.7161, lr=0.0000271 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 47649/88641, Loss=1.3422, lr=0.0000271 Time cost=4.1 Thoughput=12.29 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 47699/88641, Loss=2.0743, lr=0.0000271 Time cost=4.1 Thoughput=12.30 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 47749/88641, Loss=1.4399, lr=0.0000271 Time cost=4.1 Thoughput=12.27 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 47799/88641, Loss=0.9242, lr=0.0000271 Time cost=4.2 Thoughput=12.03 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 47849/88641, Loss=1.5355, lr=0.0000270 Time cost=4.2 Thoughput=12.02 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 47899/88641, Loss=1.7665, lr=0.0000270 Time cost=4.2 Thoughput=12.01 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 47949/88641, Loss=1.5077, lr=0.0000270 Time cost=4.1 Thoughput=12.14 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 47999/88641, Loss=1.9152, lr=0.0000270 Time cost=4.1 Thoughput=12.19 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 48049/88641, Loss=1.9912, lr=0.0000270 Time cost=4.1 Thoughput=12.29 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 48099/88641, Loss=1.6711, lr=0.0000270 Time cost=4.1 Thoughput=12.08 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 48149/88641, Loss=1.4280, lr=0.0000270 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 48199/88641, Loss=1.7853, lr=0.0000270 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 48249/88641, Loss=2.2903, lr=0.0000270 Time cost=4.1 Thoughput=12.22 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 48299/88641, Loss=2.1835, lr=0.0000269 Time cost=4.2 Thoughput=12.01 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 48349/88641, Loss=1.3850, lr=0.0000269 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 48399/88641, Loss=1.5237, lr=0.0000269 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 48449/88641, Loss=1.9027, lr=0.0000269 Time cost=4.1 Thoughput=12.27 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 48499/88641, Loss=1.7675, lr=0.0000269 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 48549/88641, Loss=1.6164, lr=0.0000269 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 48599/88641, Loss=1.8264, lr=0.0000269 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 48649/88641, Loss=1.8097, lr=0.0000269 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 48699/88641, Loss=1.9396, lr=0.0000269 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 48749/88641, Loss=1.2781, lr=0.0000269 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 48799/88641, Loss=1.2392, lr=0.0000268 Time cost=4.1 Thoughput=12.22 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 48849/88641, Loss=2.0039, lr=0.0000268 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 48899/88641, Loss=1.6952, lr=0.0000268 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 48949/88641, Loss=1.2857, lr=0.0000268 Time cost=4.1 Thoughput=12.22 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 48999/88641, Loss=1.2035, lr=0.0000268 Time cost=4.1 Thoughput=12.27 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 49049/88641, Loss=1.7092, lr=0.0000268 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 49099/88641, Loss=1.9139, lr=0.0000268 Time cost=4.1 Thoughput=12.28 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 49149/88641, Loss=1.5722, lr=0.0000268 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 49199/88641, Loss=1.2935, lr=0.0000268 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 49249/88641, Loss=1.2385, lr=0.0000267 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 49299/88641, Loss=1.4742, lr=0.0000267 Time cost=4.1 Thoughput=12.27 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 49349/88641, Loss=1.4054, lr=0.0000267 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 49399/88641, Loss=2.0615, lr=0.0000267 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 49449/88641, Loss=1.7534, lr=0.0000267 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 49499/88641, Loss=1.7206, lr=0.0000267 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 49549/88641, Loss=2.1745, lr=0.0000267 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 49599/88641, Loss=1.7523, lr=0.0000267 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 49649/88641, Loss=1.2813, lr=0.0000267 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 49699/88641, Loss=1.7539, lr=0.0000267 Time cost=4.1 Thoughput=12.20 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 49749/88641, Loss=2.2210, lr=0.0000266 Time cost=4.6 Thoughput=10.93 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 49799/88641, Loss=1.8914, lr=0.0000266 Time cost=4.1 Thoughput=12.27 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 49849/88641, Loss=1.7024, lr=0.0000266 Time cost=4.1 Thoughput=12.27 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 49899/88641, Loss=1.5955, lr=0.0000266 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 49949/88641, Loss=1.5045, lr=0.0000266 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 49999/88641, Loss=1.9601, lr=0.0000266 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 50049/88641, Loss=1.1252, lr=0.0000266 Time cost=4.1 Thoughput=12.28 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 50099/88641, Loss=1.5807, lr=0.0000266 Time cost=4.1 Thoughput=12.30 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 50149/88641, Loss=1.5868, lr=0.0000266 Time cost=4.1 Thoughput=12.05 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 50199/88641, Loss=2.1703, lr=0.0000265 Time cost=4.2 Thoughput=11.99 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 50249/88641, Loss=1.1852, lr=0.0000265 Time cost=4.1 Thoughput=12.20 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 50299/88641, Loss=1.7140, lr=0.0000265 Time cost=4.1 Thoughput=12.08 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 50349/88641, Loss=1.8952, lr=0.0000265 Time cost=4.1 Thoughput=12.14 samples/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gluonnlp:Epoch: 1, Batch: 50399/88641, Loss=2.5777, lr=0.0000265 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 50449/88641, Loss=1.5659, lr=0.0000265 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 50499/88641, Loss=2.3836, lr=0.0000265 Time cost=4.1 Thoughput=12.05 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 50549/88641, Loss=1.3364, lr=0.0000265 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 50599/88641, Loss=1.6311, lr=0.0000265 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 50649/88641, Loss=2.0004, lr=0.0000265 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 50699/88641, Loss=1.4358, lr=0.0000264 Time cost=4.1 Thoughput=12.19 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 50749/88641, Loss=1.7844, lr=0.0000264 Time cost=4.1 Thoughput=12.07 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 50799/88641, Loss=1.1062, lr=0.0000264 Time cost=4.1 Thoughput=12.18 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 50849/88641, Loss=1.7894, lr=0.0000264 Time cost=4.1 Thoughput=12.18 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 50899/88641, Loss=2.0896, lr=0.0000264 Time cost=4.1 Thoughput=12.22 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 50949/88641, Loss=1.7001, lr=0.0000264 Time cost=4.1 Thoughput=12.21 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 50999/88641, Loss=1.9338, lr=0.0000264 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 51049/88641, Loss=1.7046, lr=0.0000264 Time cost=4.2 Thoughput=12.03 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 51099/88641, Loss=2.0670, lr=0.0000264 Time cost=4.1 Thoughput=12.10 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 51149/88641, Loss=1.2597, lr=0.0000264 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 51199/88641, Loss=1.7372, lr=0.0000263 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 51249/88641, Loss=1.9518, lr=0.0000263 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 51299/88641, Loss=1.9435, lr=0.0000263 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 51349/88641, Loss=1.4240, lr=0.0000263 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 51399/88641, Loss=1.9698, lr=0.0000263 Time cost=4.1 Thoughput=12.17 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 51449/88641, Loss=1.9592, lr=0.0000263 Time cost=4.1 Thoughput=12.17 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 51499/88641, Loss=1.1827, lr=0.0000263 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 51549/88641, Loss=1.4306, lr=0.0000263 Time cost=4.1 Thoughput=12.19 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 51599/88641, Loss=1.8591, lr=0.0000263 Time cost=4.1 Thoughput=12.21 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 51649/88641, Loss=1.6840, lr=0.0000262 Time cost=4.1 Thoughput=12.05 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 51699/88641, Loss=1.5378, lr=0.0000262 Time cost=4.1 Thoughput=12.13 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 51749/88641, Loss=2.1951, lr=0.0000262 Time cost=4.1 Thoughput=12.21 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 51799/88641, Loss=1.4118, lr=0.0000262 Time cost=4.1 Thoughput=12.21 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 51849/88641, Loss=1.7683, lr=0.0000262 Time cost=4.1 Thoughput=12.19 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 51899/88641, Loss=1.2532, lr=0.0000262 Time cost=4.1 Thoughput=12.20 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 51949/88641, Loss=1.3010, lr=0.0000262 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 51999/88641, Loss=1.9416, lr=0.0000262 Time cost=4.1 Thoughput=12.17 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 52049/88641, Loss=1.7464, lr=0.0000262 Time cost=4.1 Thoughput=12.20 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 52099/88641, Loss=1.9445, lr=0.0000262 Time cost=4.2 Thoughput=11.89 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 52149/88641, Loss=1.5379, lr=0.0000261 Time cost=4.2 Thoughput=12.04 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 52199/88641, Loss=1.3914, lr=0.0000261 Time cost=4.1 Thoughput=12.20 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 52249/88641, Loss=1.4906, lr=0.0000261 Time cost=4.1 Thoughput=12.21 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 52299/88641, Loss=1.6064, lr=0.0000261 Time cost=4.1 Thoughput=12.19 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 52349/88641, Loss=1.6964, lr=0.0000261 Time cost=4.1 Thoughput=12.16 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 52399/88641, Loss=1.5839, lr=0.0000261 Time cost=4.1 Thoughput=12.17 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 52449/88641, Loss=1.2504, lr=0.0000261 Time cost=4.1 Thoughput=12.19 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 52499/88641, Loss=1.6541, lr=0.0000261 Time cost=4.1 Thoughput=12.06 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 52549/88641, Loss=1.6947, lr=0.0000261 Time cost=4.3 Thoughput=11.70 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 52599/88641, Loss=1.3039, lr=0.0000260 Time cost=4.2 Thoughput=11.97 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 52649/88641, Loss=2.0509, lr=0.0000260 Time cost=4.2 Thoughput=11.78 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 52699/88641, Loss=1.9397, lr=0.0000260 Time cost=4.2 Thoughput=11.96 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 52749/88641, Loss=1.5654, lr=0.0000260 Time cost=4.2 Thoughput=11.95 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 52799/88641, Loss=1.9215, lr=0.0000260 Time cost=4.2 Thoughput=11.96 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 52849/88641, Loss=1.3982, lr=0.0000260 Time cost=4.1 Thoughput=12.14 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 52899/88641, Loss=2.0790, lr=0.0000260 Time cost=4.1 Thoughput=12.28 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 52949/88641, Loss=1.9529, lr=0.0000260 Time cost=4.1 Thoughput=12.22 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 52999/88641, Loss=1.3570, lr=0.0000260 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 53049/88641, Loss=1.7258, lr=0.0000260 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 53099/88641, Loss=1.3768, lr=0.0000259 Time cost=4.1 Thoughput=12.21 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 53149/88641, Loss=1.5508, lr=0.0000259 Time cost=4.1 Thoughput=12.27 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 53199/88641, Loss=1.3044, lr=0.0000259 Time cost=4.1 Thoughput=12.27 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 53249/88641, Loss=1.8543, lr=0.0000259 Time cost=4.1 Thoughput=12.29 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 53299/88641, Loss=1.8004, lr=0.0000259 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 53349/88641, Loss=1.4656, lr=0.0000259 Time cost=4.1 Thoughput=12.28 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 53399/88641, Loss=1.3297, lr=0.0000259 Time cost=4.1 Thoughput=12.27 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 53449/88641, Loss=2.5692, lr=0.0000259 Time cost=4.1 Thoughput=12.27 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 53499/88641, Loss=1.4299, lr=0.0000259 Time cost=4.1 Thoughput=12.31 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 53549/88641, Loss=2.1118, lr=0.0000258 Time cost=4.1 Thoughput=12.31 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 53599/88641, Loss=1.2745, lr=0.0000258 Time cost=4.6 Thoughput=10.95 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 53649/88641, Loss=2.0830, lr=0.0000258 Time cost=4.1 Thoughput=12.30 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 53699/88641, Loss=1.4168, lr=0.0000258 Time cost=4.1 Thoughput=12.28 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 53749/88641, Loss=1.6963, lr=0.0000258 Time cost=4.1 Thoughput=12.08 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 53799/88641, Loss=1.9473, lr=0.0000258 Time cost=4.2 Thoughput=11.97 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 53849/88641, Loss=1.9530, lr=0.0000258 Time cost=4.1 Thoughput=12.11 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 53899/88641, Loss=1.5128, lr=0.0000258 Time cost=4.1 Thoughput=12.28 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 53949/88641, Loss=1.8607, lr=0.0000258 Time cost=4.1 Thoughput=12.20 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 53999/88641, Loss=1.7105, lr=0.0000258 Time cost=4.1 Thoughput=12.09 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 54049/88641, Loss=1.4454, lr=0.0000257 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 54099/88641, Loss=1.3795, lr=0.0000257 Time cost=4.1 Thoughput=12.26 samples/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gluonnlp:Epoch: 1, Batch: 54149/88641, Loss=1.3993, lr=0.0000257 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 54199/88641, Loss=1.2691, lr=0.0000257 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 54249/88641, Loss=1.2348, lr=0.0000257 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 54299/88641, Loss=1.6117, lr=0.0000257 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 54349/88641, Loss=1.4235, lr=0.0000257 Time cost=4.1 Thoughput=12.19 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 54399/88641, Loss=0.9643, lr=0.0000257 Time cost=4.1 Thoughput=12.22 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 54449/88641, Loss=2.1576, lr=0.0000257 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 54499/88641, Loss=1.3076, lr=0.0000257 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 54549/88641, Loss=1.7657, lr=0.0000256 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 54599/88641, Loss=1.7771, lr=0.0000256 Time cost=4.2 Thoughput=11.87 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 54649/88641, Loss=1.8517, lr=0.0000256 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 54699/88641, Loss=1.7878, lr=0.0000256 Time cost=4.2 Thoughput=12.01 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 54749/88641, Loss=2.0707, lr=0.0000256 Time cost=4.1 Thoughput=12.08 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 54799/88641, Loss=1.7974, lr=0.0000256 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 54849/88641, Loss=1.3140, lr=0.0000256 Time cost=4.2 Thoughput=11.92 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 54899/88641, Loss=1.9341, lr=0.0000256 Time cost=4.1 Thoughput=12.18 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 54949/88641, Loss=1.4641, lr=0.0000256 Time cost=4.1 Thoughput=12.15 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 54999/88641, Loss=1.3219, lr=0.0000255 Time cost=4.1 Thoughput=12.09 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 55049/88641, Loss=2.0203, lr=0.0000255 Time cost=4.1 Thoughput=12.09 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 55099/88641, Loss=1.7468, lr=0.0000255 Time cost=4.1 Thoughput=12.08 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 55149/88641, Loss=1.8626, lr=0.0000255 Time cost=4.2 Thoughput=11.90 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 55199/88641, Loss=1.3335, lr=0.0000255 Time cost=4.2 Thoughput=11.90 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 55249/88641, Loss=1.6095, lr=0.0000255 Time cost=4.1 Thoughput=12.08 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 55299/88641, Loss=1.9620, lr=0.0000255 Time cost=4.1 Thoughput=12.19 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 55349/88641, Loss=1.2639, lr=0.0000255 Time cost=4.1 Thoughput=12.18 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 55399/88641, Loss=1.4091, lr=0.0000255 Time cost=4.1 Thoughput=12.14 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 55449/88641, Loss=1.8720, lr=0.0000255 Time cost=4.1 Thoughput=12.14 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 55499/88641, Loss=1.3639, lr=0.0000254 Time cost=4.1 Thoughput=12.19 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 55549/88641, Loss=1.5507, lr=0.0000254 Time cost=4.1 Thoughput=12.21 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 55599/88641, Loss=1.3148, lr=0.0000254 Time cost=4.1 Thoughput=12.29 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 55649/88641, Loss=1.7203, lr=0.0000254 Time cost=4.1 Thoughput=12.27 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 55699/88641, Loss=2.0078, lr=0.0000254 Time cost=4.1 Thoughput=12.28 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 55749/88641, Loss=1.6152, lr=0.0000254 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 55799/88641, Loss=2.1783, lr=0.0000254 Time cost=4.1 Thoughput=12.27 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 55849/88641, Loss=1.5152, lr=0.0000254 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 55899/88641, Loss=1.3841, lr=0.0000254 Time cost=4.1 Thoughput=12.20 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 55949/88641, Loss=2.2818, lr=0.0000253 Time cost=4.1 Thoughput=12.28 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 55999/88641, Loss=1.4345, lr=0.0000253 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 56049/88641, Loss=0.8357, lr=0.0000253 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 56099/88641, Loss=2.4549, lr=0.0000253 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 56149/88641, Loss=1.4042, lr=0.0000253 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 56199/88641, Loss=1.7545, lr=0.0000253 Time cost=4.1 Thoughput=12.28 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 56249/88641, Loss=1.7010, lr=0.0000253 Time cost=4.1 Thoughput=12.29 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 56299/88641, Loss=1.4513, lr=0.0000253 Time cost=4.6 Thoughput=10.93 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 56349/88641, Loss=2.1593, lr=0.0000253 Time cost=4.1 Thoughput=12.19 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 56399/88641, Loss=1.4470, lr=0.0000253 Time cost=4.1 Thoughput=12.22 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 56449/88641, Loss=1.5679, lr=0.0000252 Time cost=4.1 Thoughput=12.08 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 56499/88641, Loss=1.4205, lr=0.0000252 Time cost=4.1 Thoughput=12.18 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 56549/88641, Loss=1.6215, lr=0.0000252 Time cost=4.1 Thoughput=12.17 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 56599/88641, Loss=2.2626, lr=0.0000252 Time cost=4.1 Thoughput=12.20 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 56649/88641, Loss=1.6487, lr=0.0000252 Time cost=4.1 Thoughput=12.17 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 56699/88641, Loss=2.1063, lr=0.0000252 Time cost=4.1 Thoughput=12.21 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 56749/88641, Loss=1.7392, lr=0.0000252 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 56799/88641, Loss=1.4735, lr=0.0000252 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 56849/88641, Loss=1.7668, lr=0.0000252 Time cost=4.1 Thoughput=12.21 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 56899/88641, Loss=1.5743, lr=0.0000251 Time cost=4.1 Thoughput=12.21 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 56949/88641, Loss=1.6443, lr=0.0000251 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 56999/88641, Loss=1.6174, lr=0.0000251 Time cost=4.2 Thoughput=12.02 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 57049/88641, Loss=1.6262, lr=0.0000251 Time cost=4.2 Thoughput=11.80 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 57099/88641, Loss=1.6849, lr=0.0000251 Time cost=4.2 Thoughput=11.98 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 57149/88641, Loss=1.8366, lr=0.0000251 Time cost=4.2 Thoughput=12.01 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 57199/88641, Loss=1.5633, lr=0.0000251 Time cost=4.2 Thoughput=12.01 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 57249/88641, Loss=1.3038, lr=0.0000251 Time cost=4.2 Thoughput=12.00 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 57299/88641, Loss=1.6784, lr=0.0000251 Time cost=4.1 Thoughput=12.08 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 57349/88641, Loss=1.9776, lr=0.0000251 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 57399/88641, Loss=1.2229, lr=0.0000250 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 57449/88641, Loss=1.2553, lr=0.0000250 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 57499/88641, Loss=1.4831, lr=0.0000250 Time cost=4.2 Thoughput=12.01 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 57549/88641, Loss=1.8330, lr=0.0000250 Time cost=4.2 Thoughput=11.92 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 57599/88641, Loss=1.4305, lr=0.0000250 Time cost=4.1 Thoughput=12.19 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 57649/88641, Loss=1.7306, lr=0.0000250 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 57699/88641, Loss=1.4141, lr=0.0000250 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 57749/88641, Loss=1.3810, lr=0.0000250 Time cost=4.1 Thoughput=12.10 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 57799/88641, Loss=1.7983, lr=0.0000250 Time cost=4.1 Thoughput=12.10 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 57849/88641, Loss=1.8840, lr=0.0000250 Time cost=4.1 Thoughput=12.27 samples/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gluonnlp:Epoch: 1, Batch: 57899/88641, Loss=2.4120, lr=0.0000249 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 57949/88641, Loss=1.3040, lr=0.0000249 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 57999/88641, Loss=1.6165, lr=0.0000249 Time cost=4.1 Thoughput=12.19 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 58049/88641, Loss=1.6051, lr=0.0000249 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 58099/88641, Loss=1.4662, lr=0.0000249 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 58149/88641, Loss=1.8499, lr=0.0000249 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 58199/88641, Loss=1.8868, lr=0.0000249 Time cost=4.1 Thoughput=12.27 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 58249/88641, Loss=1.5480, lr=0.0000249 Time cost=4.1 Thoughput=12.28 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 58299/88641, Loss=2.2630, lr=0.0000249 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 58349/88641, Loss=1.3646, lr=0.0000248 Time cost=4.1 Thoughput=12.17 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 58399/88641, Loss=1.3326, lr=0.0000248 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 58449/88641, Loss=1.4239, lr=0.0000248 Time cost=4.1 Thoughput=12.28 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 58499/88641, Loss=1.6895, lr=0.0000248 Time cost=4.1 Thoughput=12.18 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 58549/88641, Loss=1.8554, lr=0.0000248 Time cost=4.1 Thoughput=12.11 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 58599/88641, Loss=1.5452, lr=0.0000248 Time cost=4.2 Thoughput=11.87 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 58649/88641, Loss=1.0540, lr=0.0000248 Time cost=4.1 Thoughput=12.14 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 58699/88641, Loss=1.1462, lr=0.0000248 Time cost=4.1 Thoughput=12.28 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 58749/88641, Loss=2.0461, lr=0.0000248 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 58799/88641, Loss=1.5657, lr=0.0000248 Time cost=4.1 Thoughput=12.22 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 58849/88641, Loss=1.5630, lr=0.0000247 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 58899/88641, Loss=1.4866, lr=0.0000247 Time cost=4.1 Thoughput=12.21 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 58949/88641, Loss=2.1592, lr=0.0000247 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 58999/88641, Loss=1.3943, lr=0.0000247 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 59049/88641, Loss=1.6964, lr=0.0000247 Time cost=4.1 Thoughput=12.17 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 59099/88641, Loss=1.1521, lr=0.0000247 Time cost=4.1 Thoughput=12.22 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 59149/88641, Loss=1.8261, lr=0.0000247 Time cost=4.1 Thoughput=12.21 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 59199/88641, Loss=2.0809, lr=0.0000247 Time cost=4.1 Thoughput=12.21 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 59249/88641, Loss=1.7239, lr=0.0000247 Time cost=4.2 Thoughput=11.88 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 59299/88641, Loss=1.8421, lr=0.0000246 Time cost=4.1 Thoughput=12.11 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 59349/88641, Loss=1.5460, lr=0.0000246 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 59399/88641, Loss=1.4921, lr=0.0000246 Time cost=4.1 Thoughput=12.20 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 59449/88641, Loss=1.5204, lr=0.0000246 Time cost=4.1 Thoughput=12.17 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 59499/88641, Loss=1.2968, lr=0.0000246 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 59549/88641, Loss=1.7793, lr=0.0000246 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 59599/88641, Loss=1.4800, lr=0.0000246 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 59649/88641, Loss=1.3673, lr=0.0000246 Time cost=4.1 Thoughput=12.22 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 59699/88641, Loss=2.4517, lr=0.0000246 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 59749/88641, Loss=2.0294, lr=0.0000246 Time cost=4.1 Thoughput=12.22 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 59799/88641, Loss=1.7910, lr=0.0000245 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 59849/88641, Loss=1.9385, lr=0.0000245 Time cost=4.1 Thoughput=12.22 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 59899/88641, Loss=1.3075, lr=0.0000245 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 59949/88641, Loss=1.1017, lr=0.0000245 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 59999/88641, Loss=1.8708, lr=0.0000245 Time cost=4.1 Thoughput=12.32 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 60049/88641, Loss=1.6685, lr=0.0000245 Time cost=4.1 Thoughput=12.27 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 60099/88641, Loss=1.4566, lr=0.0000245 Time cost=4.1 Thoughput=12.29 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 60149/88641, Loss=2.1973, lr=0.0000245 Time cost=4.6 Thoughput=10.88 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 60199/88641, Loss=1.6762, lr=0.0000245 Time cost=4.1 Thoughput=12.27 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 60249/88641, Loss=1.3278, lr=0.0000244 Time cost=4.1 Thoughput=12.29 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 60299/88641, Loss=1.8799, lr=0.0000244 Time cost=4.1 Thoughput=12.27 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 60349/88641, Loss=2.2129, lr=0.0000244 Time cost=4.1 Thoughput=12.27 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 60399/88641, Loss=1.5856, lr=0.0000244 Time cost=4.2 Thoughput=12.00 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 60449/88641, Loss=1.2722, lr=0.0000244 Time cost=4.1 Thoughput=12.20 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 60499/88641, Loss=1.8670, lr=0.0000244 Time cost=4.1 Thoughput=12.20 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 60549/88641, Loss=1.6505, lr=0.0000244 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 60599/88641, Loss=2.1744, lr=0.0000244 Time cost=4.1 Thoughput=12.21 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 60649/88641, Loss=1.8226, lr=0.0000244 Time cost=4.1 Thoughput=12.11 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 60699/88641, Loss=1.4670, lr=0.0000244 Time cost=4.1 Thoughput=12.11 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 60749/88641, Loss=1.3840, lr=0.0000243 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 60799/88641, Loss=1.3610, lr=0.0000243 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 60849/88641, Loss=1.1359, lr=0.0000243 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 60899/88641, Loss=1.5045, lr=0.0000243 Time cost=4.1 Thoughput=12.27 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 60949/88641, Loss=1.7500, lr=0.0000243 Time cost=4.1 Thoughput=12.31 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 60999/88641, Loss=1.4998, lr=0.0000243 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 61049/88641, Loss=1.7790, lr=0.0000243 Time cost=4.1 Thoughput=12.27 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 61099/88641, Loss=2.0050, lr=0.0000243 Time cost=4.1 Thoughput=12.21 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 61149/88641, Loss=1.4202, lr=0.0000243 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 61199/88641, Loss=1.0560, lr=0.0000243 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 61249/88641, Loss=1.7513, lr=0.0000242 Time cost=4.1 Thoughput=12.15 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 61299/88641, Loss=1.8016, lr=0.0000242 Time cost=4.1 Thoughput=12.22 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 61349/88641, Loss=1.4095, lr=0.0000242 Time cost=4.1 Thoughput=12.18 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 61399/88641, Loss=1.1859, lr=0.0000242 Time cost=4.2 Thoughput=12.02 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 61449/88641, Loss=1.0121, lr=0.0000242 Time cost=4.1 Thoughput=12.27 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 61499/88641, Loss=1.7305, lr=0.0000242 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 61549/88641, Loss=1.7805, lr=0.0000242 Time cost=4.1 Thoughput=12.21 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 61599/88641, Loss=1.9489, lr=0.0000242 Time cost=4.1 Thoughput=12.18 samples/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gluonnlp:Epoch: 1, Batch: 61649/88641, Loss=0.9391, lr=0.0000242 Time cost=4.1 Thoughput=12.22 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 61699/88641, Loss=1.3298, lr=0.0000241 Time cost=4.1 Thoughput=12.12 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 61749/88641, Loss=1.4386, lr=0.0000241 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 61799/88641, Loss=1.8105, lr=0.0000241 Time cost=4.2 Thoughput=12.03 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 61849/88641, Loss=1.0077, lr=0.0000241 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 61899/88641, Loss=1.3393, lr=0.0000241 Time cost=4.1 Thoughput=12.11 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 61949/88641, Loss=1.5552, lr=0.0000241 Time cost=4.2 Thoughput=11.77 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 61999/88641, Loss=1.4533, lr=0.0000241 Time cost=4.2 Thoughput=11.83 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 62049/88641, Loss=1.2557, lr=0.0000241 Time cost=4.2 Thoughput=11.98 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 62099/88641, Loss=1.6344, lr=0.0000241 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 62149/88641, Loss=1.6564, lr=0.0000241 Time cost=4.1 Thoughput=12.08 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 62199/88641, Loss=1.9244, lr=0.0000240 Time cost=4.1 Thoughput=12.19 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 62249/88641, Loss=1.7135, lr=0.0000240 Time cost=4.1 Thoughput=12.12 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 62299/88641, Loss=1.5269, lr=0.0000240 Time cost=4.1 Thoughput=12.11 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 62349/88641, Loss=1.4613, lr=0.0000240 Time cost=4.1 Thoughput=12.07 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 62399/88641, Loss=1.6625, lr=0.0000240 Time cost=4.1 Thoughput=12.15 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 62449/88641, Loss=2.2822, lr=0.0000240 Time cost=4.1 Thoughput=12.16 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 62499/88641, Loss=1.3650, lr=0.0000240 Time cost=4.1 Thoughput=12.20 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 62549/88641, Loss=1.7381, lr=0.0000240 Time cost=4.1 Thoughput=12.21 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 62599/88641, Loss=1.3182, lr=0.0000240 Time cost=4.1 Thoughput=12.20 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 62649/88641, Loss=2.0916, lr=0.0000239 Time cost=4.1 Thoughput=12.21 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 62699/88641, Loss=1.5562, lr=0.0000239 Time cost=4.1 Thoughput=12.21 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 62749/88641, Loss=1.3130, lr=0.0000239 Time cost=4.1 Thoughput=12.28 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 62799/88641, Loss=1.6585, lr=0.0000239 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 62849/88641, Loss=1.2874, lr=0.0000239 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 62899/88641, Loss=1.5062, lr=0.0000239 Time cost=4.6 Thoughput=10.91 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 62949/88641, Loss=2.1313, lr=0.0000239 Time cost=4.1 Thoughput=12.22 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 62999/88641, Loss=1.4830, lr=0.0000239 Time cost=4.1 Thoughput=12.20 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 63049/88641, Loss=1.5391, lr=0.0000239 Time cost=4.1 Thoughput=12.08 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 63099/88641, Loss=1.6639, lr=0.0000239 Time cost=4.1 Thoughput=12.06 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 63149/88641, Loss=1.2528, lr=0.0000238 Time cost=4.1 Thoughput=12.27 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 63199/88641, Loss=1.2289, lr=0.0000238 Time cost=4.1 Thoughput=12.29 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 63249/88641, Loss=1.3729, lr=0.0000238 Time cost=4.1 Thoughput=12.21 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 63299/88641, Loss=1.7132, lr=0.0000238 Time cost=4.1 Thoughput=12.22 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 63349/88641, Loss=1.8268, lr=0.0000238 Time cost=4.1 Thoughput=12.28 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 63399/88641, Loss=1.9607, lr=0.0000238 Time cost=4.1 Thoughput=12.27 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 63449/88641, Loss=2.3938, lr=0.0000238 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 63499/88641, Loss=1.4350, lr=0.0000238 Time cost=4.1 Thoughput=12.21 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 63549/88641, Loss=1.4240, lr=0.0000238 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 63599/88641, Loss=1.2773, lr=0.0000237 Time cost=4.2 Thoughput=12.00 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 63649/88641, Loss=1.3843, lr=0.0000237 Time cost=4.1 Thoughput=12.16 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 63699/88641, Loss=1.5990, lr=0.0000237 Time cost=4.1 Thoughput=12.21 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 63749/88641, Loss=1.4822, lr=0.0000237 Time cost=4.1 Thoughput=12.18 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 63799/88641, Loss=1.2848, lr=0.0000237 Time cost=4.1 Thoughput=12.18 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 63849/88641, Loss=1.6544, lr=0.0000237 Time cost=4.1 Thoughput=12.18 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 63899/88641, Loss=1.7213, lr=0.0000237 Time cost=4.1 Thoughput=12.18 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 63949/88641, Loss=1.4379, lr=0.0000237 Time cost=4.2 Thoughput=12.05 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 63999/88641, Loss=1.4380, lr=0.0000237 Time cost=4.2 Thoughput=11.95 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 64049/88641, Loss=1.4206, lr=0.0000237 Time cost=4.1 Thoughput=12.19 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 64099/88641, Loss=1.8430, lr=0.0000236 Time cost=4.1 Thoughput=12.20 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 64149/88641, Loss=1.7364, lr=0.0000236 Time cost=4.1 Thoughput=12.11 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 64199/88641, Loss=1.8489, lr=0.0000236 Time cost=4.1 Thoughput=12.16 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 64249/88641, Loss=1.9121, lr=0.0000236 Time cost=4.1 Thoughput=12.14 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 64299/88641, Loss=1.2011, lr=0.0000236 Time cost=4.1 Thoughput=12.16 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 64349/88641, Loss=1.9964, lr=0.0000236 Time cost=4.1 Thoughput=12.05 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 64399/88641, Loss=1.8272, lr=0.0000236 Time cost=4.1 Thoughput=12.20 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 64449/88641, Loss=1.4704, lr=0.0000236 Time cost=4.1 Thoughput=12.20 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 64499/88641, Loss=1.2850, lr=0.0000236 Time cost=4.1 Thoughput=12.22 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 64549/88641, Loss=1.5731, lr=0.0000236 Time cost=4.1 Thoughput=12.27 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 64599/88641, Loss=1.1164, lr=0.0000235 Time cost=4.1 Thoughput=12.32 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 64649/88641, Loss=1.3223, lr=0.0000235 Time cost=4.1 Thoughput=12.32 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 64699/88641, Loss=1.6716, lr=0.0000235 Time cost=4.1 Thoughput=12.31 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 64749/88641, Loss=1.4559, lr=0.0000235 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 64799/88641, Loss=1.2014, lr=0.0000235 Time cost=4.2 Thoughput=12.04 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 64849/88641, Loss=1.4684, lr=0.0000235 Time cost=4.2 Thoughput=12.00 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 64899/88641, Loss=1.7614, lr=0.0000235 Time cost=4.2 Thoughput=11.95 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 64949/88641, Loss=1.8655, lr=0.0000235 Time cost=4.1 Thoughput=12.13 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 64999/88641, Loss=1.6143, lr=0.0000235 Time cost=4.1 Thoughput=12.18 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 65049/88641, Loss=1.2674, lr=0.0000234 Time cost=4.1 Thoughput=12.18 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 65099/88641, Loss=1.4231, lr=0.0000234 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 65149/88641, Loss=1.5160, lr=0.0000234 Time cost=4.1 Thoughput=12.28 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 65199/88641, Loss=1.6080, lr=0.0000234 Time cost=4.1 Thoughput=12.28 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 65249/88641, Loss=1.7871, lr=0.0000234 Time cost=4.1 Thoughput=12.29 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 65299/88641, Loss=1.8278, lr=0.0000234 Time cost=4.1 Thoughput=12.29 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 65349/88641, Loss=1.6248, lr=0.0000234 Time cost=4.1 Thoughput=12.27 samples/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gluonnlp:Epoch: 1, Batch: 65399/88641, Loss=2.3966, lr=0.0000234 Time cost=4.1 Thoughput=12.28 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 65449/88641, Loss=1.9131, lr=0.0000234 Time cost=4.1 Thoughput=12.29 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 65499/88641, Loss=1.6839, lr=0.0000234 Time cost=4.1 Thoughput=12.30 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 65549/88641, Loss=1.4222, lr=0.0000233 Time cost=4.1 Thoughput=12.29 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 65599/88641, Loss=0.9255, lr=0.0000233 Time cost=4.1 Thoughput=12.17 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 65649/88641, Loss=1.4318, lr=0.0000233 Time cost=4.2 Thoughput=11.97 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 65699/88641, Loss=2.0611, lr=0.0000233 Time cost=4.2 Thoughput=11.99 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 65749/88641, Loss=1.2486, lr=0.0000233 Time cost=4.2 Thoughput=12.02 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 65799/88641, Loss=1.5025, lr=0.0000233 Time cost=4.2 Thoughput=11.95 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 65849/88641, Loss=1.6962, lr=0.0000233 Time cost=4.1 Thoughput=12.18 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 65899/88641, Loss=1.5678, lr=0.0000233 Time cost=4.1 Thoughput=12.20 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 65949/88641, Loss=1.7514, lr=0.0000233 Time cost=4.1 Thoughput=12.22 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 65999/88641, Loss=1.9634, lr=0.0000232 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 66049/88641, Loss=1.1042, lr=0.0000232 Time cost=4.3 Thoughput=11.71 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 66099/88641, Loss=1.4515, lr=0.0000232 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 66149/88641, Loss=1.2324, lr=0.0000232 Time cost=4.1 Thoughput=12.28 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 66199/88641, Loss=1.6680, lr=0.0000232 Time cost=4.1 Thoughput=12.27 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 66249/88641, Loss=1.5984, lr=0.0000232 Time cost=4.1 Thoughput=12.21 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 66299/88641, Loss=1.4963, lr=0.0000232 Time cost=4.2 Thoughput=12.03 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 66349/88641, Loss=1.5476, lr=0.0000232 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 66399/88641, Loss=1.7620, lr=0.0000232 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 66449/88641, Loss=1.5849, lr=0.0000232 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 66499/88641, Loss=1.6138, lr=0.0000231 Time cost=4.1 Thoughput=12.06 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 66549/88641, Loss=1.3280, lr=0.0000231 Time cost=4.1 Thoughput=12.18 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 66599/88641, Loss=1.1935, lr=0.0000231 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 66649/88641, Loss=1.6349, lr=0.0000231 Time cost=4.1 Thoughput=12.22 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 66699/88641, Loss=1.1404, lr=0.0000231 Time cost=4.1 Thoughput=12.28 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 66749/88641, Loss=2.2059, lr=0.0000231 Time cost=4.6 Thoughput=10.93 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 66799/88641, Loss=2.0567, lr=0.0000231 Time cost=4.1 Thoughput=12.19 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 66849/88641, Loss=1.2528, lr=0.0000231 Time cost=4.2 Thoughput=12.03 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 66899/88641, Loss=1.9532, lr=0.0000231 Time cost=4.1 Thoughput=12.13 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 66949/88641, Loss=1.3666, lr=0.0000231 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 66999/88641, Loss=1.6244, lr=0.0000230 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 67049/88641, Loss=2.0479, lr=0.0000230 Time cost=4.1 Thoughput=12.13 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 67099/88641, Loss=1.7540, lr=0.0000230 Time cost=4.1 Thoughput=12.16 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 67149/88641, Loss=1.6779, lr=0.0000230 Time cost=4.1 Thoughput=12.13 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 67199/88641, Loss=2.1020, lr=0.0000230 Time cost=4.2 Thoughput=11.97 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 67249/88641, Loss=1.6507, lr=0.0000230 Time cost=4.1 Thoughput=12.21 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 67299/88641, Loss=1.4682, lr=0.0000230 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 67349/88641, Loss=1.2209, lr=0.0000230 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 67399/88641, Loss=1.9123, lr=0.0000230 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 67449/88641, Loss=1.3021, lr=0.0000229 Time cost=4.1 Thoughput=12.21 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 67499/88641, Loss=1.2747, lr=0.0000229 Time cost=4.1 Thoughput=12.18 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 67549/88641, Loss=1.2878, lr=0.0000229 Time cost=4.1 Thoughput=12.21 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 67599/88641, Loss=1.2123, lr=0.0000229 Time cost=4.1 Thoughput=12.22 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 67649/88641, Loss=1.0349, lr=0.0000229 Time cost=4.1 Thoughput=12.20 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 67699/88641, Loss=1.5914, lr=0.0000229 Time cost=4.1 Thoughput=12.22 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 67749/88641, Loss=1.4084, lr=0.0000229 Time cost=4.1 Thoughput=12.22 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 67799/88641, Loss=1.3571, lr=0.0000229 Time cost=4.1 Thoughput=12.20 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 67849/88641, Loss=1.3907, lr=0.0000229 Time cost=4.2 Thoughput=12.00 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 67899/88641, Loss=1.7150, lr=0.0000229 Time cost=4.2 Thoughput=12.04 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 67949/88641, Loss=2.0805, lr=0.0000228 Time cost=4.1 Thoughput=12.21 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 67999/88641, Loss=2.3472, lr=0.0000228 Time cost=4.2 Thoughput=12.00 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 68049/88641, Loss=1.2377, lr=0.0000228 Time cost=4.2 Thoughput=12.02 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 68099/88641, Loss=1.9653, lr=0.0000228 Time cost=4.2 Thoughput=12.04 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 68149/88641, Loss=1.6590, lr=0.0000228 Time cost=4.1 Thoughput=12.22 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 68199/88641, Loss=1.2356, lr=0.0000228 Time cost=4.1 Thoughput=12.27 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 68249/88641, Loss=1.7906, lr=0.0000228 Time cost=4.1 Thoughput=12.22 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 68299/88641, Loss=1.6608, lr=0.0000228 Time cost=4.1 Thoughput=12.20 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 68349/88641, Loss=1.5261, lr=0.0000228 Time cost=4.1 Thoughput=12.15 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 68399/88641, Loss=2.0241, lr=0.0000227 Time cost=4.1 Thoughput=12.16 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 68449/88641, Loss=1.4795, lr=0.0000227 Time cost=4.1 Thoughput=12.16 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 68499/88641, Loss=1.3346, lr=0.0000227 Time cost=4.1 Thoughput=12.19 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 68549/88641, Loss=1.7903, lr=0.0000227 Time cost=4.1 Thoughput=12.15 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 68599/88641, Loss=1.3308, lr=0.0000227 Time cost=4.1 Thoughput=12.17 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 68649/88641, Loss=1.0538, lr=0.0000227 Time cost=4.1 Thoughput=12.07 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 68699/88641, Loss=1.3458, lr=0.0000227 Time cost=4.1 Thoughput=12.15 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 68749/88641, Loss=1.9415, lr=0.0000227 Time cost=4.1 Thoughput=12.19 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 68799/88641, Loss=1.8531, lr=0.0000227 Time cost=4.2 Thoughput=12.04 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 68849/88641, Loss=1.3387, lr=0.0000227 Time cost=4.1 Thoughput=12.11 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 68899/88641, Loss=1.5721, lr=0.0000226 Time cost=4.1 Thoughput=12.20 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 68949/88641, Loss=1.3002, lr=0.0000226 Time cost=4.1 Thoughput=12.10 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 68999/88641, Loss=1.8211, lr=0.0000226 Time cost=4.1 Thoughput=12.17 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 69049/88641, Loss=1.5459, lr=0.0000226 Time cost=4.2 Thoughput=12.01 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 69099/88641, Loss=1.7874, lr=0.0000226 Time cost=4.1 Thoughput=12.25 samples/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gluonnlp:Epoch: 1, Batch: 69149/88641, Loss=1.6482, lr=0.0000226 Time cost=4.1 Thoughput=12.27 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 69199/88641, Loss=1.5573, lr=0.0000226 Time cost=4.1 Thoughput=12.15 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 69249/88641, Loss=2.0132, lr=0.0000226 Time cost=4.2 Thoughput=12.03 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 69299/88641, Loss=1.8906, lr=0.0000226 Time cost=4.1 Thoughput=12.27 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 69349/88641, Loss=1.8081, lr=0.0000225 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 69399/88641, Loss=2.0015, lr=0.0000225 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 69449/88641, Loss=1.1883, lr=0.0000225 Time cost=4.6 Thoughput=10.94 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 69499/88641, Loss=1.3868, lr=0.0000225 Time cost=4.1 Thoughput=12.21 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 69549/88641, Loss=1.7349, lr=0.0000225 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 69599/88641, Loss=1.3064, lr=0.0000225 Time cost=4.1 Thoughput=12.22 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 69649/88641, Loss=1.7472, lr=0.0000225 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 69699/88641, Loss=1.4703, lr=0.0000225 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 69749/88641, Loss=2.0789, lr=0.0000225 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 69799/88641, Loss=0.8895, lr=0.0000225 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 69849/88641, Loss=1.3962, lr=0.0000224 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 69899/88641, Loss=1.4665, lr=0.0000224 Time cost=4.1 Thoughput=12.18 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 69949/88641, Loss=1.2578, lr=0.0000224 Time cost=4.1 Thoughput=12.19 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 69999/88641, Loss=1.1927, lr=0.0000224 Time cost=4.1 Thoughput=12.16 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 70049/88641, Loss=1.6397, lr=0.0000224 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 70099/88641, Loss=1.2197, lr=0.0000224 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 70149/88641, Loss=1.7156, lr=0.0000224 Time cost=4.2 Thoughput=11.83 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 70199/88641, Loss=2.1800, lr=0.0000224 Time cost=4.1 Thoughput=12.22 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 70249/88641, Loss=1.2150, lr=0.0000224 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 70299/88641, Loss=1.0540, lr=0.0000224 Time cost=4.1 Thoughput=12.22 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 70349/88641, Loss=1.7969, lr=0.0000223 Time cost=4.1 Thoughput=12.20 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 70399/88641, Loss=1.1776, lr=0.0000223 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 70449/88641, Loss=1.7229, lr=0.0000223 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 70499/88641, Loss=1.9099, lr=0.0000223 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 70549/88641, Loss=1.7001, lr=0.0000223 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 70599/88641, Loss=1.4021, lr=0.0000223 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 70649/88641, Loss=2.0430, lr=0.0000223 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 70699/88641, Loss=1.8441, lr=0.0000223 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 70749/88641, Loss=1.6127, lr=0.0000223 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 70799/88641, Loss=1.2451, lr=0.0000222 Time cost=4.1 Thoughput=12.21 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 70849/88641, Loss=1.3876, lr=0.0000222 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 70899/88641, Loss=1.7170, lr=0.0000222 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 70949/88641, Loss=1.3260, lr=0.0000222 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 70999/88641, Loss=1.6820, lr=0.0000222 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 71049/88641, Loss=1.5467, lr=0.0000222 Time cost=4.1 Thoughput=12.27 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 71099/88641, Loss=1.2241, lr=0.0000222 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 71149/88641, Loss=1.6808, lr=0.0000222 Time cost=4.1 Thoughput=12.17 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 71199/88641, Loss=0.8222, lr=0.0000222 Time cost=4.2 Thoughput=12.03 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 71249/88641, Loss=1.7008, lr=0.0000222 Time cost=4.2 Thoughput=12.04 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 71299/88641, Loss=1.1859, lr=0.0000221 Time cost=4.1 Thoughput=12.18 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 71349/88641, Loss=1.7765, lr=0.0000221 Time cost=4.1 Thoughput=12.19 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 71399/88641, Loss=1.0176, lr=0.0000221 Time cost=4.1 Thoughput=12.27 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 71449/88641, Loss=1.6686, lr=0.0000221 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 71499/88641, Loss=1.9637, lr=0.0000221 Time cost=4.1 Thoughput=12.17 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 71549/88641, Loss=1.4563, lr=0.0000221 Time cost=4.1 Thoughput=12.06 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 71599/88641, Loss=1.4325, lr=0.0000221 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 71649/88641, Loss=1.6258, lr=0.0000221 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 71699/88641, Loss=1.8654, lr=0.0000221 Time cost=4.1 Thoughput=12.27 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 71749/88641, Loss=1.5321, lr=0.0000220 Time cost=4.1 Thoughput=12.19 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 71799/88641, Loss=1.1977, lr=0.0000220 Time cost=4.1 Thoughput=12.19 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 71849/88641, Loss=2.0127, lr=0.0000220 Time cost=4.1 Thoughput=12.17 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 71899/88641, Loss=2.0132, lr=0.0000220 Time cost=4.1 Thoughput=12.21 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 71949/88641, Loss=1.2355, lr=0.0000220 Time cost=4.1 Thoughput=12.18 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 71999/88641, Loss=1.8106, lr=0.0000220 Time cost=4.1 Thoughput=12.21 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 72049/88641, Loss=1.6028, lr=0.0000220 Time cost=4.1 Thoughput=12.22 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 72099/88641, Loss=1.4516, lr=0.0000220 Time cost=4.1 Thoughput=12.09 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 72149/88641, Loss=0.7003, lr=0.0000220 Time cost=4.1 Thoughput=12.20 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 72199/88641, Loss=1.5920, lr=0.0000220 Time cost=4.1 Thoughput=12.18 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 72249/88641, Loss=1.7041, lr=0.0000219 Time cost=4.1 Thoughput=12.16 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 72299/88641, Loss=1.5522, lr=0.0000219 Time cost=4.1 Thoughput=12.17 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 72349/88641, Loss=1.7750, lr=0.0000219 Time cost=4.2 Thoughput=11.91 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 72399/88641, Loss=1.6690, lr=0.0000219 Time cost=4.2 Thoughput=11.79 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 72449/88641, Loss=1.4703, lr=0.0000219 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 72499/88641, Loss=2.1018, lr=0.0000219 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 72549/88641, Loss=1.4512, lr=0.0000219 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 72599/88641, Loss=1.4266, lr=0.0000219 Time cost=4.2 Thoughput=11.97 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 72649/88641, Loss=1.4590, lr=0.0000219 Time cost=4.1 Thoughput=12.05 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 72699/88641, Loss=1.4937, lr=0.0000218 Time cost=4.2 Thoughput=11.84 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 72749/88641, Loss=1.0984, lr=0.0000218 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 72799/88641, Loss=2.0312, lr=0.0000218 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 72849/88641, Loss=1.9328, lr=0.0000218 Time cost=4.1 Thoughput=12.22 samples/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gluonnlp:Epoch: 1, Batch: 72899/88641, Loss=1.5161, lr=0.0000218 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 72949/88641, Loss=1.9171, lr=0.0000218 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 72999/88641, Loss=1.3566, lr=0.0000218 Time cost=4.1 Thoughput=12.20 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 73049/88641, Loss=1.6701, lr=0.0000218 Time cost=4.1 Thoughput=12.15 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 73099/88641, Loss=1.6624, lr=0.0000218 Time cost=4.1 Thoughput=12.20 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 73149/88641, Loss=1.5490, lr=0.0000218 Time cost=4.1 Thoughput=12.14 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 73199/88641, Loss=1.1134, lr=0.0000217 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 73249/88641, Loss=1.3910, lr=0.0000217 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 73299/88641, Loss=1.6503, lr=0.0000217 Time cost=4.6 Thoughput=10.90 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 73349/88641, Loss=1.5392, lr=0.0000217 Time cost=4.1 Thoughput=12.09 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 73399/88641, Loss=1.7824, lr=0.0000217 Time cost=4.1 Thoughput=12.09 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 73449/88641, Loss=1.9329, lr=0.0000217 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 73499/88641, Loss=1.1613, lr=0.0000217 Time cost=4.1 Thoughput=12.17 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 73549/88641, Loss=1.4953, lr=0.0000217 Time cost=4.1 Thoughput=12.17 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 73599/88641, Loss=1.6327, lr=0.0000217 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 73649/88641, Loss=2.0502, lr=0.0000217 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 73699/88641, Loss=1.6888, lr=0.0000216 Time cost=4.1 Thoughput=12.12 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 73749/88641, Loss=1.4832, lr=0.0000216 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 73799/88641, Loss=1.6807, lr=0.0000216 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 73849/88641, Loss=1.6883, lr=0.0000216 Time cost=4.1 Thoughput=12.21 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 73899/88641, Loss=1.3913, lr=0.0000216 Time cost=4.1 Thoughput=12.19 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 73949/88641, Loss=1.5839, lr=0.0000216 Time cost=4.1 Thoughput=12.14 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 73999/88641, Loss=1.8832, lr=0.0000216 Time cost=4.1 Thoughput=12.18 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 74049/88641, Loss=2.0362, lr=0.0000216 Time cost=4.1 Thoughput=12.16 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 74099/88641, Loss=1.5334, lr=0.0000216 Time cost=4.2 Thoughput=11.95 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 74149/88641, Loss=1.9662, lr=0.0000215 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 74199/88641, Loss=1.3444, lr=0.0000215 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 74249/88641, Loss=2.0151, lr=0.0000215 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 74299/88641, Loss=1.4801, lr=0.0000215 Time cost=4.1 Thoughput=12.10 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 74349/88641, Loss=1.8299, lr=0.0000215 Time cost=4.1 Thoughput=12.22 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 74399/88641, Loss=1.7753, lr=0.0000215 Time cost=4.1 Thoughput=12.15 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 74449/88641, Loss=1.8311, lr=0.0000215 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 74499/88641, Loss=1.1257, lr=0.0000215 Time cost=4.1 Thoughput=12.15 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 74549/88641, Loss=1.8970, lr=0.0000215 Time cost=4.2 Thoughput=11.93 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 74599/88641, Loss=1.8206, lr=0.0000215 Time cost=4.2 Thoughput=11.92 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 74649/88641, Loss=1.8085, lr=0.0000214 Time cost=4.2 Thoughput=11.98 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 74699/88641, Loss=1.6423, lr=0.0000214 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 74749/88641, Loss=1.2460, lr=0.0000214 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 74799/88641, Loss=1.5085, lr=0.0000214 Time cost=4.1 Thoughput=12.22 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 74849/88641, Loss=1.2152, lr=0.0000214 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 74899/88641, Loss=1.7577, lr=0.0000214 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 74949/88641, Loss=1.4341, lr=0.0000214 Time cost=4.1 Thoughput=12.13 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 74999/88641, Loss=1.5884, lr=0.0000214 Time cost=4.2 Thoughput=11.95 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 75049/88641, Loss=1.8075, lr=0.0000214 Time cost=4.2 Thoughput=11.96 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 75099/88641, Loss=1.7000, lr=0.0000213 Time cost=4.2 Thoughput=11.93 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 75149/88641, Loss=1.6724, lr=0.0000213 Time cost=4.2 Thoughput=11.97 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 75199/88641, Loss=2.0975, lr=0.0000213 Time cost=4.2 Thoughput=11.98 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 75249/88641, Loss=1.4482, lr=0.0000213 Time cost=4.2 Thoughput=11.98 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 75299/88641, Loss=1.4655, lr=0.0000213 Time cost=4.2 Thoughput=11.97 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 75349/88641, Loss=1.3798, lr=0.0000213 Time cost=4.1 Thoughput=12.07 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 75399/88641, Loss=1.4798, lr=0.0000213 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 75449/88641, Loss=1.0813, lr=0.0000213 Time cost=4.2 Thoughput=11.88 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 75499/88641, Loss=1.7986, lr=0.0000213 Time cost=4.2 Thoughput=12.01 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 75549/88641, Loss=1.4601, lr=0.0000213 Time cost=4.2 Thoughput=12.00 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 75599/88641, Loss=1.3661, lr=0.0000212 Time cost=4.1 Thoughput=12.18 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 75649/88641, Loss=2.1079, lr=0.0000212 Time cost=4.1 Thoughput=12.19 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 75699/88641, Loss=1.4589, lr=0.0000212 Time cost=4.2 Thoughput=12.02 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 75749/88641, Loss=0.9834, lr=0.0000212 Time cost=4.2 Thoughput=12.02 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 75799/88641, Loss=1.5527, lr=0.0000212 Time cost=4.1 Thoughput=12.08 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 75849/88641, Loss=1.2622, lr=0.0000212 Time cost=4.2 Thoughput=11.93 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 75899/88641, Loss=1.7596, lr=0.0000212 Time cost=4.1 Thoughput=12.06 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 75949/88641, Loss=1.8976, lr=0.0000212 Time cost=4.1 Thoughput=12.17 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 75999/88641, Loss=1.8435, lr=0.0000212 Time cost=4.7 Thoughput=10.72 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 76049/88641, Loss=1.5411, lr=0.0000211 Time cost=4.2 Thoughput=11.99 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 76099/88641, Loss=1.6646, lr=0.0000211 Time cost=4.2 Thoughput=12.01 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 76149/88641, Loss=1.2161, lr=0.0000211 Time cost=4.2 Thoughput=12.01 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 76199/88641, Loss=1.4128, lr=0.0000211 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 76249/88641, Loss=1.3750, lr=0.0000211 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 76299/88641, Loss=1.8963, lr=0.0000211 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 76349/88641, Loss=1.2667, lr=0.0000211 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 76399/88641, Loss=1.2984, lr=0.0000211 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 76449/88641, Loss=1.5765, lr=0.0000211 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 76499/88641, Loss=1.5833, lr=0.0000211 Time cost=4.2 Thoughput=11.97 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 76549/88641, Loss=1.8531, lr=0.0000210 Time cost=4.2 Thoughput=11.97 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 76599/88641, Loss=1.5092, lr=0.0000210 Time cost=4.2 Thoughput=12.03 samples/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gluonnlp:Epoch: 1, Batch: 76649/88641, Loss=1.2488, lr=0.0000210 Time cost=4.2 Thoughput=12.04 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 76699/88641, Loss=1.2278, lr=0.0000210 Time cost=4.5 Thoughput=11.20 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 76749/88641, Loss=1.2164, lr=0.0000210 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 76799/88641, Loss=1.7373, lr=0.0000210 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 76849/88641, Loss=1.8412, lr=0.0000210 Time cost=4.1 Thoughput=12.14 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 76899/88641, Loss=1.2768, lr=0.0000210 Time cost=4.2 Thoughput=12.00 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 76949/88641, Loss=1.5269, lr=0.0000210 Time cost=4.2 Thoughput=12.02 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 76999/88641, Loss=1.5091, lr=0.0000210 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 77049/88641, Loss=1.3345, lr=0.0000209 Time cost=4.1 Thoughput=12.11 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 77099/88641, Loss=1.8744, lr=0.0000209 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 77149/88641, Loss=1.9378, lr=0.0000209 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 77199/88641, Loss=1.6421, lr=0.0000209 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 77249/88641, Loss=1.7883, lr=0.0000209 Time cost=4.1 Thoughput=12.22 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 77299/88641, Loss=1.5881, lr=0.0000209 Time cost=4.1 Thoughput=12.08 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 77349/88641, Loss=1.0782, lr=0.0000209 Time cost=4.1 Thoughput=12.12 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 77399/88641, Loss=1.6726, lr=0.0000209 Time cost=4.1 Thoughput=12.27 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 77449/88641, Loss=1.7298, lr=0.0000209 Time cost=4.2 Thoughput=12.04 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 77499/88641, Loss=1.8077, lr=0.0000208 Time cost=4.1 Thoughput=12.22 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 77549/88641, Loss=1.4606, lr=0.0000208 Time cost=4.1 Thoughput=12.09 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 77599/88641, Loss=1.7416, lr=0.0000208 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 77649/88641, Loss=1.6735, lr=0.0000208 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 77699/88641, Loss=1.8198, lr=0.0000208 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 77749/88641, Loss=1.6735, lr=0.0000208 Time cost=4.1 Thoughput=12.17 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 77799/88641, Loss=1.6379, lr=0.0000208 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 77849/88641, Loss=1.4381, lr=0.0000208 Time cost=4.1 Thoughput=12.20 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 77899/88641, Loss=1.5751, lr=0.0000208 Time cost=4.2 Thoughput=11.97 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 77949/88641, Loss=1.4667, lr=0.0000208 Time cost=4.2 Thoughput=11.83 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 77999/88641, Loss=1.1453, lr=0.0000207 Time cost=4.2 Thoughput=12.02 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 78049/88641, Loss=2.1538, lr=0.0000207 Time cost=4.1 Thoughput=12.11 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 78099/88641, Loss=1.3751, lr=0.0000207 Time cost=4.1 Thoughput=12.22 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 78149/88641, Loss=1.7569, lr=0.0000207 Time cost=4.1 Thoughput=12.22 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 78199/88641, Loss=1.6606, lr=0.0000207 Time cost=4.1 Thoughput=12.20 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 78249/88641, Loss=1.3722, lr=0.0000207 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 78299/88641, Loss=1.0533, lr=0.0000207 Time cost=4.1 Thoughput=12.22 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 78349/88641, Loss=1.7309, lr=0.0000207 Time cost=4.1 Thoughput=12.21 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 78399/88641, Loss=1.7803, lr=0.0000207 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 78449/88641, Loss=1.1796, lr=0.0000206 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 78499/88641, Loss=1.6132, lr=0.0000206 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 78549/88641, Loss=1.3760, lr=0.0000206 Time cost=4.1 Thoughput=12.13 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 78599/88641, Loss=1.1252, lr=0.0000206 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 78649/88641, Loss=1.3323, lr=0.0000206 Time cost=4.1 Thoughput=12.20 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 78699/88641, Loss=1.3536, lr=0.0000206 Time cost=4.2 Thoughput=11.98 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 78749/88641, Loss=1.2877, lr=0.0000206 Time cost=4.1 Thoughput=12.09 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 78799/88641, Loss=1.0099, lr=0.0000206 Time cost=4.1 Thoughput=12.27 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 78849/88641, Loss=1.7430, lr=0.0000206 Time cost=4.1 Thoughput=12.20 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 78899/88641, Loss=1.4811, lr=0.0000206 Time cost=4.2 Thoughput=11.85 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 78949/88641, Loss=1.3595, lr=0.0000205 Time cost=4.1 Thoughput=12.06 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 78999/88641, Loss=1.8835, lr=0.0000205 Time cost=4.2 Thoughput=11.99 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 79049/88641, Loss=1.1538, lr=0.0000205 Time cost=4.2 Thoughput=11.97 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 79099/88641, Loss=1.8224, lr=0.0000205 Time cost=4.2 Thoughput=11.96 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 79149/88641, Loss=0.9021, lr=0.0000205 Time cost=4.1 Thoughput=12.11 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 79199/88641, Loss=1.2286, lr=0.0000205 Time cost=4.1 Thoughput=12.20 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 79249/88641, Loss=1.2020, lr=0.0000205 Time cost=4.1 Thoughput=12.11 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 79299/88641, Loss=1.5576, lr=0.0000205 Time cost=4.2 Thoughput=12.01 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 79349/88641, Loss=1.9161, lr=0.0000205 Time cost=4.2 Thoughput=11.99 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 79399/88641, Loss=1.6777, lr=0.0000204 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 79449/88641, Loss=1.8491, lr=0.0000204 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 79499/88641, Loss=1.6939, lr=0.0000204 Time cost=4.1 Thoughput=12.27 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 79549/88641, Loss=1.3926, lr=0.0000204 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 79599/88641, Loss=1.5431, lr=0.0000204 Time cost=4.1 Thoughput=12.28 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 79649/88641, Loss=1.8633, lr=0.0000204 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 79699/88641, Loss=1.2612, lr=0.0000204 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 79749/88641, Loss=1.5719, lr=0.0000204 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 79799/88641, Loss=1.5679, lr=0.0000204 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 79849/88641, Loss=1.4912, lr=0.0000204 Time cost=4.6 Thoughput=10.87 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 79899/88641, Loss=1.2211, lr=0.0000203 Time cost=4.1 Thoughput=12.22 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 79949/88641, Loss=1.6424, lr=0.0000203 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 79999/88641, Loss=0.6817, lr=0.0000203 Time cost=4.1 Thoughput=12.27 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 80049/88641, Loss=1.9575, lr=0.0000203 Time cost=4.1 Thoughput=12.28 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 80099/88641, Loss=2.0129, lr=0.0000203 Time cost=4.1 Thoughput=12.27 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 80149/88641, Loss=1.6340, lr=0.0000203 Time cost=4.1 Thoughput=12.13 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 80199/88641, Loss=1.4390, lr=0.0000203 Time cost=4.2 Thoughput=12.00 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 80249/88641, Loss=2.2709, lr=0.0000203 Time cost=4.2 Thoughput=11.99 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 80299/88641, Loss=1.5152, lr=0.0000203 Time cost=4.1 Thoughput=12.11 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 80349/88641, Loss=1.0952, lr=0.0000203 Time cost=4.1 Thoughput=12.26 samples/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gluonnlp:Epoch: 1, Batch: 80399/88641, Loss=1.2037, lr=0.0000202 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 80449/88641, Loss=1.4740, lr=0.0000202 Time cost=4.1 Thoughput=12.19 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 80499/88641, Loss=1.7257, lr=0.0000202 Time cost=4.2 Thoughput=12.04 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 80549/88641, Loss=1.5663, lr=0.0000202 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 80599/88641, Loss=1.6288, lr=0.0000202 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 80649/88641, Loss=1.5895, lr=0.0000202 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 80699/88641, Loss=1.7532, lr=0.0000202 Time cost=4.1 Thoughput=12.21 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 80749/88641, Loss=1.3047, lr=0.0000202 Time cost=4.1 Thoughput=12.22 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 80799/88641, Loss=1.6022, lr=0.0000202 Time cost=4.3 Thoughput=11.70 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 80849/88641, Loss=1.5722, lr=0.0000201 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 80899/88641, Loss=1.2796, lr=0.0000201 Time cost=4.1 Thoughput=12.20 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 80949/88641, Loss=1.5948, lr=0.0000201 Time cost=4.1 Thoughput=12.19 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 80999/88641, Loss=1.6318, lr=0.0000201 Time cost=4.1 Thoughput=12.15 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 81049/88641, Loss=1.4772, lr=0.0000201 Time cost=4.2 Thoughput=11.93 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 81099/88641, Loss=1.7591, lr=0.0000201 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 81149/88641, Loss=1.5670, lr=0.0000201 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 81199/88641, Loss=1.2387, lr=0.0000201 Time cost=4.1 Thoughput=12.27 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 81249/88641, Loss=1.3012, lr=0.0000201 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 81299/88641, Loss=1.6329, lr=0.0000201 Time cost=4.1 Thoughput=12.27 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 81349/88641, Loss=1.1280, lr=0.0000200 Time cost=4.1 Thoughput=12.25 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 81399/88641, Loss=1.3618, lr=0.0000200 Time cost=4.1 Thoughput=12.08 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 81449/88641, Loss=1.6345, lr=0.0000200 Time cost=4.2 Thoughput=11.90 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 81499/88641, Loss=1.5391, lr=0.0000200 Time cost=4.1 Thoughput=12.10 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 81549/88641, Loss=1.5634, lr=0.0000200 Time cost=4.2 Thoughput=11.94 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 81599/88641, Loss=1.6447, lr=0.0000200 Time cost=4.1 Thoughput=12.07 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 81649/88641, Loss=1.6838, lr=0.0000200 Time cost=4.1 Thoughput=12.20 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 81699/88641, Loss=2.2238, lr=0.0000200 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 81749/88641, Loss=1.1466, lr=0.0000200 Time cost=4.1 Thoughput=12.18 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 81799/88641, Loss=2.1927, lr=0.0000199 Time cost=4.1 Thoughput=12.08 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 81849/88641, Loss=1.0130, lr=0.0000199 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 81899/88641, Loss=1.6372, lr=0.0000199 Time cost=4.1 Thoughput=12.27 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 81949/88641, Loss=1.7540, lr=0.0000199 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 81999/88641, Loss=1.6504, lr=0.0000199 Time cost=4.4 Thoughput=11.39 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 82049/88641, Loss=1.4246, lr=0.0000199 Time cost=4.1 Thoughput=12.07 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 82099/88641, Loss=1.6736, lr=0.0000199 Time cost=4.2 Thoughput=12.03 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 82149/88641, Loss=1.6361, lr=0.0000199 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 82199/88641, Loss=1.2832, lr=0.0000199 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 82249/88641, Loss=1.4051, lr=0.0000199 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 82299/88641, Loss=1.9429, lr=0.0000198 Time cost=4.1 Thoughput=12.23 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 82349/88641, Loss=1.3164, lr=0.0000198 Time cost=4.1 Thoughput=12.22 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 82399/88641, Loss=1.4778, lr=0.0000198 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 82449/88641, Loss=1.9400, lr=0.0000198 Time cost=4.1 Thoughput=12.24 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 82499/88641, Loss=1.4926, lr=0.0000198 Time cost=4.1 Thoughput=12.26 samples/s\n",
      "INFO:gluonnlp:Epoch: 1, Batch: 82549/88641, Loss=1.4897, lr=0.0000198 Time cost=4.6 Thoughput=10.90 samples/s\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def train(log, train_data_transform, train_dataloader):\n",
    "    \"\"\"Training function.\"\"\"\n",
    "\n",
    "    log.info('Start Training')\n",
    "\n",
    "    optimizer_params = {'learning_rate': lr}\n",
    "    trainer = mx.gluon.Trainer(net.collect_params(), optimizer,\n",
    "                               optimizer_params, update_on_kvstore=False)\n",
    "\n",
    "    num_train_examples = len(train_data_transform)\n",
    "    step_size = batch_size * accumulate if accumulate else batch_size\n",
    "    num_train_steps = int(num_train_examples / step_size * epochs)\n",
    "    num_warmup_steps = int(num_train_steps * warmup_ratio)\n",
    "    step_num = 0\n",
    "    \n",
    "    def set_new_lr(step_num, batch_id):\n",
    "        \"\"\"set new learning rate\"\"\"\n",
    "        # set grad to zero for gradient accumulation\n",
    "        if accumulate:\n",
    "            if batch_id % accumulate == 0:\n",
    "                net.collect_params().zero_grad()\n",
    "                step_num += 1\n",
    "        else:\n",
    "            step_num += 1\n",
    "        # learning rate schedule\n",
    "        # Notice that this learning rate scheduler is adapted from traditional linear learning\n",
    "        # rate scheduler where step_num >= num_warmup_steps, new_lr = 1 - step_num/num_train_steps\n",
    "        if step_num < num_warmup_steps:\n",
    "            new_lr = lr * step_num / num_warmup_steps\n",
    "        else:\n",
    "            offset = (step_num - num_warmup_steps) * lr / \\\n",
    "                (num_train_steps - num_warmup_steps)\n",
    "            new_lr = lr - offset\n",
    "        trainer.set_learning_rate(new_lr)\n",
    "        return step_num\n",
    "\n",
    "    # Do not apply weight decay on LayerNorm and bias terms\n",
    "    for _, v in net.collect_params('.*beta|.*gamma|.*bias').items():\n",
    "        v.wd_mult = 0.0\n",
    "    # Collect differentiable parameters\n",
    "    params = [p for p in net.collect_params().values()\n",
    "              if p.grad_req != 'null']\n",
    "    # Set grad_req if gradient accumulation is required\n",
    "    if accumulate:\n",
    "        for p in params:\n",
    "            p.grad_req = 'add'\n",
    "\n",
    "    epoch_tic = time.time()\n",
    "    total_num = 0\n",
    "    log_num = 0\n",
    "    for epoch_id in range(epochs):\n",
    "        step_loss = 0.0\n",
    "        tic = time.time()\n",
    "        for batch_id, data in enumerate(train_dataloader):\n",
    "            # set new lr\n",
    "            step_num = set_new_lr(step_num, batch_id)\n",
    "            # forward and backward\n",
    "            with mx.autograd.record():\n",
    "                _, inputs, token_types, valid_length, start_label, end_label = data\n",
    "\n",
    "                log_num += len(inputs)\n",
    "                total_num += len(inputs)\n",
    "\n",
    "                out = net(inputs.astype('float32').as_in_context(ctx),\n",
    "                          token_types.astype('float32').as_in_context(ctx),\n",
    "                          valid_length.astype('float32').as_in_context(ctx))\n",
    "\n",
    "                ls = loss_function(out, [\n",
    "                    start_label.astype('float32').as_in_context(ctx),\n",
    "                    end_label.astype('float32').as_in_context(ctx)]).mean()\n",
    "\n",
    "                if accumulate:\n",
    "                    ls = ls / accumulate\n",
    "            ls.backward()\n",
    "            # update\n",
    "            if not accumulate or (batch_id + 1) % accumulate == 0:\n",
    "                trainer.allreduce_grads()\n",
    "                nlp.utils.clip_grad_global_norm(params, 1)\n",
    "                trainer.update(1)\n",
    "\n",
    "            step_loss += ls.asscalar()\n",
    "        \n",
    "#         for batch_id, data in enumerate(train_dataloader):\n",
    "#             # set new lr\n",
    "#             step_num = set_new_lr(step_num, batch_id)\n",
    "#             # forward and backward\n",
    "# #             with mx.autograd.record():\n",
    "#             _, inputs, token_types, valid_length, start_label, end_label = data\n",
    "\n",
    "#             log_num += len(inputs)\n",
    "#             total_num += len(inputs)\n",
    "\n",
    "#             def split_and_load(data, ctx):\n",
    "#                 n, k = data.shape[0], len(ctx)\n",
    "#                 print(n, k)\n",
    "#                 if (n//k)*k != n:\n",
    "#                     drop = n - (n//k)*k\n",
    "#                     data = data[:-drop]\n",
    "#                     n, k = data.shape[0], len(ctx)\n",
    "#                 assert (n//k)*k == n, '# examples is not divided by # devices'\n",
    "#                 idx = list(range(0, n+1, n//k))\n",
    "#                 return [data[idx[i]:idx[i+1]].as_in_context(ctx[i]) for i in range(k)]\n",
    "            \n",
    "# #                 def train_batch(inputs, params, ctx, lr):\n",
    "#                     # split the data batch and load them on GPUs\n",
    "#             print(len(inputs[0]), len(token_types[0]), len(valid_length[0]), len(start_label[0]), len(end_label[0]))\n",
    "#             inputs = split_and_load(inputs[0], ctx)\n",
    "#             token_types = split_and_load(token_types[0], ctx)\n",
    "# #             valid_length = split_and_load(valid_length, ctx)\n",
    "# #             start_label = split_and_load(start_label[0], ctx)\n",
    "# #             end_label = split_and_load(end_label[0], ctx)\n",
    "\n",
    "#             # run forward on each GPU\n",
    "#             with mx.autograd.record():\n",
    "#                 losses = [loss_function(net(X, Y, W), [U, V])\n",
    "#                           for X, Y, W, U, V in zip(inputs, token_types, valid_length, start_label, end_label)]\n",
    "#             # run backward on each gpu\n",
    "#             for ls in losses:\n",
    "#                 ls.backward()\n",
    "#                 step_loss += ls.asscalar()\n",
    "#             # aggregate gradient over GPUs\n",
    "#             for i in range(len(params[0])):\n",
    "#                 allreduce([params[c][i].grad for c in range(len(ctx))])\n",
    "#             # update parameters with SGD on each GPU\n",
    "#             for p in params:\n",
    "#                 nlp.utils.clip_grad_global_norm(P, 1)\n",
    "#                 trainer.update(1)\n",
    "            if (batch_id + 1) % log_interval == 0: \n",
    "                toc = time.time()\n",
    "                log.info('Epoch: {}, Batch: {}/{}, Loss={:.4f}, lr={:.7f} Time cost={:.1f} Thoughput={:.2f} samples/s'  # pylint: disable=line-too-long\n",
    "                         .format(epoch_id, batch_id, len(train_dataloader),\n",
    "                                 step_loss / log_interval,\n",
    "                                 trainer.learning_rate, toc - tic, log_num/(toc - tic)))\n",
    "                tic = time.time()\n",
    "                step_loss = 0.0\n",
    "                log_num = 0\n",
    "        epoch_toc = time.time()\n",
    "        log.info('Time cost={:.2f} s, Thoughput={:.2f} samples/s'.format(\n",
    "            epoch_toc - epoch_tic, total_num/(epoch_toc - epoch_tic)))\n",
    "\n",
    "    net.save_parameters(os.path.join(output_dir, 'net.params'))\n",
    "\n",
    "\n",
    "train(log, train_data_transform, train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate():\n",
    "    \"\"\"Evaluate the model on validation dataset.\n",
    "    \"\"\"\n",
    "    log.info('Loading dev data...')\n",
    "#     if version_2:\n",
    "#         dev_data = SQuAD('dev', version='2.0')\n",
    "#     else:\n",
    "    dev_data = SQuAD('dev', version='1.1')\n",
    "    if args.debug:\n",
    "        sampled_data = [dev_data[0], dev_data[1], dev_data[2]]\n",
    "        dev_data = mx.gluon.data.SimpleDataset(sampled_data)\n",
    "    log.info('Number of records in dev data:{}'.format(len(dev_data)))\n",
    "\n",
    "    dev_dataset = dev_data.transform(\n",
    "        SQuADTransform(\n",
    "            copy.copy(tokenizer),\n",
    "            max_seq_length=max_seq_length,\n",
    "            doc_stride=doc_stride,\n",
    "            max_query_length=max_query_length,\n",
    "            is_pad=False,\n",
    "            is_training=False)._transform, lazy=False)\n",
    "    \n",
    "    dev_data_transform, _ = preprocess_dataset(\n",
    "        dev_data, SQuADTransform(\n",
    "            copy.copy(tokenizer),\n",
    "            max_seq_length=max_seq_length,\n",
    "            doc_stride=doc_stride,\n",
    "            max_query_length=max_query_length,\n",
    "            is_pad=False,\n",
    "            is_training=False))\n",
    "    log.info('The number of examples after preprocessing:{}'.format(\n",
    "        len(dev_data_transform)))\n",
    "\n",
    "    dev_dataloader = mx.gluon.data.DataLoader(\n",
    "        dev_data_transform,\n",
    "        batchify_fn=batchify_fn,\n",
    "        num_workers=4, batch_size=test_batch_size,\n",
    "        shuffle=False, last_batch='keep')\n",
    "\n",
    "    log.info('start prediction')\n",
    "\n",
    "    all_results = collections.defaultdict(list)\n",
    "\n",
    "    epoch_tic = time.time()\n",
    "    total_num = 0\n",
    "    for data in dev_dataloader:\n",
    "        example_ids, inputs, token_types, valid_length, _, _ = data\n",
    "        total_num += len(inputs)\n",
    "        out = net(inputs.astype('float32').as_in_context(ctx),\n",
    "                  token_types.astype('float32').as_in_context(ctx),\n",
    "                  valid_length.astype('float32').as_in_context(ctx))\n",
    "\n",
    "        output = mx.nd.split(out, axis=2, num_outputs=2)\n",
    "        example_ids = example_ids.asnumpy().tolist()\n",
    "        pred_start = output[0].reshape((0, -3)).asnumpy()\n",
    "        pred_end = output[1].reshape((0, -3)).asnumpy()\n",
    "\n",
    "        for example_id, start, end in zip(example_ids, pred_start, pred_end):\n",
    "            all_results[example_id].append(PredResult(start=start, end=end))\n",
    "            \n",
    "    epoch_toc = time.time()\n",
    "    log.info('Time cost={:.2f} s, Thoughput={:.2f} samples/s'.format(\n",
    "        epoch_toc - epoch_tic, total_num/(epoch_toc - epoch_tic)))\n",
    "\n",
    "    log.info('Get prediction results...')\n",
    "\n",
    "    all_predictions = collections.OrderedDict()\n",
    "\n",
    "    for features in dev_dataset:\n",
    "        results = all_results[features[0].example_id]\n",
    "        example_qas_id = features[0].qas_id\n",
    "\n",
    "        prediction, _ = predict(\n",
    "            features=features,\n",
    "            results=results,\n",
    "            tokenizer=nlp.data.BERTBasicTokenizer(lower=lower),\n",
    "            max_answer_length=max_answer_length,\n",
    "            null_score_diff_threshold=null_score_diff_threshold,\n",
    "            n_best_size=n_best_size,\n",
    "#             version_2=version_2\n",
    "        )\n",
    "\n",
    "        all_predictions[example_qas_id] = prediction\n",
    "\n",
    "    with io.open(os.path.join(output_dir, 'predictions.json'),\n",
    "                 'w', encoding='utf-8') as fout:\n",
    "        data = json.dumps(all_predictions, ensure_ascii=False)\n",
    "        fout.write(data)\n",
    "\n",
    "#     if version_2:\n",
    "#         log.info('Please run evaluate-v2.0.py to get evaluation results for SQuAD 2.0')\n",
    "#     else:\n",
    "    F1_EM = get_F1_EM(dev_data, all_predictions)\n",
    "    log.info(F1_EM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gluonnlp:Loading dev data...\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Namespace' object has no attribute 'debug'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-3f393ad04e6a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-20-13aa78fa4d8a>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m#     else:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mdev_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSQuAD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'dev'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mversion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'1.1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0msampled_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdev_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdev_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdev_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mdev_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgluon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSimpleDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msampled_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Namespace' object has no attribute 'debug'"
     ]
    }
   ],
   "source": [
    "evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy on SageMaker\n",
    "\n",
    "1. Saving the model parameters\n",
    "2. Preparing functions for inference \n",
    "3. Building a docker container with dependencies installed\n",
    "4. Launch a serving end-point with SageMaker SDK\n",
    "\n",
    "### 1. Save the model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "## save parameters, model definition and vocabulary in a zip file\n",
    "\n",
    "# net.export('checkpoint')\n",
    "with open('vocab.json', 'w') as f:\n",
    "    f.write(vocab.to_json())\n",
    "import tarfile\n",
    "with tarfile.open(\"model.tar.gz\", \"w:gz\") as tar:\n",
    "    tar.add(\"output_dir/checkpoint-0000.params\") \n",
    "    tar.add(\"output_dir/checkpoint-symbol.json\") \n",
    "    tar.add(\"output_dir/vocab.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Preparing functions for inference\n",
    "\n",
    "Two functions: \n",
    "1. model_fn() to load model parameters\n",
    "2. transform_fn() to run model inference given an input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Building a docker container with dependencies installed\n",
    "\n",
    "Let's prepare a docker container with all the dependencies required for model inference. Here we build a docker container based on the SageMaker MXNet inference container, and you can find the list of all available inference containers at https://docs.aws.amazon.com/sagemaker/latest/dg/pre-built-containers-frameworks-deep-learning.html\n",
    "\n",
    "Here we use local mode for demonstration purpose. To deploy on actual instances, you need to login into AWS elastic container registry (ECR) service, and push the container to ECR. \n",
    "\n",
    "```\n",
    "docker build -t $YOUR_EDR_DOCKER_TAG . -f Dockerfile\n",
    "$(aws ecr get-login --no-include-email --region $YOUR_REGION)\n",
    "docker push $YOUR_EDR_DOCKER_TAG\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting Dockerfile\n"
     ]
    }
   ],
   "source": [
    "%%writefile Dockerfile\n",
    "\n",
    "ARG REGION\n",
    "FROM 763104351884.dkr.ecr.$REGION.amazonaws.com/mxnet-inference:1.6.0-gpu-py3\n",
    "\n",
    "RUN pip install --upgrade --user --pre 'mxnet-mkl' 'https://github.com/dmlc/gluon-nlp/tarball/v0.9.x'\n",
    "\n",
    "RUN pip list | grep mxnet\n",
    "\n",
    "COPY *.py /opt/ml/model/code/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING! Using --password via the CLI is insecure. Use --password-stdin.\n",
      "WARNING! Your password will be stored unencrypted in /home/ec2-user/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n",
      "Login Succeeded\n"
     ]
    }
   ],
   "source": [
    "## Docker login cmd\n",
    "!$(aws ecr get-login --no-include-email --region us-east-1 --registry-ids 763104351884)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending build context to Docker daemon  2.127GB\n",
      "Step 1/5 : ARG REGION\n",
      "Step 2/5 : FROM 763104351884.dkr.ecr.$REGION.amazonaws.com/mxnet-inference:1.6.0-gpu-py3\n",
      "1.6.0-gpu-py3: Pulling from mxnet-inference\n",
      "\n",
      "\u001b[1B7927d38a: Pulling fs layer \n",
      "\u001b[1Bac894db4: Pulling fs layer \n",
      "\u001b[1B2af6d627: Pulling fs layer \n",
      "\u001b[1B86211d23: Pulling fs layer \n",
      "\u001b[1B603ff777: Pulling fs layer \n",
      "\u001b[1B7165632f: Pulling fs layer \n",
      "\u001b[1B96e40dcf: Pulling fs layer \n",
      "\u001b[1B91ff3706: Pulling fs layer \n",
      "\u001b[1B02a4385b: Pulling fs layer \n",
      "\u001b[1Be229cfdb: Pulling fs layer \n",
      "\u001b[1B0e6ed5b5: Pulling fs layer \n",
      "\u001b[1Bc8e328fe: Pulling fs layer \n",
      "\u001b[1Bbb20abb1: Pulling fs layer \n",
      "\u001b[1B0702cb67: Pulling fs layer \n",
      "\u001b[1Bd6c2671b: Pulling fs layer \n",
      "\u001b[1B486e676d: Pulling fs layer \n",
      "\u001b[1Ba8b75933: Pulling fs layer \n",
      "\u001b[1B7d871d5a: Pulling fs layer \n",
      "\u001b[1Bc8e48618: Pulling fs layer \n",
      "\u001b[1B9ef7425f: Pulling fs layer \n",
      "\u001b[1Bc02fa024: Pulling fs layer \n",
      "\u001b[9B0702cb67: Downloading  686.7MB/686.7MBK\u001b[19A\u001b[1K\u001b[K\u001b[18A\u001b[1K\u001b[K\u001b[22A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[22A\u001b[1K\u001b[K\u001b[18A\u001b[1K\u001b[K\u001b[16A\u001b[1K\u001b[K\u001b[22A\u001b[1K\u001b[K\u001b[15A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[15A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[22A\u001b[1K\u001b[K\u001b[22A\u001b[1K\u001b[K\u001b[22A\u001b[1K\u001b[KDownloading  538.1kB/270.4MB\u001b[22A\u001b[1K\u001b[K\u001b[13A\u001b[1K\u001b[K\u001b[22A\u001b[1K\u001b[K\u001b[22A\u001b[1K\u001b[K\u001b[13A\u001b[1K\u001b[K\u001b[22A\u001b[1K\u001b[K\u001b[22A\u001b[1K\u001b[K\u001b[13A\u001b[1K\u001b[K\u001b[22A\u001b[1K\u001b[K\u001b[13A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[22A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[22A\u001b[1K\u001b[K\u001b[15A\u001b[1K\u001b[K\u001b[12A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[12A\u001b[1K\u001b[K\u001b[9A\u001b[1K\u001b[K\u001b[15A\u001b[1K\u001b[K\u001b[12A\u001b[1K\u001b[K\u001b[9A\u001b[1K\u001b[K\u001b[15A\u001b[1K\u001b[K\u001b[15A\u001b[1K\u001b[K\u001b[15A\u001b[1K\u001b[K\u001b[9A\u001b[1K\u001b[K\u001b[12A\u001b[1K\u001b[K\u001b[9A\u001b[1K\u001b[K\u001b[12A\u001b[1K\u001b[K\u001b[15A\u001b[1K\u001b[K\u001b[15A\u001b[1K\u001b[K\u001b[9A\u001b[1K\u001b[K\u001b[12A\u001b[1K\u001b[K\u001b[9A\u001b[1K\u001b[K\u001b[9A\u001b[1K\u001b[K\u001b[15A\u001b[1K\u001b[K\u001b[9A\u001b[1K\u001b[K\u001b[15A\u001b[1K\u001b[K\u001b[7A\u001b[1K\u001b[K\u001b[15A\u001b[1K\u001b[K\u001b[7A\u001b[1K\u001b[K\u001b[9A\u001b[1K\u001b[K\u001b[9A\u001b[1K\u001b[K\u001b[15A\u001b[1K\u001b[Kwrite /home/ec2-user/SageMaker/docker-data/tmp/GetImageBlob331553077: no space left on device\n"
     ]
    }
   ],
   "source": [
    "!export REGION=$(wget -qO- http://169.254.169.254/latest/meta-data/placement/availability-zone) &&\\\n",
    " docker build --no-cache --build-arg REGION=${REGION::-1} -t my-docker:inference . -f Dockerfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "us-east-1a"
     ]
    }
   ],
   "source": [
    "!wget -qO- http://169.254.169.254/latest/meta-data/placement/availability-zone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "docker login -u AWS -p eyJwYXlsb2FkIjoiV3FDZFFmeFhrOXZ2aVhsSzZ4YUFmU2U0aWJsRHp5ZEJLRjhNd3hXcW5KREwveEtDcjdUaUhRZlJ0NEg2ZmR2ZWswcVQ2eGFjMUswVWFtblhwOWNTVUROUkloRWZaL1M3YWU1K01JZEdUbFAvMmtWV09nWW1LUExMVFArV2JPblhxR0dSVGFFQjA1RHdrcGFEcThtVFFidjU0WWtpRkpqRkttRzAvVzNUTWxUM3VqRWp3ZkppVWlIMnBZU3JYY3lqWHBtUlRsUXNJbzRRbDJkVG5TM25FVkRlRm5jckFYOHpZUWNtY2RtcmxqSHo3UEhSZ2h5RVcxWjI3eU9Yd2FGckVDRTk3VXhYVy9aVHB0N2RSb21HVERCVGcrRVJ1RDVCb0hyVGF0SGk3RC9ROEs2d0ZaUVE0YXYrT1NQbUJQSUViNFFBOSswMG5tWXR4Rmk3K3c2eU8vSjl6eXdtRW9nQzA3ejdiTHpIRjduZDRTeHlVK2hzTjJkV1ZjWVBpVXI3aU05d21ESEdJZWkxWkJjWnk5eW9CWGNwcE00OXhGb0NBRE80b3J3L1NRNmpxdk5NSi9sU1FYb01yNU1GV0d2Sy9QdTNXUnlXcEpobjU5WDUrOEsxalBxWnhuTVJrTXdxb1A5N2RYQzdZUFF6NCtFYXVvNSszMHROck9QZktiMmQyYk9US1htOHhIa2NsblJhVm84aVlpaWl3QnhVSWJHalhIOHB0eVVrSVUzTlo5Nkw5TVpTc0YzdmdhTzZVQytPSFFXbTdsQU9obk15Wm1GeVVoQlA2OTFDNHJlY1lGTEIxc1IwZVJtQzhRMXRZMW45NThzMDhCK2F6VVlHYWZtbE9NSjdraStjMTB6SnA1WXhseGRsejdIdGhicVE4WHJrVkJGSHFJaWszRjVuRERBMWd0NGZQdHIzTnBkWnp4YjZjVzRsZ0lQTjBoQVgxYlhsVVRzY1gyZ00xaWdtR2h1eHZQSU1pS0tqR2VKTUEyMzJCUDlxQStVVVBQbkZyYVhyOHdLM1VrbEpBSllMYWxHL0t4RmtkWHdiTmF0eklsRHRMWkpRdHRnWHQ2SmF5RU1FNmt1V0tNdnE0WGlTZzlJblRvS1RNL01aTmpjRkJmeDhZbGdTREk3OEFSbTVBQnk3bC96aFhXRlNQbzJJSkppUEE3ZjZSNzJ3ZnphWlBoT0tFNk96R1BDMTFKK1hvM1orYXR2RzJwMFh4cU1nWEN4RFhtaUEzRTdWUmZlYTRvcC9rM25qMVlKZlI5NkRBQVRnTWYrRGhyNVpDa29acmFSb0c4T1luYkl5a3RFTk84anVvMDB0N29jWmJ2OGJCYXBiTDNRL2VIV3B4WENLRmhRMkxSZUNUR2orVjNKVy9HYi8rU2o1UEhuTUdDaUZpdU9QUFZheFppVTlVY1ArUnNSbUhIN05MUzAzQklEdkxERXRHRnI4bEZMaE1jeU4yVzFkNEdXUVQ1cjN0eC9nbUZOMFAyZi91UFJuL0N2MDVYdU5mOTlLNTU0bWE2bUNVRXkyc2habUg4UitkQmgvTmpsSXRDV2Y1VGZyMUhDclJ2a1FPakkvTkpTTHN1bFc2T2E5cnZHcWVBdTB2dXlvbTRCUTNvdEFFSG13eHo2a3RIM3ZSdU1zTHQxM0tFd1IrdFAwQVEzdUl6eDJPZzJ0cmxWV2xGaXpkYlZSRU9zM3hTMG0zMEw0TDN4blVMazh2LzZpaXVtQi9sN2VPL0ZrYTdkd0wyNXQrdkRraVdKZGg5dk1DaUxxMXVaVCIsImRhdGFrZXkiOiJBUUVCQUhod20wWWFJU0plUnRKbTVuMUc2dXFlZWtYdW9YWFBlNVVGY2U5UnE4LzE0d0FBQUg0d2ZBWUpLb1pJaHZjTkFRY0dvRzh3YlFJQkFEQm9CZ2txaGtpRzl3MEJCd0V3SGdZSllJWklBV1VEQkFFdU1CRUVESXV1ZzhtcWRkSWJ3U0xkdlFJQkVJQTdJbklaTHIwbUhYQVAwNE5peHlwa0RDTkt0S2ppcDdzTEJ1WmowUDdqMlZBZU1aYmpvZlNCZ09NbUx2SytNa0EwZDVOTHh5eVlUWVFJdlpvPSIsInZlcnNpb24iOiIyIiwidHlwZSI6IkRBVEFfS0VZIiwiZXhwaXJhdGlvbiI6MTU3ODY0ODgyNn0= https://763104351884.dkr.ecr.us-east-1.amazonaws.com\r\n"
     ]
    }
   ],
   "source": [
    "# !aws ecr get-login --no-include-email --registry-ids 763104351884\n",
    "!aws ecr get-login --no-include-email --region us-east-1 --registry-ids 763104351884"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6.0-gpu-py3: Pulling from mxnet-inference\n",
      "\n",
      "\u001b[1B7927d38a: Pulling fs layer \n",
      "\u001b[1Bac894db4: Pulling fs layer \n",
      "\u001b[1B2af6d627: Pulling fs layer \n",
      "\u001b[1B86211d23: Pulling fs layer \n",
      "\u001b[1B603ff777: Pulling fs layer \n",
      "\u001b[1B7165632f: Pulling fs layer \n",
      "\u001b[1B96e40dcf: Pulling fs layer \n",
      "\u001b[1B91ff3706: Pulling fs layer \n",
      "\u001b[1B02a4385b: Pulling fs layer \n",
      "\u001b[1Be229cfdb: Pulling fs layer \n",
      "\u001b[1B0e6ed5b5: Pulling fs layer \n",
      "\u001b[1Bc8e328fe: Pulling fs layer \n",
      "\u001b[1Bbb20abb1: Pulling fs layer \n",
      "\u001b[1B0702cb67: Pulling fs layer \n",
      "\u001b[1Bd6c2671b: Pulling fs layer \n",
      "\u001b[1B486e676d: Pulling fs layer \n",
      "\u001b[1Ba8b75933: Pulling fs layer \n",
      "\u001b[13B165632f: Waiting fs layer \n",
      "\u001b[1Bc8e48618: Pulling fs layer \n",
      "\u001b[12B2a4385b: Waiting fs layer \n",
      "\u001b[1Bc02fa024: Pulling fs layer \n",
      "\u001b[7B486e676d: Download complete  B/768.9MB0A\u001b[1K\u001b[K\u001b[19A\u001b[1K\u001b[K\u001b[22A\u001b[1K\u001b[K\u001b[18A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[18A\u001b[1K\u001b[K\u001b[16A\u001b[1K\u001b[K\u001b[22A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[22A\u001b[1K\u001b[K\u001b[15A\u001b[1K\u001b[K\u001b[22A\u001b[1K\u001b[K\u001b[15A\u001b[1K\u001b[K\u001b[22A\u001b[1K\u001b[K\u001b[22A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[22A\u001b[1K\u001b[K\u001b[15A\u001b[1K\u001b[K\u001b[22A\u001b[1K\u001b[K\u001b[13A\u001b[1K\u001b[K\u001b[22A\u001b[1K\u001b[K\u001b[13A\u001b[1K\u001b[K\u001b[22A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[22A\u001b[1K\u001b[K\u001b[22A\u001b[1K\u001b[K\u001b[13A\u001b[1K\u001b[K\u001b[22A\u001b[1K\u001b[K\u001b[13A\u001b[1K\u001b[K\u001b[15A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[13A\u001b[1K\u001b[K\u001b[15A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[13A\u001b[1K\u001b[K\u001b[22A\u001b[1K\u001b[K\u001b[13A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[15A\u001b[1K\u001b[K\u001b[22A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[KDownloading  124.5MB/688.7MB\u001b[14A\u001b[1K\u001b[K\u001b[19A\u001b[1K\u001b[K\u001b[13A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[19A\u001b[1K\u001b[K\u001b[13A\u001b[1K\u001b[K\u001b[15A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[13A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[13A\u001b[1K\u001b[K\u001b[13A\u001b[1K\u001b[K\u001b[16A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[13A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[13A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[13A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[15A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[15A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[15A\u001b[1K\u001b[K\u001b[13A\u001b[1K\u001b[K\u001b[15A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[15A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[13A\u001b[1K\u001b[K\u001b[15A\u001b[1K\u001b[K\u001b[15A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[13A\u001b[1K\u001b[K\u001b[15A\u001b[1K\u001b[K\u001b[13A\u001b[1K\u001b[K\u001b[15A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[15A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[15A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[15A\u001b[1K\u001b[K\u001b[15A\u001b[1K\u001b[K\u001b[12A\u001b[1K\u001b[K\u001b[15A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[15A\u001b[1K\u001b[K\u001b[12A\u001b[1K\u001b[K\u001b[15A\u001b[1K\u001b[K\u001b[12A\u001b[1K\u001b[K\u001b[9A\u001b[1K\u001b[K\u001b[12A\u001b[1K\u001b[K\u001b[9A\u001b[1K\u001b[K\u001b[15A\u001b[1K\u001b[K\u001b[12A\u001b[1K\u001b[K\u001b[15A\u001b[1K\u001b[K\u001b[15A\u001b[1K\u001b[K\u001b[12A\u001b[1K\u001b[K\u001b[12A\u001b[1K\u001b[K\u001b[12A\u001b[1K\u001b[K\u001b[15A\u001b[1K\u001b[K\u001b[8A\u001b[1K\u001b[K\u001b[15A\u001b[1K\u001b[K\u001b[9A\u001b[1K\u001b[K\u001b[15A\u001b[1K\u001b[K\u001b[9A\u001b[1K\u001b[K\u001b[9A\u001b[1K\u001b[K\u001b[9A\u001b[1K\u001b[K\u001b[15A\u001b[1K\u001b[K\u001b[9A\u001b[1K\u001b[K\u001b[15A\u001b[1K\u001b[K\u001b[9A\u001b[1K\u001b[K\u001b[15A\u001b[1K\u001b[K\u001b[9A\u001b[1K\u001b[K\u001b[7A\u001b[1K\u001b[K\u001b[9A\u001b[1K\u001b[K\u001b[7A\u001b[1K\u001b[K\u001b[9A\u001b[1K\u001b[K\u001b[9A\u001b[1K\u001b[K\u001b[15A\u001b[1K\u001b[K\u001b[7A\u001b[1K\u001b[K\u001b[9A\u001b[1K\u001b[K\u001b[15A\u001b[1K\u001b[K\u001b[9A\u001b[1K\u001b[K\u001b[9A\u001b[1K\u001b[K\u001b[7A\u001b[1K\u001b[K\u001b[9A\u001b[1K\u001b[K\u001b[7A\u001b[1K\u001b[K\u001b[9A\u001b[1K\u001b[K\u001b[7A\u001b[1K\u001b[K\u001b[9A\u001b[1K\u001b[K\u001b[7A\u001b[1K\u001b[K\u001b[9A\u001b[1K\u001b[K\u001b[15A\u001b[1K\u001b[K\u001b[9A\u001b[1K\u001b[K\u001b[9A\u001b[1K\u001b[K\u001b[7A\u001b[1K\u001b[K\u001b[9A\u001b[1K\u001b[K\u001b[15A\u001b[1K\u001b[K\u001b[9A\u001b[1K\u001b[K\u001b[7A\u001b[1K\u001b[K\u001b[9A\u001b[1K\u001b[K\u001b[15A\u001b[1K\u001b[K\u001b[15A\u001b[1K\u001b[K\u001b[15A\u001b[1K\u001b[K\u001b[15A\u001b[1K\u001b[K\u001b[15A\u001b[1K\u001b[K\u001b[15A\u001b[1K\u001b[K\u001b[15A\u001b[1K\u001b[K\u001b[15A\u001b[1K\u001b[K\u001b[15A\u001b[1K\u001b[K\u001b[15A\u001b[1K\u001b[K\u001b[15A\u001b[1K\u001b[K\u001b[15A\u001b[1K\u001b[K\u001b[15A\u001b[1K\u001b[K\u001b[15A\u001b[1K\u001b[K\u001b[15A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[15A\u001b[1K\u001b[K\u001b[4A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[15A\u001b[1K\u001b[K\u001b[2A\u001b[1K\u001b[K\u001b[1A\u001b[1K\u001b[K\u001b[15A\u001b[1K\u001b[K\u001b[15A\u001b[1K\u001b[K\u001b[15A\u001b[1K\u001b[K\u001b[15A\u001b[1K\u001b[K\u001b[15A\u001b[1K\u001b[K\u001b[15A\u001b[1K\u001b[K\u001b[15A\u001b[1K\u001b[K\u001b[15A\u001b[1K\u001b[K\u001b[15A\u001b[1K\u001b[K\u001b[15A\u001b[1K\u001b[K\u001b[15A\u001b[1K\u001b[K\u001b[9A\u001b[1K\u001b[K\u001b[15A\u001b[1K\u001b[K\u001b[9A\u001b[1K\u001b[K\u001b[15A\u001b[1K\u001b[K\u001b[9A\u001b[1K\u001b[K\u001b[15A\u001b[1K\u001b[K\u001b[9A\u001b[1K\u001b[K\u001b[15A\u001b[1K\u001b[K\u001b[9A\u001b[1K\u001b[K\u001b[15A\u001b[1K\u001b[K\u001b[15A\u001b[1K\u001b[K\u001b[15A\u001b[1K\u001b[K\u001b[15A\u001b[1K\u001b[K\u001b[9A\u001b[1K\u001b[K\u001b[15A\u001b[1K\u001b[K\u001b[9A\u001b[1K\u001b[K\u001b[15A\u001b[1K\u001b[K\u001b[9A\u001b[1K\u001b[K\u001b[15A\u001b[1K\u001b[K\u001b[15A\u001b[1K\u001b[K\u001b[15A\u001b[1K\u001b[K\u001b[15A\u001b[1K\u001b[K\u001b[15A\u001b[1K\u001b[K\u001b[15A\u001b[1K\u001b[K\u001b[15A\u001b[1K\u001b[K\u001b[15A\u001b[1K\u001b[K\u001b[15A\u001b[1K\u001b[K\u001b[15A\u001b[1K\u001b[K\u001b[15A\u001b[1K\u001b[K\u001b[15A\u001b[1K\u001b[K\u001b[15A\u001b[1K\u001b[K\u001b[15A\u001b[1K\u001b[K\u001b[15A\u001b[1K\u001b[K\u001b[15A\u001b[1K\u001b[K\u001b[15A\u001b[1K\u001b[K\u001b[15A\u001b[1K\u001b[K\u001b[15A\u001b[1K\u001b[K\u001b[15A\u001b[1K\u001b[K\u001b[15A\u001b[1K\u001b[K\u001b[15A\u001b[1K\u001b[K\u001b[15A\u001b[1K\u001b[K\u001b[15A\u001b[1K\u001b[K\u001b[15A\u001b[1K\u001b[K\u001b[15A\u001b[1K\u001b[K\u001b[7A\u001b[1K\u001b[K\u001b[15A\u001b[1K\u001b[K\u001b[7A\u001b[1K\u001b[K\u001b[15A\u001b[1K\u001b[K\u001b[7A\u001b[1K\u001b[K\u001b[15A\u001b[1K\u001b[K\u001b[15A\u001b[1K\u001b[K\u001b[15A\u001b[1K\u001b[K\u001b[7A\u001b[1K\u001b[K\u001b[15A\u001b[1K\u001b[K\u001b[15A\u001b[1K\u001b[K\u001b[7A\u001b[1K\u001b[K\u001b[15A\u001b[1K\u001b[K\u001b[7A\u001b[1K\u001b[K\u001b[15A\u001b[1K\u001b[K\u001b[7A\u001b[1K\u001b[K\u001b[15A\u001b[1K\u001b[K\u001b[7A\u001b[1K\u001b[K\u001b[15A\u001b[1K\u001b[K\u001b[15A\u001b[1K\u001b[K\u001b[15A\u001b[1K\u001b[K\u001b[15A\u001b[1K\u001b[K\u001b[7A\u001b[1K\u001b[K\u001b[15A\u001b[1K\u001b[K\u001b[7A\u001b[1K\u001b[K\u001b[15A\u001b[1K\u001b[K\u001b[7A\u001b[1K\u001b[K\u001b[15A\u001b[1K\u001b[K\u001b[15A\u001b[1K\u001b[K\u001b[7A\u001b[1K\u001b[K\u001b[7A\u001b[1K\u001b[K\u001b[7A\u001b[1K\u001b[K\u001b[7A\u001b[1K\u001b[K\u001b[7A\u001b[1K\u001b[K\u001b[7A\u001b[1K\u001b[K\u001b[7A\u001b[1K\u001b[K\u001b[7A\u001b[1K\u001b[K\u001b[7A\u001b[1K\u001b[K\u001b[7A\u001b[1K\u001b[K\u001b[7A\u001b[1K\u001b[KDownloading  377.8MB/768.9MB\u001b[7A\u001b[1K\u001b[K\u001b[7A\u001b[1K\u001b[K\u001b[7A\u001b[1K\u001b[K\u001b[7A\u001b[1K\u001b[K\u001b[7A\u001b[1K\u001b[K\u001b[7A\u001b[1K\u001b[K\u001b[7A\u001b[1K\u001b[K\u001b[7A\u001b[1K\u001b[K\u001b[7A\u001b[1K\u001b[K\u001b[7A\u001b[1K\u001b[K\u001b[7A\u001b[1K\u001b[K\u001b[7A\u001b[1K\u001b[K\u001b[7A\u001b[1K\u001b[K\u001b[7A\u001b[1K\u001b[K\u001b[7A\u001b[1K\u001b[K\u001b[7A\u001b[1K\u001b[K\u001b[7A\u001b[1K\u001b[K\u001b[7A\u001b[1K\u001b[K\u001b[7A\u001b[1K\u001b[K\u001b[7A\u001b[1K\u001b[K\u001b[7A\u001b[1K\u001b[K\u001b[7A\u001b[1K\u001b[K\u001b[7A\u001b[1K\u001b[K\u001b[7A\u001b[1K\u001b[K\u001b[7A\u001b[1K\u001b[K\u001b[7A\u001b[1K\u001b[K\u001b[7A\u001b[1K\u001b[K\u001b[7A\u001b[1K\u001b[K\u001b[7A\u001b[1K\u001b[K\u001b[7A\u001b[1K\u001b[K\u001b[7A\u001b[1K\u001b[K\u001b[7A\u001b[1K\u001b[K\u001b[7A\u001b[1K\u001b[K\u001b[7A\u001b[1K\u001b[K\u001b[7A\u001b[1K\u001b[K\u001b[7A\u001b[1K\u001b[K\u001b[7A\u001b[1K\u001b[K\u001b[7A\u001b[1K\u001b[K\u001b[7A\u001b[1K\u001b[K\u001b[7A\u001b[1K\u001b[K\u001b[7A\u001b[1K\u001b[K\u001b[7A\u001b[1K\u001b[K\u001b[7A\u001b[1K\u001b[K\u001b[7A\u001b[1K\u001b[K\u001b[7A\u001b[1K\u001b[K\u001b[7A\u001b[1K\u001b[K\u001b[7A\u001b[1K\u001b[K\u001b[7A\u001b[1K\u001b[K\u001b[7A\u001b[1K\u001b[K\u001b[7A\u001b[1K\u001b[K\u001b[7A\u001b[1K\u001b[K\u001b[7A\u001b[1K\u001b[K\u001b[7A\u001b[1K\u001b[K\u001b[7A\u001b[1K\u001b[K\u001b[7A\u001b[1K\u001b[Kwrite /home/ec2-user/SageMaker/docker-data/tmp/GetImageBlob671858852: no space left on device\n"
     ]
    }
   ],
   "source": [
    "!docker pull 763104351884.dkr.ecr.us-east-1.amazonaws.com/mxnet-inference:1.6.0-gpu-py3\n",
    "#              763104351884.dkr.ecr.<region>.amazonaws.com/mxnet-inference:1.4.1-gpu-py3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "docker login -u AWS -p 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 https://397262719838.dkr.ecr.us-east-1.amazonaws.com\r\n"
     ]
    }
   ],
   "source": [
    "!aws ecr get-login --no-include-email --region us-east-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error response from daemon: Get https://520713654638.dkr.ecr.us-east-1.amazonaws.com/v2/mxnet-inference/manifests/1.6.0-gpu-py3: no basic auth credentials\r\n"
     ]
    }
   ],
   "source": [
    "!docker pull 520713654638.dkr.ecr.us-east-1.amazonaws.com/mxnet-inference:1.6.0-gpu-py3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "\n",
    "role=sagemaker.get_execution_role()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "docker login -u AWS -p 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 https://520713654638.dkr.ecr.us-east-1.amazonaws.com\r\n"
     ]
    }
   ],
   "source": [
    "!aws ecr get-login --no-include-email --registry-ids 520713654638"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_mxnet_p36",
   "language": "python",
   "name": "conda_mxnet_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
