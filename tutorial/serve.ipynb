{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import gluonnlp as nlp\n",
    "import mxnet as mx\n",
    "from utils import predict_sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fn(model_dir):\n",
    "    \"\"\"\n",
    "    Load the gluon model. Called once when hosting service starts.\n",
    "    :param: model_dir The directory where model files are stored.\n",
    "    :return: a model (in this case a Gluon network)\n",
    "    \"\"\"\n",
    "    prefix = 'checkpoint'\n",
    "    net = mx.gluon.nn.SymbolBlock.imports(prefix + '-symbol.json',\n",
    "                                          ['data0', 'data1', 'data2'],\n",
    "                                          prefix + '-0000.params')\n",
    "    net.load_parameters('%s/'%model_dir + prefix + '-0000.params', ctx=mx.cpu())\n",
    "    vocab_json = open('%s/vocab.json'%model_dir).read()\n",
    "    vocab = nlp.vocab.BERTVocab.from_json(vocab_json)\n",
    "    return net, vocab\n",
    "\n",
    "\n",
    "def transform_fn(model, data, input_content_type, output_content_type):\n",
    "    \"\"\"\n",
    "    Transform a request using the Gluon model. Called once per request.\n",
    "    :param net: The Gluon model.\n",
    "    :param data: The request payload.\n",
    "    :param input_content_type: The request content type.\n",
    "    :param output_content_type: The (desired) response content type.\n",
    "    :return: response payload and content type.\n",
    "    \"\"\"\n",
    "    # we can use content types to vary input/output handling, but\n",
    "    # here we just assume json for both                                                                                                      96,5          Bot\n",
    "    net, vocabulary = model\n",
    "    sentence = json.loads(data)\n",
    "    tokenizer = nlp.data.BERTTokenizer(vocabulary)\n",
    "    result = predict_sentiment(net, mx.cpu(), vocabulary, tokenizer, sentence)\n",
    "    response_body = json.dumps(result)\n",
    "    return response_body, output_content_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# example usage:\\n\\nmodel = model_fn('.')\\ndata = json.dumps('this movie is great')\\ninput_content_type = 'application/json'\\noutput_content_type = 'application/json'\\nresult, _ = transform_fn(model, data, input_content_type, output_content_type)\\nprint(result)\\n\""
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# example usage:\n",
    "\n",
    "model = model_fn('.')\n",
    "data = json.dumps('this movie is great')\n",
    "input_content_type = 'application/json'\n",
    "output_content_type = 'application/json'\n",
    "result, _ = transform_fn(model, data, input_content_type, output_content_type)\n",
    "print(result)\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_mxnet_p36",
   "language": "python",
   "name": "conda_mxnet_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
